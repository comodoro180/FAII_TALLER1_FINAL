{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282215d1",
   "metadata": {
    "papermill": {
     "duration": 0.016676,
     "end_time": "2025-04-07T22:59:38.735429",
     "exception": false,
     "start_time": "2025-04-07T22:59:38.718753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2011d56",
   "metadata": {
    "papermill": {
     "duration": 0.009755,
     "end_time": "2025-04-07T22:59:38.755698",
     "exception": false,
     "start_time": "2025-04-07T22:59:38.745943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae19e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%pip install torchsummary albumentations wandb --quiet\\n%pip install tqdm \\n%pip install pandas \\n%pip install torch\\n%pip install PIL\\n%pip install torchvision\\n%pip install matplotlib\\n%pip install scikit-learn\\n%pip install scikit-image\\n%pip install setuptools\\n%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n%pip install optuna '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%pip install torchsummary albumentations wandb --quiet\n",
    "%pip install tqdm \n",
    "%pip install pandas \n",
    "%pip install torch\n",
    "%pip install PIL\n",
    "%pip install torchvision\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install scikit-image\n",
    "%pip install setuptools\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install optuna '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e826f10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allc0363\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.6'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\allc0363\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import typing as ty\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from itertools import chain, islice\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from skimage import io, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.ops import box_iou\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import wandb\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1dbbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e465e538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2675bbbd290>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un generador para el DataLoader\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa521595",
   "metadata": {
    "papermill": {
     "duration": 0.010047,
     "end_time": "2025-04-07T22:59:52.115831",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.105784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3511cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../Datos/' \n",
    "WORK_DIR = '../Datos/' \n",
    "DIR_Results = './Resultados/'\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "IMG_ORIG_H, IMG_ORIG_W = 720, 1280\n",
    "TARGET_H, TARGET_W = 224, 224 \n",
    "\n",
    "img_dir = osp.join(DATA_DIR, \"images/images\")\n",
    "df = pd.read_csv(osp.join(DATA_DIR, \"train.csv\"))\n",
    "\n",
    "obj2id  = {'f16':0,'cougar':1,'chinook':2,'ah64':3,'f15':4,'seahawk':5}\n",
    "#obj2id = {'f16':0, 'cougar':1, 'chinook':2, 'ah64':3, 'f15':4, 'seahawk':5}\n",
    "id2obj = {v: k for k, v in obj2id.items()} \n",
    "\n",
    "NUM_CLASSES = len(obj2id)\n",
    "MEANS_IMAGENET = [0.485, 0.456, 0.406] \n",
    "STDS_IMAGENET = [0.229, 0.224, 0.225]  \n",
    "\n",
    "df[\"class_id\"] = df[\"class\"].map(obj2id)\n",
    "columns_f=['filename','xmin','ymin','xmax','ymax','class','class_id']\n",
    "df= df[columns_f].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1301579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global: TARGET_H=224, TARGET_W=224, NUM_CLASSES=6\n",
      "Global: IMG_ORIG_H=720, IMG_ORIG_W=1280\n"
     ]
    }
   ],
   "source": [
    "print(f\"Global: TARGET_H={TARGET_H}, TARGET_W={TARGET_W}, NUM_CLASSES={NUM_CLASSES}\")\n",
    "print(f\"Global: IMG_ORIG_H={IMG_ORIG_H}, IMG_ORIG_W={IMG_ORIG_W}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d6fb3",
   "metadata": {
    "papermill": {
     "duration": 0.009851,
     "end_time": "2025-04-07T22:59:52.204505",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.194654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd3bd31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.225659Z",
     "iopub.status.busy": "2025-04-07T22:59:52.225404Z",
     "iopub.status.idle": "2025-04-07T22:59:52.325826Z",
     "shell.execute_reply": "2025-04-07T22:59:52.324926Z"
    },
    "papermill": {
     "duration": 0.112991,
     "end_time": "2025-04-07T22:59:52.327459",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.214468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_filename = osp.join(DATA_DIR, \"images/images\",'image_00077.jpeg')\n",
    "\n",
    "img1 = cv2.imread(img_filename)\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = io.imread(img_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5efba73b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.349085Z",
     "iopub.status.busy": "2025-04-07T22:59:52.348843Z",
     "iopub.status.idle": "2025-04-07T22:59:52.352980Z",
     "shell.execute_reply": "2025-04-07T22:59:52.352286Z"
    },
    "papermill": {
     "duration": 0.016291,
     "end_time": "2025-04-07T22:59:52.354133",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.337842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "(3, 720, 1280)\n"
     ]
    }
   ],
   "source": [
    "print(img1.shape)\n",
    "print(img1.transpose((2,0,1)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6543d9ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.376495Z",
     "iopub.status.busy": "2025-04-07T22:59:52.376268Z",
     "iopub.status.idle": "2025-04-07T22:59:55.005361Z",
     "shell.execute_reply": "2025-04-07T22:59:55.004526Z"
    },
    "papermill": {
     "duration": 2.641242,
     "end_time": "2025-04-07T22:59:55.006753",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.365511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:01<00:00, 131.40it/s]\n"
     ]
    }
   ],
   "source": [
    "list_image = list(df.filename)\n",
    "data_shape = []\n",
    "data_dim = []\n",
    "data_w = []\n",
    "data_h = []\n",
    "\n",
    "for i in tqdm(list_image): ## tqdm(list_image)dura 40 segundos\n",
    "    ruta_imagen = osp.join(img_dir, i)\n",
    "    imagen = io.imread(ruta_imagen)\n",
    "    shapes = imagen.shape\n",
    "    dimen = imagen.ndim\n",
    "    imagen = Image.open(ruta_imagen)\n",
    "    w, h = imagen.size\n",
    "    \n",
    "    data_w.append(w)\n",
    "    data_h.append(h)\n",
    "    data_shape.append(shapes)\n",
    "    data_dim.append(dimen)\n",
    "\n",
    "data_w_h = pd.DataFrame([list_image,data_shape,data_dim,data_w,data_h]).T.rename(columns={0:'filename',1:'shapes',2:'ndim',3:'w',4:'h'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e071a90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.030465Z",
     "iopub.status.busy": "2025-04-07T22:59:55.030178Z",
     "iopub.status.idle": "2025-04-07T22:59:55.039998Z",
     "shell.execute_reply": "2025-04-07T22:59:55.039336Z"
    },
    "papermill": {
     "duration": 0.022737,
     "end_time": "2025-04-07T22:59:55.041156",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.018419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w\n",
       "1280    189\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_h['w'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d6b57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.064527Z",
     "iopub.status.busy": "2025-04-07T22:59:55.064283Z",
     "iopub.status.idle": "2025-04-07T22:59:55.069700Z",
     "shell.execute_reply": "2025-04-07T22:59:55.069042Z"
    },
    "papermill": {
     "duration": 0.018239,
     "end_time": "2025-04-07T22:59:55.070844",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.052605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ndim\n",
       "3    189\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_h['ndim'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f41c81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.094434Z",
     "iopub.status.busy": "2025-04-07T22:59:55.094166Z",
     "iopub.status.idle": "2025-04-07T22:59:55.100319Z",
     "shell.execute_reply": "2025-04-07T22:59:55.099444Z"
    },
    "papermill": {
     "duration": 0.019167,
     "end_time": "2025-04-07T22:59:55.101580",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.082413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shapes\n",
       "(720, 1280, 3)    189\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_h['shapes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae60b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.125406Z",
     "iopub.status.busy": "2025-04-07T22:59:55.125136Z",
     "iopub.status.idle": "2025-04-07T22:59:55.131514Z",
     "shell.execute_reply": "2025-04-07T22:59:55.130710Z"
    },
    "papermill": {
     "duration": 0.019562,
     "end_time": "2025-04-07T22:59:55.132734",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.113172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_id\n",
       "0    41\n",
       "1    37\n",
       "2    35\n",
       "3    34\n",
       "4    23\n",
       "5    19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a308b33b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.157130Z",
     "iopub.status.busy": "2025-04-07T22:59:55.156885Z",
     "iopub.status.idle": "2025-04-07T22:59:55.162977Z",
     "shell.execute_reply": "2025-04-07T22:59:55.162127Z"
    },
    "papermill": {
     "duration": 0.019619,
     "end_time": "2025-04-07T22:59:55.164326",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.144707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "f16        41\n",
       "cougar     37\n",
       "chinook    35\n",
       "ah64       34\n",
       "f15        23\n",
       "seahawk    19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ae5293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.188357Z",
     "iopub.status.busy": "2025-04-07T22:59:55.188113Z",
     "iopub.status.idle": "2025-04-07T22:59:55.193849Z",
     "shell.execute_reply": "2025-04-07T22:59:55.193147Z"
    },
    "papermill": {
     "duration": 0.01912,
     "end_time": "2025-04-07T22:59:55.195028",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.175908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 7), (0, 7))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['xmin']>=df['xmax']].shape, df[df['ymin']>=df['ymax']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa249fc",
   "metadata": {
    "papermill": {
     "duration": 0.011273,
     "end_time": "2025-04-07T22:59:55.246598",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.235325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalizamos los bboxes (En la siguiente monitoria hablaremos de la importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed1e5e2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.270360Z",
     "iopub.status.busy": "2025-04-07T22:59:55.270085Z",
     "iopub.status.idle": "2025-04-07T22:59:55.291960Z",
     "shell.execute_reply": "2025-04-07T22:59:55.291089Z"
    },
    "papermill": {
     "duration": 0.035167,
     "end_time": "2025-04-07T22:59:55.293184",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.258017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ymin        ymax        xmin         xmax\n",
      "count  189.000000  189.000000  189.000000   189.000000\n",
      "mean   186.396825  425.455026  401.238095   902.666667\n",
      "std    112.079883  103.348946  232.361996   213.588688\n",
      "min      1.000000  154.000000    1.000000   298.000000\n",
      "25%    109.000000  359.000000  210.000000   730.000000\n",
      "50%    188.000000  417.000000  418.000000   901.000000\n",
      "75%    267.000000  494.000000  572.000000  1071.000000\n",
      "max    440.000000  702.000000  944.000000  1280.000000\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"ymin\", \"ymax\", \"xmin\", \"xmax\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10389b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de Bounding Boxes.\n",
    "# Las coordenadas se convierten a relativas [0,1].\n",
    "df[[\"ymin\", \"ymax\"]] = df[[\"ymin\", \"ymax\"]].div(IMG_ORIG_H, axis=0)\n",
    "df[[\"xmin\", \"xmax\"]] = df[[\"xmin\", \"xmax\"]].div(IMG_ORIG_W, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "accb9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que los bboxes estén acotados a [0,1] después de la normalización\n",
    "df[['xmin', 'ymin', 'xmax', 'ymax']] = df[['xmin', 'ymin', 'xmax', 'ymax']].clip(0.0, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bc1f4af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.349071Z",
     "iopub.status.busy": "2025-04-07T22:59:55.348826Z",
     "iopub.status.idle": "2025-04-07T22:59:55.361872Z",
     "shell.execute_reply": "2025-04-07T22:59:55.361223Z"
    },
    "papermill": {
     "duration": 0.026846,
     "end_time": "2025-04-07T22:59:55.363577",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.336731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ymin        ymax        xmin        xmax\n",
      "count  189.000000  189.000000  189.000000  189.000000\n",
      "mean     0.258884    0.590910    0.313467    0.705208\n",
      "std      0.155667    0.143540    0.181533    0.166866\n",
      "min      0.001389    0.213889    0.000781    0.232813\n",
      "25%      0.151389    0.498611    0.164062    0.570312\n",
      "50%      0.261111    0.579167    0.326562    0.703906\n",
      "75%      0.370833    0.686111    0.446875    0.836719\n",
      "max      0.611111    0.975000    0.737500    1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"ymin\", \"ymax\", \"xmin\", \"xmax\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca908b2f",
   "metadata": {
    "papermill": {
     "duration": 0.011617,
     "end_time": "2025-04-07T22:59:55.387443",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.375826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Particionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c0a403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.412138Z",
     "iopub.status.busy": "2025-04-07T22:59:55.411871Z",
     "iopub.status.idle": "2025-04-07T22:59:55.418848Z",
     "shell.execute_reply": "2025-04-07T22:59:55.418165Z"
    },
    "papermill": {
     "duration": 0.020781,
     "end_time": "2025-04-07T22:59:55.420086",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.399305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c24d0582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.444859Z",
     "iopub.status.busy": "2025-04-07T22:59:55.444635Z",
     "iopub.status.idle": "2025-04-07T22:59:55.450846Z",
     "shell.execute_reply": "2025-04-07T22:59:55.449988Z"
    },
    "papermill": {
     "duration": 0.019809,
     "end_time": "2025-04-07T22:59:55.452158",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.432349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "f16        21.854305\n",
       "cougar     19.867550\n",
       "chinook    18.543046\n",
       "ah64       17.880795\n",
       "f15        11.920530\n",
       "seahawk     9.933775\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class'].value_counts(1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aae1ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.476944Z",
     "iopub.status.busy": "2025-04-07T22:59:55.476726Z",
     "iopub.status.idle": "2025-04-07T22:59:55.482578Z",
     "shell.execute_reply": "2025-04-07T22:59:55.481788Z"
    },
    "papermill": {
     "duration": 0.019392,
     "end_time": "2025-04-07T22:59:55.483775",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.464383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_id\n",
       "0    21.052632\n",
       "3    18.421053\n",
       "2    18.421053\n",
       "1    18.421053\n",
       "4    13.157895\n",
       "5    10.526316\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['class_id'].value_counts(1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28a5e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. Funciones y Clases Auxiliares ---\n",
    "def reset_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7551c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# DEFINICIÓN DE collate_fn_skip_none \n",
    "def collate_fn_skip_none(batch):\n",
    "    batch_original_len = len(batch)\n",
    "    batch_filtered = [item for item in batch if item is not None]\n",
    "    \n",
    "    if batch_original_len != len(batch_filtered) and batch_original_len > 0 :\n",
    "        # print(f\"DEBUG collate_fn: Original batch len: {batch_original_len}, Filtered batch len: {len(batch_filtered)}. {batch_original_len - len(batch_filtered)} muestra(s) eran None.\")\n",
    "        pass\n",
    "\n",
    "    if not batch_filtered:\n",
    "        # print(\"DEBUG collate_fn: Entire batch is None after filtering.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return torch.utils.data.dataloader.default_collate(batch_filtered)\n",
    "    except Exception as e:\n",
    "        # print(f\"ERROR en default_collate dentro de collate_fn_skip_none: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03522bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiciones de Clases de Transformación\n",
    "class ToTensorDict:\n",
    "    def __call__(self, sample):\n",
    "        image, bbox, class_id = sample['image'], sample['bbox'], sample['class_id']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample['image'] = torch.from_numpy(image.copy()).float().div(255.0)\n",
    "        sample['bbox'] = bbox \n",
    "        sample['class_id'] = class_id\n",
    "        return sample\n",
    "\n",
    "class NormalizeDict:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.tensor(mean, dtype=torch.float32).view(3, 1, 1)\n",
    "        self.std = torch.tensor(std, dtype=torch.float32).view(3, 1, 1)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = (sample['image'] - self.mean) / self.std\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d194f",
   "metadata": {
    "papermill": {
     "duration": 0.011616,
     "end_time": "2025-04-07T22:59:55.507333",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.495717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Clase para estructura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4067aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class militarDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, labeled=True): \n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.labeled = labeled \n",
    "        print(f\"DEBUG militarDataset: Inicializado con {len(self.df)} filas. Transformaciones: {'Sí' if self.transform else 'No'}. Labeled: {self.labeled}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        if idx >= len(self.df):\n",
    "            print(f\"DEBUG militarDataset: Índice {idx} fuera de rango para DataFrame (len {len(self.df)}). Devolviendo None.\")\n",
    "            return None\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        img_filename = row.get('filename', f\"DESCONOCIDO_idx_{idx}\")\n",
    "        \n",
    "        try:\n",
    "            img_path = os.path.join(self.img_dir, img_filename)\n",
    "            if not osp.exists(img_path):\n",
    "                print(f\"DEBUG militarDataset: RUTA DE IMAGEN NO EXISTE {img_path} para {img_filename}. Saltando.\")\n",
    "                return None\n",
    "            pil_image = Image.open(img_path).convert('RGB')\n",
    "            numpy_image = np.array(pil_image)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"DEBUG militarDataset: FileNotFoundError para {img_path} ({img_filename}). Saltando.\")\n",
    "            return None\n",
    "        except UnidentifiedImageError:\n",
    "            print(f\"DEBUG militarDataset: UnidentifiedImageError para {img_path} ({img_filename}). Saltando.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"DEBUG militarDataset: Error cargando imagen {img_filename} ({img_path}): {e}. Saltando.\")\n",
    "            return None\n",
    "        \n",
    "        # --- SI ES PARA TEST (NO ETIQUETADO) ---\n",
    "        if not self.labeled:\n",
    "            sample_to_transform = {'image': numpy_image}\n",
    "            if self.transform:\n",
    "                try:\n",
    "                    transformed = self.transform(**sample_to_transform)\n",
    "                    image_tensor = transformed['image']\n",
    "                    return image_tensor # 📌 Devolver solo la imagen transformada\n",
    "                except Exception as e:\n",
    "                    print(f\"DEBUG militarDataset: Error aplicando transformación (test) para {img_filename} (idx {idx}): {e}. Saltando.\")\n",
    "                    return None\n",
    "            else: # Si no hay transformaciones (aunque para test deberías al menos tener Resize, Normalize, ToTensorV2)\n",
    "                return torch.from_numpy(numpy_image.transpose((2, 0, 1))).float().div(255.0)\n",
    "\n",
    "        # --- SI ES PARA ENTRENAMIENTO/VALIDACIÓN (ETIQUETADO) ---\n",
    "        try:\n",
    "            bbox_coords = row[['xmin', 'ymin', 'xmax', 'ymax']].values.astype(np.float32)\n",
    "            class_id_val = int(row['class_id'])\n",
    "        except KeyError as e:\n",
    "            print(f\"DEBUG militarDataset: Falta columna {e} para {img_filename} (idx {idx}) aunque labeled=True. Saltando.\")\n",
    "            return None\n",
    "        except ValueError as e:\n",
    "            print(f\"DEBUG militarDataset: Valor inválido en bbox o class_id para {img_filename} (idx {idx}): {e}. Saltando.\")\n",
    "            return None\n",
    "\n",
    "        \n",
    "        if not (0 <= class_id_val < NUM_CLASSES):\n",
    "            print(f\"DEBUG militarDataset: class_id {class_id_val} fuera de rango [0, {NUM_CLASSES-1}] para {img_filename} (idx {idx}). Saltando.\")\n",
    "            return None\n",
    "\n",
    "        sample_to_transform = {\n",
    "            'image': numpy_image,\n",
    "            'bboxes': [bbox_coords.tolist()], \n",
    "            'class_labels': [class_id_val] \n",
    "        }\n",
    "\n",
    "        image_tensor, class_id_tensor, bbox_tensor = None, None, None\n",
    "\n",
    "        if self.transform:\n",
    "            try:\n",
    "                transformed = self.transform(**sample_to_transform)\n",
    "                \n",
    "                img_from_transform = transformed.get('image')\n",
    "                bboxes_from_transform = transformed.get('bboxes')\n",
    "                class_labels_from_transform = transformed.get('class_labels')\n",
    "\n",
    "                if img_from_transform is None:\n",
    "                    print(f\"DEBUG militarDataset: 'image' es None post-transformación para {img_filename} (idx {idx}). Saltando.\")\n",
    "                    return None\n",
    "                image_tensor = img_from_transform\n",
    "\n",
    "                if bboxes_from_transform and len(bboxes_from_transform) > 0:\n",
    "                    current_bbox = bboxes_from_transform[0]\n",
    "                    if isinstance(current_bbox, (list, tuple, np.ndarray)) and len(current_bbox) == 4:\n",
    "                        bbox_tensor = torch.tensor(current_bbox, dtype=torch.float32).unsqueeze(0)\n",
    "                        \n",
    "                        if class_labels_from_transform and len(class_labels_from_transform) > 0:\n",
    "                            _class_id_item = class_labels_from_transform[0]\n",
    "                            if not (0 <= _class_id_item < NUM_CLASSES):\n",
    "                                print(f\"DEBUG militarDataset: class_id {_class_id_item} post-transform fuera de rango para {img_filename} (idx {idx}). Saltando.\")\n",
    "                                return None\n",
    "                            class_id_tensor = torch.tensor(_class_id_item, dtype=torch.long)\n",
    "                        else:\n",
    "                            print(f\"DEBUG militarDataset: class_labels perdidas post-transformación para {img_filename} (idx {idx}). Saltando.\")\n",
    "                            return None \n",
    "                    else:\n",
    "                        print(f\"DEBUG militarDataset: Formato de bbox inesperado para {img_filename} (idx {idx}) post-transformación. Saltando.\")\n",
    "                        return None\n",
    "                else: \n",
    "                    print(f\"DEBUG militarDataset: Bbox para {img_filename} (idx {idx}) removido o vacío post-transformación. Saltando.\")\n",
    "                    return None\n",
    "                \n",
    "                if not (isinstance(image_tensor, torch.Tensor) and \n",
    "                        isinstance(class_id_tensor, torch.Tensor) and \n",
    "                        isinstance(bbox_tensor, torch.Tensor)):\n",
    "                    print(f\"DEBUG militarDataset: Componente no es Tensor para {img_filename} (idx {idx}) post-transform. Saltando.\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"DEBUG militarDataset: Error aplicando/procesando transformación (train/val) para {img_filename} (idx {idx}): {e}. Saltando.\")\n",
    "                return None\n",
    "        else: \n",
    "            if not (0 <= class_id_val < NUM_CLASSES):\n",
    "                print(f\"DEBUG militarDataset: class_id {class_id_val} (sin transform) fuera de rango para {img_filename} (idx {idx}). Saltando.\")\n",
    "                return None\n",
    "            image_tensor = torch.from_numpy(numpy_image.transpose((2, 0, 1))).float().div(255.0)\n",
    "            bbox_tensor = torch.tensor(bbox_coords, dtype=torch.float32).unsqueeze(0)\n",
    "            class_id_tensor = torch.tensor(class_id_val, dtype=torch.long)\n",
    "        \n",
    "        return image_tensor, class_id_tensor, bbox_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7f2b4",
   "metadata": {
    "papermill": {
     "duration": 0.022342,
     "end_time": "2025-04-07T22:59:56.589719",
     "exception": false,
     "start_time": "2025-04-07T22:59:56.567377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalización (Ahora de los píxeles, es diferente a la normalización anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52a6a252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando medias de ImageNet: [0.485, 0.456, 0.406]\n",
      "Usando desviaciones estándar de ImageNet: [0.229, 0.224, 0.225]\n"
     ]
    }
   ],
   "source": [
    "# Definir medias y desviaciones estándar\n",
    "MEANS_IMAGENET = [0.485, 0.456, 0.406]\n",
    "STDS_IMAGENET = [0.229, 0.224, 0.225]\n",
    "print(f\"Usando medias de ImageNet: {MEANS_IMAGENET}\")\n",
    "print(f\"Usando desviaciones estándar de ImageNet: {STDS_IMAGENET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27d62a",
   "metadata": {
    "papermill": {
     "duration": 0.021929,
     "end_time": "2025-04-07T22:59:59.630713",
     "exception": false,
     "start_time": "2025-04-07T22:59:59.608784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18a80dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allc0363\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\albumentations\\core\\validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\allc0363\\AppData\\Local\\Temp\\ipykernel_34400\\3914898059.py:6: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
      "  A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT, value = 0),\n"
     ]
    }
   ],
   "source": [
    "train_transforms = A.Compose([\n",
    "    A.Resize(height=TARGET_H, width=TARGET_W),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2), \n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT, value = 0), \n",
    "    # A.CoarseDropout(max_holes=8, max_height=TARGET_H//10, max_width=TARGET_W//10, min_holes=1, min_height=TARGET_H//20, min_width=TARGET_W//20, fill_value=0, p=0.3),\n",
    "    # Normalización estándar de ResNet. max_pixel_value=255.0 asegura la división por 255.\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2() # Convierte imagen a tensor PyTorch (C, H, W). No afecta bboxes.\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels'], min_area=16, min_visibility=0.2)) # pascal_voc: [xmin, ymin, xmax, ymax]\n",
    "\n",
    "eval_transforms = A.Compose([\n",
    "    A.Resize(height=TARGET_H, width=TARGET_W),\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels'])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d857848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Definiendo transformaciones globales train_transforms y eval_transforms con pipeline MÍNIMO.\n",
      "DEBUG: Creando train_dataset y val_dataset GLOBALES con las transformaciones simplificadas.\n",
      "DEBUG militarDataset: Inicializado con 151 filas. Transformaciones: Sí. Labeled: True\n",
      "DEBUG: train_dataset global creado con 151 items.\n",
      "DEBUG militarDataset: Inicializado con 38 filas. Transformaciones: Sí. Labeled: True\n",
      "DEBUG: val_dataset global creado con 38 items.\n"
     ]
    }
   ],
   "source": [
    "# train_transforms y eval_transforms globales\n",
    "\n",
    "print(\"DEBUG: Definiendo transformaciones globales train_transforms y eval_transforms con pipeline MÍNIMO.\")\n",
    "\n",
    "# --- 📌 MODIFICACIÓN DRÁSTICA DE train_transforms (global) ---\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(height=TARGET_H, width=TARGET_W), # Necesario\n",
    "    # --- Temporalmente SIN otras aumentaciones ---\n",
    "    # A.HorizontalFlip(p=0.5),\n",
    "    # A.VerticalFlip(p=0.2),\n",
    "    # A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3), # Intensidad reducida\n",
    "    # A.ShiftScaleRotate(shift_limit=0.03, scale_limit=0.03, rotate_limit=10, p=0.3, \n",
    "    #                    border_mode=cv2.BORDER_CONSTANT), # 'value' eliminado o comentada la línea entera si da warning\n",
    "    \n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0), # Necesario\n",
    "    ToTensorV2() # Necesario\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', \n",
    "                             label_fields=['class_labels'], \n",
    "                             min_area=1,       # 📌 VALOR MÁS PERMISIVO POSIBLE\n",
    "                             min_visibility=0.0 # 📌 VALOR MÁS PERMISIVO POSIBLE\n",
    "                            ))\n",
    "\n",
    "\n",
    "eval_transforms = A.Compose([ \n",
    "    A.Resize(height=TARGET_H, width=TARGET_W),\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "\n",
    "print(\"DEBUG: Creando train_dataset y val_dataset GLOBALES con las transformaciones simplificadas.\")\n",
    "\n",
    "if 'train_df' in locals() and not train_df.empty: # Comprueba si train_df existe y no está vacío\n",
    "    train_dataset = militarDataset(df=train_df, img_dir=img_dir, transform=train_transforms)\n",
    "    print(f\"DEBUG: train_dataset global creado con {len(train_dataset)} items.\")\n",
    "else:\n",
    "    print(\"Advertencia: train_df global no está definido o está vacío. No se creó train_dataset global.\")\n",
    "    train_dataset = [] # o None\n",
    "\n",
    "if 'val_df' in locals() and not val_df.empty: # Comprueba si val_df existe y no está vacío\n",
    "    val_dataset = militarDataset(df=val_df, img_dir=img_dir, transform=eval_transforms)\n",
    "    print(f\"DEBUG: val_dataset global creado con {len(val_dataset)} items.\")\n",
    "else:\n",
    "    print(\"Advertencia: val_df global no está definido o está vacío. No se creó val_dataset global.\")\n",
    "    val_dataset = [] # o None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4191b",
   "metadata": {
    "papermill": {
     "duration": 0.021938,
     "end_time": "2025-04-07T23:00:00.139010",
     "exception": false,
     "start_time": "2025-04-07T23:00:00.117072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0aee77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50MultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_classes=6, dropout=0.5, freeze_backbone=True, use_deeper_bbox_head=False): # Nuevo argumento\n",
    "        super(ResNet50MultiTaskModel, self).__init__()\n",
    "\n",
    "        # Cargar el modelo base ResNet50 pre-entrenado\n",
    "        base_model = resnet50(weights=ResNet50_Weights.DEFAULT) #\n",
    "\n",
    "        # Congelar los pesos del backbone si se especifica\n",
    "        if freeze_backbone: #\n",
    "            for param in base_model.parameters(): #\n",
    "                param.requires_grad = False #\n",
    "\n",
    "        # Extractor de características (todas las capas de ResNet excepto avgpool y fc)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2]) #\n",
    "        \n",
    "        # Pooling adaptativo para obtener un tamaño de salida fijo\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1)) #\n",
    "        \n",
    "        # Capa para aplanar las características\n",
    "        self.flatten = nn.Flatten() #\n",
    "\n",
    "        # --- Cabeza de Clasificación ---\n",
    "        self.classification_dropout = nn.Dropout(dropout) #\n",
    "        # La capa de entrada para el clasificador es 2048 (salida de ResNet50 antes de avgpool)\n",
    "        self.classifier = nn.Linear(base_model.fc.in_features, num_classes) #\n",
    "\n",
    "        # --- Cabeza de Regresión de Bounding Box ---\n",
    "        self.bbox_dropout = nn.Dropout(dropout) #\n",
    "        \n",
    "        if use_deeper_bbox_head:\n",
    "            print(\"Usando cabeza de regresión de BBox más profunda.\")\n",
    "            self.bbox_regressor = nn.Sequential(\n",
    "                nn.Linear(base_model.fc.in_features, 1024), # base_model.fc.in_features es 2048\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout), # Dropout adicional dentro de la cabeza\n",
    "                nn.Linear(1024, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 4) # Salida de 4 coordenadas para el bbox\n",
    "            )\n",
    "            # Inicialización de pesos para la cabeza más profunda (opcional pero puede ayudar)\n",
    "            for m in self.bbox_regressor.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.zeros_(m.bias)\n",
    "        else:\n",
    "            print(\"Usando cabeza de regresión de BBox simple (Linear).\")\n",
    "            self.bbox_regressor = nn.Linear(base_model.fc.in_features, 4) #\n",
    "            # Inicialización de pesos para la cabeza simple (opcional)\n",
    "            nn.init.xavier_uniform_(self.bbox_regressor.weight)\n",
    "            # if self.bbox_regressor.bias is not None:\n",
    "            #     nn.init.zeros_(self.bbox_regressor.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        features = self.feature_extractor(x) #\n",
    "        pooled_features = self.pooling(features) #\n",
    "        flattened_features = self.flatten(pooled_features) #\n",
    "\n",
    "        # Clasificación\n",
    "        class_features_dropout = self.classification_dropout(flattened_features) #\n",
    "        class_output = self.classifier(class_features_dropout) #\n",
    "\n",
    "        # Regresión de Bounding Box\n",
    "        bbox_features_dropout = self.bbox_dropout(flattened_features) #\n",
    "        bbox_output = self.bbox_regressor(bbox_features_dropout) #\n",
    "        \n",
    "        return class_output, bbox_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734b8f7",
   "metadata": {
    "papermill": {
     "duration": 0.033065,
     "end_time": "2025-04-07T23:00:04.930437",
     "exception": false,
     "start_time": "2025-04-07T23:00:04.897372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3f18cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_bbox: torch.Tensor, y_pred_bbox: torch.Tensor, apply_sigmoid_to_pred=False):\n",
    "    \n",
    "    if y_true_bbox.device != y_pred_bbox.device:\n",
    "        y_true_bbox = y_true_bbox.to(y_pred_bbox.device)\n",
    "    if apply_sigmoid_to_pred:\n",
    "         y_pred_bbox = torch.sigmoid(y_pred_bbox)\n",
    "    if y_true_bbox.ndim == 3 and y_true_bbox.shape[1] == 1:\n",
    "        y_true_bbox = y_true_bbox.squeeze(1)\n",
    "    if y_pred_bbox.ndim == 3 and y_pred_bbox.shape[1] == 1:\n",
    "        y_pred_bbox = y_pred_bbox.squeeze(1)\n",
    "    if y_true_bbox.shape[0] == 0 or y_pred_bbox.shape[0] == 0:\n",
    "        return torch.tensor(0.0, device=y_pred_bbox.device)\n",
    "    pairwise_iou_matrix = box_iou(y_true_bbox, y_pred_bbox)\n",
    "    if pairwise_iou_matrix.shape[0] == pairwise_iou_matrix.shape[1]:\n",
    "        return torch.diag(pairwise_iou_matrix).mean()\n",
    "    elif pairwise_iou_matrix.numel() > 0:\n",
    "        return pairwise_iou_matrix.mean()\n",
    "    else:\n",
    "        return torch.tensor(0.0, device=y_pred_bbox.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10fb7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(y_pred_class: torch.Tensor, y_true_class: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Calcula la precisión de la clasificación.\n",
    "\n",
    "    Args:\n",
    "        y_pred_class (torch.Tensor): Logits o probabilidades predichas por el modelo.\n",
    "                                     Shape: (batch_size, num_classes)\n",
    "        y_true_class (torch.Tensor): Etiquetas de clase verdaderas.\n",
    "                                     Shape: (batch_size,) o (batch_size, 1)\n",
    "    Returns:\n",
    "        torch.Tensor: Precisión.\n",
    "    \"\"\"\n",
    "    # Obtener las clases predichas tomando el argmax\n",
    "    pred_labels = torch.argmax(y_pred_class, dim=1)\n",
    "\n",
    "    # Asegurar que y_true_class tenga la misma forma que pred_labels\n",
    "    if y_true_class.ndim == 2 and y_true_class.shape[1] == 1:\n",
    "        y_true_class = y_true_class.squeeze(1)\n",
    "\n",
    "    # Comparar con las etiquetas verdaderas\n",
    "    correct = torch.eq(pred_labels, y_true_class).float() # Convertir a float para la suma\n",
    "    total = torch.ones_like(correct) # Un tensor de unos con la misma forma\n",
    "\n",
    "    # Calcular la precisión\n",
    "    acc = torch.sum(correct) / torch.sum(total) \n",
    "    # result = torch.divide(torch.sum(correct), torch.sum(total)) \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2384060b",
   "metadata": {
    "papermill": {
     "duration": 0.023501,
     "end_time": "2025-04-07T23:00:05.088388",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.064887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c9610d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:05.136026Z",
     "iopub.status.busy": "2025-04-07T23:00:05.135732Z",
     "iopub.status.idle": "2025-04-07T23:00:05.140464Z",
     "shell.execute_reply": "2025-04-07T23:00:05.139643Z"
    },
    "papermill": {
     "duration": 0.030006,
     "end_time": "2025-04-07T23:00:05.141652",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.111646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn_multitask(class_preds: torch.Tensor, bbox_preds: torch.Tensor,\n",
    "                      true_classes: torch.Tensor, true_bboxes: torch.Tensor,\n",
    "                      alpha: float = 0.5):\n",
    "    \"\"\"\n",
    "    Calcula la pérdida combinada para clasificación y regresión de bounding box.\n",
    "\n",
    "    Args:\n",
    "        class_preds (torch.Tensor): Predicciones de clase del modelo (logits).\n",
    "                                     Shape: (batch_size, num_classes)\n",
    "        bbox_preds (torch.Tensor): Predicciones de bounding box del modelo.\n",
    "                                   Shape: (batch_size, 4)\n",
    "        true_classes (torch.Tensor): Etiquetas de clase verdaderas.\n",
    "                                     Shape: (batch_size,) o (batch_size, 1) - deben ser long ints.\n",
    "        true_bboxes (torch.Tensor): Coordenadas de bounding box verdaderas.\n",
    "                                    Shape: (batch_size, 4)\n",
    "        alpha (float): Peso para balancear la pérdida de regresión.\n",
    "                       total_loss = (1-alpha)*cls_loss + alpha*reg_loss\n",
    "    Returns:\n",
    "        dict: Un diccionario con 'total_loss', 'cls_loss', 'reg_loss'.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que true_classes tenga el tipo de dato correcto para CrossEntropyLoss\n",
    "    true_classes = true_classes.long()\n",
    "    if true_classes.ndim == 2 and true_classes.shape[1] == 1:\n",
    "        true_classes = true_classes.squeeze(1) # (batch_size, 1) -> (batch_size,)\n",
    "\n",
    "    # Pérdida de Clasificación\n",
    "    # class_preds son logits, true_classes son índices de clase\n",
    "    cls_loss = F.cross_entropy(class_preds, true_classes)\n",
    "\n",
    "    # Pérdida de Regresión para Bounding Box\n",
    "    # bbox_preds y true_bboxes deben tener la misma forma [N, 4]\n",
    "    reg_loss = F.mse_loss(bbox_preds, true_bboxes)\n",
    "    # Alternativa: reg_loss = F.l1_loss(bbox_preds, true_bboxes)\n",
    "\n",
    "    # Pérdida Total Combinada\n",
    "    total_loss = (1 - alpha) * cls_loss + alpha * reg_loss\n",
    "\n",
    "    return {\n",
    "        'total_loss': total_loss,\n",
    "        'reg_loss': reg_loss,\n",
    "        'cls_loss': cls_loss\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31423eb",
   "metadata": {
    "papermill": {
     "duration": 0.023293,
     "end_time": "2025-04-07T23:00:05.188467",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.165174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85e5a0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:05.236504Z",
     "iopub.status.busy": "2025-04-07T23:00:05.236170Z",
     "iopub.status.idle": "2025-04-07T23:00:05.241135Z",
     "shell.execute_reply": "2025-04-07T23:00:05.240248Z"
    },
    "papermill": {
     "duration": 0.030676,
     "end_time": "2025-04-07T23:00:05.242576",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.211900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def printer_callback(logs: dict): # ty.Dict[str, ty.Any] si usas type hints\n",
    "    \"\"\"\n",
    "    Imprime los logs del entrenamiento.\n",
    "    \"\"\"\n",
    "    # print every 10 steps - asumiendo que 'iters' está en logs\n",
    "    if 'iters' in logs and logs['iters'] % 10 != 0: # Cambié == a != para imprimir cada 10\n",
    "        if logs['iters'] != 1: # Imprimir siempre la primera iteración\n",
    "            return\n",
    "\n",
    "    print(f\"Iteración #: {logs.get('iters', 'N/A')}\") # Usar .get para evitar KeyError\n",
    "    for name, value in logs.items():\n",
    "        if name == 'iters':\n",
    "            continue\n",
    "\n",
    "        if isinstance(value, (float, int)): # type(value) in [float, int] es menos idiomático\n",
    "            value_str = f\"{value:.4f}\" if isinstance(value, float) else str(value)\n",
    "        elif isinstance(value, torch.Tensor):\n",
    "            # value_str = f\"{value.item():.4f}\" if value.numel() == 1 else str(value)\n",
    "            value_str = f\"{torch.round(value, decimals=4).item() if value.numel() == 1 else str(value.round(decimals=4))}\"\n",
    "        else:\n",
    "            value_str = str(value)\n",
    "        print(f\"\\t{name} = {value_str}\")\n",
    "    print(\"-\" * 30) # Separador\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd653d",
   "metadata": {
    "papermill": {
     "duration": 0.02323,
     "end_time": "2025-04-07T23:00:05.289353",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.266123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ce5d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time # Para medir la duración de las épocas\n",
    "import copy # Para guardar el mejor estado del modelo\n",
    "import os   # Para la modificación de guardado del modelo\n",
    "\n",
    "\n",
    "def train_multitask_model(\n",
    "    model, train_loader, val_loader, classification_criterion, bbox_criterion,\n",
    "    optimizer, device, num_epochs=30, bbox_loss_weight=1.0, patience=5,\n",
    "    model_save_path=\"best_multitask_model.pth\", apply_sigmoid_to_bbox_pred=False,\n",
    "    scheduler=None # \n",
    "):\n",
    "    # reset_seed(42) # Puedes llamarlo fuera o dentro si quieres resetear en cada llamada.\n",
    "\n",
    "    history = {\n",
    "        'train_loss_cls': [], 'train_loss_bbox': [], 'train_loss_total': [],\n",
    "        'train_acc': [], 'train_iou': [],\n",
    "        'val_loss_cls': [], 'val_loss_bbox': [], 'val_loss_total': [],\n",
    "        'val_acc': [], 'val_iou': []\n",
    "    }\n",
    "\n",
    "    best_val_loss_total = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    print(f\"Iniciando entrenamiento por {num_epochs} épocas en dispositivo: {device}.\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # --- Fase de Entrenamiento ---\n",
    "        model.train()\n",
    "        running_train_loss_cls = 0.0\n",
    "        running_train_loss_bbox = 0.0\n",
    "        running_train_loss_total = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_samples = 0\n",
    "        sum_train_iou = 0.0 # Acumulador para la suma de IoUs (no promediado aún)\n",
    "        num_train_batches_with_iou = 0 # Contador para batches donde se calculó IoU\n",
    "\n",
    "        for batch_idx, batch_data in enumerate(train_loader):\n",
    "            if batch_data is None:\n",
    "                continue \n",
    "            \n",
    "            images, class_labels, bbox_labels_raw = batch_data\n",
    "            \n",
    "            images = images.to(device)\n",
    "            class_labels = class_labels.to(device).long()\n",
    "            \n",
    "            if bbox_labels_raw.ndim == 3 and bbox_labels_raw.shape[1] == 1:\n",
    "                 bbox_labels = bbox_labels_raw.to(device).float().squeeze(1)\n",
    "            elif bbox_labels_raw.ndim == 2 and bbox_labels_raw.shape[-1] == 4:\n",
    "                 bbox_labels = bbox_labels_raw.to(device).float()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            class_logits, bbox_preds_raw = model(images)\n",
    "\n",
    "            bbox_preds = torch.sigmoid(bbox_preds_raw) if apply_sigmoid_to_bbox_pred else bbox_preds_raw\n",
    "            \n",
    "            loss_cls = classification_criterion(class_logits, class_labels)\n",
    "            loss_bbox = bbox_criterion(bbox_preds, bbox_labels) \n",
    "            total_loss = loss_cls + bbox_loss_weight * loss_bbox\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = images.size(0) # Usar images.size(0) para el tamaño real del batch\n",
    "            running_train_loss_cls += loss_cls.item() * batch_size\n",
    "            running_train_loss_bbox += loss_bbox.item() * batch_size\n",
    "            running_train_loss_total += total_loss.item() * batch_size\n",
    "\n",
    "            _, predicted_classes = torch.max(class_logits, 1)\n",
    "            correct_train_preds += (predicted_classes == class_labels).sum().item()\n",
    "            total_train_samples += batch_size \n",
    "            \n",
    "            # Calcula IoU solo si hay bboxes válidos en el batch para evitar errores\n",
    "            if bbox_labels.numel() > 0 and bbox_preds.numel() > 0:\n",
    "                 # iou_metric debería devolver la suma de IoUs para el batch o el IoU promedio del batch\n",
    "                 # Si devuelve la suma de IoUs, está bien. Si devuelve el promedio, multiplica por batch_size.\n",
    "                 # Asumamos que iou_metric devuelve el IoU promedio del batch.\n",
    "                iou_batch_avg = iou_metric(bbox_labels.detach(), bbox_preds.detach(), apply_sigmoid_to_pred=False)\n",
    "                if torch.is_tensor(iou_batch_avg) and iou_batch_avg.numel() == 1 : # Asegurarse que es un escalar\n",
    "                    sum_train_iou += iou_batch_avg.item() * batch_size\n",
    "                    num_train_batches_with_iou += batch_size # o simplemente num_train_batches_with_iou += 1 si iou_metric devuelve suma\n",
    "                # else:\n",
    "                    # print(f\"Advertencia: iou_metric devolvió un valor inesperado: {iou_batch_avg}\")\n",
    "\n",
    "        print(f\"DEBUG train_multitask_model: Epoch {epoch+1}, total_train_samples procesadas esta época: {total_train_samples}\")\n",
    "\n",
    "        epoch_train_loss_cls = running_train_loss_cls / total_train_samples if total_train_samples > 0 else 0.0\n",
    "        epoch_train_loss_bbox = running_train_loss_bbox / total_train_samples if total_train_samples > 0 else 0.0\n",
    "        epoch_train_loss_total = running_train_loss_total / total_train_samples if total_train_samples > 0 else 0.0\n",
    "        epoch_train_acc = correct_train_preds / total_train_samples if total_train_samples > 0 else 0.0\n",
    "        # epoch_train_iou = sum_train_iou / num_train_batches_with_iou if num_train_batches_with_iou > 0 else 0.0 # Si iou_metric devuelve promedio y contamos batches\n",
    "        epoch_train_iou = sum_train_iou / total_train_samples if total_train_samples > 0 else 0.0 # Si iou_metric devuelve promedio y sum_train_iou acumula (promedio*tamaño_batch)\n",
    "\n",
    "\n",
    "        history['train_loss_cls'].append(epoch_train_loss_cls)\n",
    "        history['train_loss_bbox'].append(epoch_train_loss_bbox)\n",
    "        history['train_loss_total'].append(epoch_train_loss_total)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['train_iou'].append(epoch_train_iou)\n",
    "\n",
    "        # --- Fase de Validación ---\n",
    "        model.eval()\n",
    "        running_val_loss_cls = 0.0\n",
    "        running_val_loss_bbox = 0.0\n",
    "        running_val_loss_total = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_samples_val = 0\n",
    "        sum_val_iou = 0.0 # Acumulador para la suma de IoUs\n",
    "        num_val_batches_with_iou = 0 # Contador para batches donde se calculó IoU\n",
    "        current_epoch_val_loss_total = float('inf')\n",
    "\n",
    "        if val_loader is not None and len(val_loader) > 0:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx_val, batch_data_val in enumerate(val_loader):\n",
    "                    if batch_data_val is None:\n",
    "                        continue\n",
    "                    \n",
    "                    images_val, class_labels_val, bbox_labels_raw_val = batch_data_val\n",
    "\n",
    "                    images_val = images_val.to(device)\n",
    "                    class_labels_val = class_labels_val.to(device).long()\n",
    "\n",
    "                    if bbox_labels_raw_val.ndim == 3 and bbox_labels_raw_val.shape[1] == 1:\n",
    "                        bbox_labels_val = bbox_labels_raw_val.to(device).float().squeeze(1)\n",
    "                    elif bbox_labels_raw_val.ndim == 2 and bbox_labels_raw_val.shape[-1] == 4:\n",
    "                        bbox_labels_val = bbox_labels_raw_val.to(device).float()\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    class_logits_val, bbox_preds_raw_val = model(images_val)\n",
    "                    bbox_preds_val = torch.sigmoid(bbox_preds_raw_val) if apply_sigmoid_to_bbox_pred else bbox_preds_raw_val\n",
    "\n",
    "                    loss_cls_val = classification_criterion(class_logits_val, class_labels_val)\n",
    "                    loss_bbox_val = bbox_criterion(bbox_preds_val, bbox_labels_val)\n",
    "                    total_loss_val = loss_cls_val + bbox_loss_weight * loss_bbox_val\n",
    "                    \n",
    "                    batch_size_val = images_val.size(0)\n",
    "                    running_val_loss_cls += loss_cls_val.item() * batch_size_val\n",
    "                    running_val_loss_bbox += loss_bbox_val.item() * batch_size_val\n",
    "                    running_val_loss_total += total_loss_val.item() * batch_size_val\n",
    "\n",
    "                    _, predicted_classes_val = torch.max(class_logits_val, 1)\n",
    "                    correct_val_preds += (predicted_classes_val == class_labels_val).sum().item()\n",
    "                    total_val_samples_val += batch_size_val\n",
    "                    \n",
    "                    if bbox_labels_val.numel() > 0 and bbox_preds_val.numel() > 0:\n",
    "                        iou_batch_avg_val = iou_metric(bbox_labels_val.detach(), bbox_preds_val.detach(), apply_sigmoid_to_pred=False)\n",
    "                        if torch.is_tensor(iou_batch_avg_val) and iou_batch_avg_val.numel() == 1:\n",
    "                            sum_val_iou += iou_batch_avg_val.item() * batch_size_val\n",
    "                            num_val_batches_with_iou += batch_size_val\n",
    "            \n",
    "            epoch_val_loss_cls = running_val_loss_cls / total_val_samples_val if total_val_samples_val > 0 else 0.0\n",
    "            epoch_val_loss_bbox = running_val_loss_bbox / total_val_samples_val if total_val_samples_val > 0 else 0.0\n",
    "            current_epoch_val_loss_total = running_val_loss_total / total_val_samples_val if total_val_samples_val > 0 else float('inf')\n",
    "            epoch_val_acc = correct_val_preds / total_val_samples_val if total_val_samples_val > 0 else 0.0\n",
    "            # epoch_val_iou = sum_val_iou / num_val_batches_with_iou if num_val_batches_with_iou > 0 else 0.0\n",
    "            epoch_val_iou = sum_val_iou / total_val_samples_val if total_val_samples_val > 0 else 0.0\n",
    "\n",
    "\n",
    "        else: \n",
    "            epoch_val_loss_cls, epoch_val_loss_bbox = 0.0, 0.0\n",
    "            current_epoch_val_loss_total = float('inf') \n",
    "            epoch_val_acc, epoch_val_iou = 0.0, 0.0\n",
    "            total_val_samples_val = 0\n",
    "\n",
    "        history['val_loss_cls'].append(epoch_val_loss_cls)\n",
    "        history['val_loss_bbox'].append(epoch_val_loss_bbox)\n",
    "        history['val_loss_total'].append(current_epoch_val_loss_total)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        history['val_iou'].append(epoch_val_iou)\n",
    "\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} Duración: {epoch_duration:.2f}s\")\n",
    "        print(f\"  Train: LossCls={epoch_train_loss_cls:.4f}, LossBbox={epoch_train_loss_bbox:.4f}, Total={epoch_train_loss_total:.4f}, Acc={epoch_train_acc:.4f}, IoU={epoch_train_iou:.4f}\")\n",
    "        \n",
    "        if total_val_samples_val > 0:\n",
    "            print(f\"  Valid: LossCls={epoch_val_loss_cls:.4f}, LossBbox={epoch_val_loss_bbox:.4f}, Total={current_epoch_val_loss_total:.4f}, Acc={epoch_val_acc:.4f}, IoU={epoch_val_iou:.4f}\")\n",
    "        else:\n",
    "            print(\"  Valid: No hay datos de validación para esta época.\")\n",
    "\n",
    "        # 📌 Lógica de Scheduler (si se proporciona)\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                if total_val_samples_val > 0: \n",
    "                    scheduler.step(current_epoch_val_loss_total) # 📌 LLAMADA AL SCHEDULER\n",
    "                # else: Opcionalmente, si no hay validación, no hacer step o basarse en train_loss\n",
    "            else: # Para otros schedulers que hacen step por época sin argumentos\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Opcional: imprimir la tasa de aprendizaje actual\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"  Current LR: {current_lr:.1e}\")\n",
    "\n",
    "\n",
    "        # Lógica de Early Stopping y guardado del mejor modelo\n",
    "        if total_val_samples_val > 0: \n",
    "            if current_epoch_val_loss_total < best_val_loss_total:\n",
    "                best_val_loss_total = current_epoch_val_loss_total\n",
    "                if model is not None:\n",
    "                    best_model_state = copy.deepcopy(model.state_dict())\n",
    "                    try:\n",
    "                        torch.save(best_model_state, model_save_path)\n",
    "                        print(f\"  Mejor modelo guardado en '{model_save_path}' con val_loss_total: {best_val_loss_total:.4f}\")\n",
    "                    except Exception as e_save:\n",
    "                        print(f\"ERROR AL INTENTAR GUARDAR EL MODELO en '{model_save_path}': {e_save}\")\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                print(f\"  Val_loss_total no mejoró. Paciencia: {epochs_no_improve}/{patience}\")\n",
    "            \n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping activado después de {epoch+1} épocas.\")\n",
    "                break\n",
    "        elif epoch == 0 and best_model_state is None : \n",
    "             if model is not None:\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                try:\n",
    "                    torch.save(best_model_state, model_save_path)\n",
    "                    print(f\"  Modelo de la primera época guardado (sin validación activa) en '{model_save_path}'\")\n",
    "                except Exception as e_save:\n",
    "                    print(f\"ERROR AL INTENTAR GUARDAR EL MODELO (primera época sin val) en '{model_save_path}': {e_save}\")\n",
    "\n",
    "    if best_model_state:\n",
    "        print(\"Cargando el mejor estado del modelo guardado al final del entrenamiento.\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "    else:\n",
    "        print(\"No se guardó ningún 'mejor modelo'. El modelo tiene los pesos de la última época entrenada.\")\n",
    "    \n",
    "    print(\"Entrenamiento finalizado.\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f17c1a",
   "metadata": {
    "papermill": {
     "duration": 0.024267,
     "end_time": "2025-04-07T23:00:05.397282",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.373015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0af4a9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los resultados se guardarán en el directorio: c:\\Users\\allc0363\\OneDrive\\MCD - Icesi\\Semestre 2\\Fundamentos 2\\Taller 1\\FAII_TALLER1\\Notebooks\\Resultados\n",
      "Cargando y preprocesando el DataFrame...\n",
      "Bounding boxes en el script de Run normalizados y acotados a [0,1].\n",
      "DEBUG: Longitud de df_run: 189\n",
      "DEBUG: Longitud de train_df_run: 151\n",
      "Usando medias de ImageNet para el script de Run: [0.485, 0.456, 0.406]\n",
      "Usando desviaciones estándar de ImageNet para el script de Run: [0.229, 0.224, 0.225]\n",
      "DEBUG: Usando pipeline de transformación de entrenamiento MÍNIMO con BboxParams por DEFECTO.\n",
      "Creando Datasets y DataLoaders finales para el script de Run...\n",
      "DEBUG militarDataset: Inicializado con 151 filas. Transformaciones: Sí. Labeled: True\n",
      "DEBUG militarDataset: Inicializado con 38 filas. Transformaciones: Sí. Labeled: True\n",
      "\n",
      "DEBUG: Inspeccionando las primeras (hasta) 5 muestras de train_dataset_run (longitud total: 151):\n",
      "DEBUG: De las primeras muestras inspeccionadas, 5 fueron válidas.\n",
      "\n",
      "Usando dispositivo para el script de Run: cuda\n",
      "Usando cabeza de regresión de BBox simple (Linear).\n",
      "Usando cabeza de regresión de BBox MÁS PROFUNDA.\n",
      "DEBUG: El modelo se guardará en la ruta absoluta: ./Resultados/pretrained_model_20250525_201424.pth\n",
      "Iniciando el proceso de entrenamiento del script de Run...\n",
      "APPLY_SIGMOID_TO_BBOX_PRED para el script de Run está configurado a: True\n",
      "Iniciando entrenamiento por 120 épocas en dispositivo: cuda.\n",
      "DEBUG train_multitask_model: Epoch 1, total_train_samples procesadas esta época: 151\n",
      "Epoch 1/120 Duración: 2.51s\n",
      "  Train: LossCls=1.7735, LossBbox=0.0592, Total=2.9573, Acc=0.2252, IoU=0.0000\n",
      "  Valid: LossCls=1.6751, LossBbox=0.0226, Total=2.1280, Acc=0.3684, IoU=0.0000\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 2.1280\n",
      "DEBUG train_multitask_model: Epoch 2, total_train_samples procesadas esta época: 151\n",
      "Epoch 2/120 Duración: 2.28s\n",
      "  Train: LossCls=1.5967, LossBbox=0.0194, Total=1.9853, Acc=0.4570, IoU=0.0012\n",
      "  Valid: LossCls=1.5512, LossBbox=0.0059, Total=1.6687, Acc=0.4474, IoU=0.0076\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.6687\n",
      "DEBUG train_multitask_model: Epoch 3, total_train_samples procesadas esta época: 151\n",
      "Epoch 3/120 Duración: 2.36s\n",
      "  Train: LossCls=1.4746, LossBbox=0.0069, Total=1.6120, Acc=0.5762, IoU=0.0025\n",
      "  Valid: LossCls=1.4412, LossBbox=0.0023, Total=1.4870, Acc=0.5263, IoU=0.0110\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.4870\n",
      "DEBUG train_multitask_model: Epoch 4, total_train_samples procesadas esta época: 151\n",
      "Epoch 4/120 Duración: 2.30s\n",
      "  Train: LossCls=1.3538, LossBbox=0.0033, Total=1.4202, Acc=0.6291, IoU=0.0233\n",
      "  Valid: LossCls=1.3504, LossBbox=0.0019, Total=1.3875, Acc=0.6053, IoU=0.0226\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.3875\n",
      "DEBUG train_multitask_model: Epoch 5, total_train_samples procesadas esta época: 151\n",
      "Epoch 5/120 Duración: 2.26s\n",
      "  Train: LossCls=1.2279, LossBbox=0.0033, Total=1.2933, Acc=0.7616, IoU=0.0292\n",
      "  Valid: LossCls=1.2741, LossBbox=0.0019, Total=1.3124, Acc=0.6316, IoU=0.0318\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.3124\n",
      "DEBUG train_multitask_model: Epoch 6, total_train_samples procesadas esta época: 151\n",
      "Epoch 6/120 Duración: 2.27s\n",
      "  Train: LossCls=1.1323, LossBbox=0.0029, Total=1.1905, Acc=0.8278, IoU=0.0190\n",
      "  Valid: LossCls=1.1998, LossBbox=0.0020, Total=1.2403, Acc=0.6579, IoU=0.0386\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.2403\n",
      "DEBUG train_multitask_model: Epoch 7, total_train_samples procesadas esta época: 151\n",
      "Epoch 7/120 Duración: 2.41s\n",
      "  Train: LossCls=1.0574, LossBbox=0.0029, Total=1.1155, Acc=0.8344, IoU=0.0309\n",
      "  Valid: LossCls=1.1315, LossBbox=0.0021, Total=1.1727, Acc=0.7632, IoU=0.0552\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.1727\n",
      "DEBUG train_multitask_model: Epoch 8, total_train_samples procesadas esta época: 151\n",
      "Epoch 8/120 Duración: 2.31s\n",
      "  Train: LossCls=0.9719, LossBbox=0.0028, Total=1.0272, Acc=0.8874, IoU=0.0359\n",
      "  Valid: LossCls=1.0753, LossBbox=0.0019, Total=1.1138, Acc=0.7895, IoU=0.0743\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.1138\n",
      "DEBUG train_multitask_model: Epoch 9, total_train_samples procesadas esta época: 151\n",
      "Epoch 9/120 Duración: 2.47s\n",
      "  Train: LossCls=0.9020, LossBbox=0.0028, Total=0.9570, Acc=0.9073, IoU=0.0497\n",
      "  Valid: LossCls=1.0249, LossBbox=0.0018, Total=1.0605, Acc=0.7895, IoU=0.0835\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.0605\n",
      "DEBUG train_multitask_model: Epoch 10, total_train_samples procesadas esta época: 151\n",
      "Epoch 10/120 Duración: 2.42s\n",
      "  Train: LossCls=0.8410, LossBbox=0.0029, Total=0.8985, Acc=0.9139, IoU=0.0589\n",
      "  Valid: LossCls=0.9741, LossBbox=0.0017, Total=1.0072, Acc=0.8158, IoU=0.0921\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.0072\n",
      "DEBUG train_multitask_model: Epoch 11, total_train_samples procesadas esta época: 151\n",
      "Epoch 11/120 Duración: 2.43s\n",
      "  Train: LossCls=0.8116, LossBbox=0.0023, Total=0.8582, Acc=0.9404, IoU=0.0756\n",
      "  Valid: LossCls=0.9395, LossBbox=0.0015, Total=0.9701, Acc=0.8158, IoU=0.1081\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.9701\n",
      "DEBUG train_multitask_model: Epoch 12, total_train_samples procesadas esta época: 151\n",
      "Epoch 12/120 Duración: 2.29s\n",
      "  Train: LossCls=0.7461, LossBbox=0.0023, Total=0.7926, Acc=0.9338, IoU=0.0839\n",
      "  Valid: LossCls=0.9057, LossBbox=0.0015, Total=0.9356, Acc=0.8421, IoU=0.1209\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.9356\n",
      "DEBUG train_multitask_model: Epoch 13, total_train_samples procesadas esta época: 151\n",
      "Epoch 13/120 Duración: 2.25s\n",
      "  Train: LossCls=0.6719, LossBbox=0.0023, Total=0.7176, Acc=0.9338, IoU=0.1018\n",
      "  Valid: LossCls=0.8744, LossBbox=0.0015, Total=0.9034, Acc=0.8158, IoU=0.1325\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.9034\n",
      "DEBUG train_multitask_model: Epoch 14, total_train_samples procesadas esta época: 151\n",
      "Epoch 14/120 Duración: 2.32s\n",
      "  Train: LossCls=0.6467, LossBbox=0.0023, Total=0.6924, Acc=0.9338, IoU=0.1091\n",
      "  Valid: LossCls=0.8440, LossBbox=0.0014, Total=0.8721, Acc=0.8421, IoU=0.1451\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.8721\n",
      "DEBUG train_multitask_model: Epoch 15, total_train_samples procesadas esta época: 151\n",
      "Epoch 15/120 Duración: 2.25s\n",
      "  Train: LossCls=0.6159, LossBbox=0.0021, Total=0.6573, Acc=0.9338, IoU=0.1356\n",
      "  Valid: LossCls=0.8161, LossBbox=0.0014, Total=0.8436, Acc=0.8421, IoU=0.1525\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.8436\n",
      "DEBUG train_multitask_model: Epoch 16, total_train_samples procesadas esta época: 151\n",
      "Epoch 16/120 Duración: 2.26s\n",
      "  Train: LossCls=0.5668, LossBbox=0.0020, Total=0.6073, Acc=0.9536, IoU=0.1258\n",
      "  Valid: LossCls=0.7864, LossBbox=0.0014, Total=0.8136, Acc=0.8421, IoU=0.1532\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.8136\n",
      "DEBUG train_multitask_model: Epoch 17, total_train_samples procesadas esta época: 151\n",
      "Epoch 17/120 Duración: 2.25s\n",
      "  Train: LossCls=0.5610, LossBbox=0.0019, Total=0.5985, Acc=0.9338, IoU=0.1509\n",
      "  Valid: LossCls=0.7658, LossBbox=0.0013, Total=0.7924, Acc=0.8421, IoU=0.1558\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7924\n",
      "DEBUG train_multitask_model: Epoch 18, total_train_samples procesadas esta época: 151\n",
      "Epoch 18/120 Duración: 2.22s\n",
      "  Train: LossCls=0.5368, LossBbox=0.0019, Total=0.5753, Acc=0.9470, IoU=0.1578\n",
      "  Valid: LossCls=0.7434, LossBbox=0.0013, Total=0.7688, Acc=0.8421, IoU=0.1590\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7688\n",
      "DEBUG train_multitask_model: Epoch 19, total_train_samples procesadas esta época: 151\n",
      "Epoch 19/120 Duración: 2.27s\n",
      "  Train: LossCls=0.5262, LossBbox=0.0020, Total=0.5655, Acc=0.9404, IoU=0.1404\n",
      "  Valid: LossCls=0.7270, LossBbox=0.0012, Total=0.7516, Acc=0.8684, IoU=0.1629\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7516\n",
      "DEBUG train_multitask_model: Epoch 20, total_train_samples procesadas esta época: 151\n",
      "Epoch 20/120 Duración: 2.27s\n",
      "  Train: LossCls=0.4621, LossBbox=0.0019, Total=0.5010, Acc=0.9669, IoU=0.1570\n",
      "  Valid: LossCls=0.7078, LossBbox=0.0012, Total=0.7321, Acc=0.8684, IoU=0.1653\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7321\n",
      "DEBUG train_multitask_model: Epoch 21, total_train_samples procesadas esta época: 151\n",
      "Epoch 21/120 Duración: 2.30s\n",
      "  Train: LossCls=0.4659, LossBbox=0.0020, Total=0.5064, Acc=0.9735, IoU=0.1370\n",
      "  Valid: LossCls=0.6907, LossBbox=0.0012, Total=0.7143, Acc=0.8684, IoU=0.1728\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7143\n",
      "DEBUG train_multitask_model: Epoch 22, total_train_samples procesadas esta época: 151\n",
      "Epoch 22/120 Duración: 2.23s\n",
      "  Train: LossCls=0.4636, LossBbox=0.0017, Total=0.4976, Acc=0.9470, IoU=0.1368\n",
      "  Valid: LossCls=0.6725, LossBbox=0.0012, Total=0.6955, Acc=0.8684, IoU=0.1761\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6955\n",
      "DEBUG train_multitask_model: Epoch 23, total_train_samples procesadas esta época: 151\n",
      "Epoch 23/120 Duración: 2.27s\n",
      "  Train: LossCls=0.4220, LossBbox=0.0019, Total=0.4598, Acc=0.9735, IoU=0.1381\n",
      "  Valid: LossCls=0.6545, LossBbox=0.0011, Total=0.6774, Acc=0.8684, IoU=0.1755\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6774\n",
      "DEBUG train_multitask_model: Epoch 24, total_train_samples procesadas esta época: 151\n",
      "Epoch 24/120 Duración: 2.26s\n",
      "  Train: LossCls=0.3895, LossBbox=0.0018, Total=0.4249, Acc=0.9801, IoU=0.1422\n",
      "  Valid: LossCls=0.6416, LossBbox=0.0011, Total=0.6642, Acc=0.8684, IoU=0.1775\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6642\n",
      "DEBUG train_multitask_model: Epoch 25, total_train_samples procesadas esta época: 151\n",
      "Epoch 25/120 Duración: 2.27s\n",
      "  Train: LossCls=0.3868, LossBbox=0.0018, Total=0.4235, Acc=0.9801, IoU=0.1405\n",
      "  Valid: LossCls=0.6272, LossBbox=0.0011, Total=0.6499, Acc=0.8684, IoU=0.1758\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6499\n",
      "DEBUG train_multitask_model: Epoch 26, total_train_samples procesadas esta época: 151\n",
      "Epoch 26/120 Duración: 2.38s\n",
      "  Train: LossCls=0.3863, LossBbox=0.0017, Total=0.4204, Acc=0.9603, IoU=0.1571\n",
      "  Valid: LossCls=0.6224, LossBbox=0.0011, Total=0.6443, Acc=0.8684, IoU=0.1784\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6443\n",
      "DEBUG train_multitask_model: Epoch 27, total_train_samples procesadas esta época: 151\n",
      "Epoch 27/120 Duración: 2.32s\n",
      "  Train: LossCls=0.3702, LossBbox=0.0018, Total=0.4069, Acc=0.9801, IoU=0.1332\n",
      "  Valid: LossCls=0.6012, LossBbox=0.0011, Total=0.6231, Acc=0.8684, IoU=0.1821\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6231\n",
      "DEBUG train_multitask_model: Epoch 28, total_train_samples procesadas esta época: 151\n",
      "Epoch 28/120 Duración: 2.27s\n",
      "  Train: LossCls=0.3310, LossBbox=0.0016, Total=0.3630, Acc=0.9934, IoU=0.1622\n",
      "  Valid: LossCls=0.5953, LossBbox=0.0011, Total=0.6168, Acc=0.8684, IoU=0.1821\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6168\n",
      "DEBUG train_multitask_model: Epoch 29, total_train_samples procesadas esta época: 151\n",
      "Epoch 29/120 Duración: 2.29s\n",
      "  Train: LossCls=0.3379, LossBbox=0.0018, Total=0.3729, Acc=0.9669, IoU=0.1467\n",
      "  Valid: LossCls=0.5853, LossBbox=0.0011, Total=0.6065, Acc=0.8684, IoU=0.1797\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6065\n",
      "DEBUG train_multitask_model: Epoch 30, total_train_samples procesadas esta época: 151\n",
      "Epoch 30/120 Duración: 2.35s\n",
      "  Train: LossCls=0.3345, LossBbox=0.0017, Total=0.3680, Acc=0.9868, IoU=0.1709\n",
      "  Valid: LossCls=0.5744, LossBbox=0.0011, Total=0.5957, Acc=0.8684, IoU=0.1788\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5957\n",
      "DEBUG train_multitask_model: Epoch 31, total_train_samples procesadas esta época: 151\n",
      "Epoch 31/120 Duración: 2.36s\n",
      "  Train: LossCls=0.3094, LossBbox=0.0016, Total=0.3414, Acc=0.9868, IoU=0.1539\n",
      "  Valid: LossCls=0.5679, LossBbox=0.0010, Total=0.5888, Acc=0.8684, IoU=0.1801\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5888\n",
      "DEBUG train_multitask_model: Epoch 32, total_train_samples procesadas esta época: 151\n",
      "Epoch 32/120 Duración: 2.34s\n",
      "  Train: LossCls=0.3047, LossBbox=0.0016, Total=0.3365, Acc=0.9934, IoU=0.1469\n",
      "  Valid: LossCls=0.5631, LossBbox=0.0010, Total=0.5837, Acc=0.8684, IoU=0.1869\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5837\n",
      "DEBUG train_multitask_model: Epoch 33, total_train_samples procesadas esta época: 151\n",
      "Epoch 33/120 Duración: 2.47s\n",
      "  Train: LossCls=0.3337, LossBbox=0.0014, Total=0.3623, Acc=0.9603, IoU=0.1740\n",
      "  Valid: LossCls=0.5492, LossBbox=0.0010, Total=0.5700, Acc=0.8684, IoU=0.1824\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5700\n",
      "DEBUG train_multitask_model: Epoch 34, total_train_samples procesadas esta época: 151\n",
      "Epoch 34/120 Duración: 2.48s\n",
      "  Train: LossCls=0.3003, LossBbox=0.0015, Total=0.3306, Acc=0.9934, IoU=0.1652\n",
      "  Valid: LossCls=0.5438, LossBbox=0.0011, Total=0.5648, Acc=0.8684, IoU=0.1858\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5648\n",
      "DEBUG train_multitask_model: Epoch 35, total_train_samples procesadas esta época: 151\n",
      "Epoch 35/120 Duración: 2.34s\n",
      "  Train: LossCls=0.2740, LossBbox=0.0018, Total=0.3099, Acc=0.9801, IoU=0.1549\n",
      "  Valid: LossCls=0.5396, LossBbox=0.0010, Total=0.5606, Acc=0.8684, IoU=0.1837\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5606\n",
      "DEBUG train_multitask_model: Epoch 36, total_train_samples procesadas esta época: 151\n",
      "Epoch 36/120 Duración: 2.35s\n",
      "  Train: LossCls=0.2628, LossBbox=0.0014, Total=0.2908, Acc=0.9868, IoU=0.1822\n",
      "  Valid: LossCls=0.5384, LossBbox=0.0010, Total=0.5588, Acc=0.8947, IoU=0.1878\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5588\n",
      "DEBUG train_multitask_model: Epoch 37, total_train_samples procesadas esta época: 151\n",
      "Epoch 37/120 Duración: 2.34s\n",
      "  Train: LossCls=0.2533, LossBbox=0.0016, Total=0.2843, Acc=0.9934, IoU=0.1757\n",
      "  Valid: LossCls=0.5246, LossBbox=0.0010, Total=0.5447, Acc=0.8947, IoU=0.1916\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5447\n",
      "DEBUG train_multitask_model: Epoch 38, total_train_samples procesadas esta época: 151\n",
      "Epoch 38/120 Duración: 2.31s\n",
      "  Train: LossCls=0.2320, LossBbox=0.0015, Total=0.2611, Acc=1.0000, IoU=0.1623\n",
      "  Valid: LossCls=0.5154, LossBbox=0.0010, Total=0.5353, Acc=0.8947, IoU=0.1971\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5353\n",
      "DEBUG train_multitask_model: Epoch 39, total_train_samples procesadas esta época: 151\n",
      "Epoch 39/120 Duración: 2.28s\n",
      "  Train: LossCls=0.2595, LossBbox=0.0013, Total=0.2859, Acc=0.9934, IoU=0.1728\n",
      "  Valid: LossCls=0.5145, LossBbox=0.0010, Total=0.5344, Acc=0.8947, IoU=0.1926\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5344\n",
      "DEBUG train_multitask_model: Epoch 40, total_train_samples procesadas esta época: 151\n",
      "Epoch 40/120 Duración: 2.33s\n",
      "  Train: LossCls=0.2521, LossBbox=0.0013, Total=0.2782, Acc=0.9735, IoU=0.1620\n",
      "  Valid: LossCls=0.5100, LossBbox=0.0010, Total=0.5293, Acc=0.8947, IoU=0.2005\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5293\n",
      "DEBUG train_multitask_model: Epoch 41, total_train_samples procesadas esta época: 151\n",
      "Epoch 41/120 Duración: 2.39s\n",
      "  Train: LossCls=0.2121, LossBbox=0.0014, Total=0.2398, Acc=1.0000, IoU=0.1893\n",
      "  Valid: LossCls=0.5029, LossBbox=0.0010, Total=0.5223, Acc=0.8947, IoU=0.1953\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5223\n",
      "DEBUG train_multitask_model: Epoch 42, total_train_samples procesadas esta época: 151\n",
      "Epoch 42/120 Duración: 2.33s\n",
      "  Train: LossCls=0.2128, LossBbox=0.0013, Total=0.2382, Acc=1.0000, IoU=0.1857\n",
      "  Valid: LossCls=0.4965, LossBbox=0.0010, Total=0.5158, Acc=0.8947, IoU=0.1943\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5158\n",
      "DEBUG train_multitask_model: Epoch 43, total_train_samples procesadas esta época: 151\n",
      "Epoch 43/120 Duración: 2.20s\n",
      "  Train: LossCls=0.2066, LossBbox=0.0013, Total=0.2321, Acc=0.9934, IoU=0.1721\n",
      "  Valid: LossCls=0.4946, LossBbox=0.0010, Total=0.5141, Acc=0.8947, IoU=0.1870\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5141\n",
      "DEBUG train_multitask_model: Epoch 44, total_train_samples procesadas esta época: 151\n",
      "Epoch 44/120 Duración: 2.20s\n",
      "  Train: LossCls=0.2035, LossBbox=0.0012, Total=0.2272, Acc=1.0000, IoU=0.1869\n",
      "  Valid: LossCls=0.4911, LossBbox=0.0010, Total=0.5104, Acc=0.8947, IoU=0.1889\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5104\n",
      "DEBUG train_multitask_model: Epoch 45, total_train_samples procesadas esta época: 151\n",
      "Epoch 45/120 Duración: 2.21s\n",
      "  Train: LossCls=0.2037, LossBbox=0.0012, Total=0.2269, Acc=0.9934, IoU=0.1959\n",
      "  Valid: LossCls=0.4879, LossBbox=0.0010, Total=0.5074, Acc=0.8947, IoU=0.1928\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5074\n",
      "DEBUG train_multitask_model: Epoch 46, total_train_samples procesadas esta época: 151\n",
      "Epoch 46/120 Duración: 2.25s\n",
      "  Train: LossCls=0.1896, LossBbox=0.0012, Total=0.2139, Acc=1.0000, IoU=0.1894\n",
      "  Valid: LossCls=0.4770, LossBbox=0.0010, Total=0.4963, Acc=0.8947, IoU=0.2005\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4963\n",
      "DEBUG train_multitask_model: Epoch 47, total_train_samples procesadas esta época: 151\n",
      "Epoch 47/120 Duración: 2.22s\n",
      "  Train: LossCls=0.2061, LossBbox=0.0013, Total=0.2321, Acc=0.9934, IoU=0.1948\n",
      "  Valid: LossCls=0.4694, LossBbox=0.0009, Total=0.4882, Acc=0.8947, IoU=0.2069\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4882\n",
      "DEBUG train_multitask_model: Epoch 48, total_train_samples procesadas esta época: 151\n",
      "Epoch 48/120 Duración: 2.18s\n",
      "  Train: LossCls=0.1898, LossBbox=0.0012, Total=0.2147, Acc=0.9934, IoU=0.1846\n",
      "  Valid: LossCls=0.4608, LossBbox=0.0010, Total=0.4802, Acc=0.9211, IoU=0.2009\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4802\n",
      "DEBUG train_multitask_model: Epoch 49, total_train_samples procesadas esta época: 151\n",
      "Epoch 49/120 Duración: 2.19s\n",
      "  Train: LossCls=0.1911, LossBbox=0.0012, Total=0.2160, Acc=0.9934, IoU=0.2028\n",
      "  Valid: LossCls=0.4518, LossBbox=0.0010, Total=0.4709, Acc=0.8947, IoU=0.2045\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4709\n",
      "DEBUG train_multitask_model: Epoch 50, total_train_samples procesadas esta época: 151\n",
      "Epoch 50/120 Duración: 2.22s\n",
      "  Train: LossCls=0.1962, LossBbox=0.0011, Total=0.2190, Acc=0.9934, IoU=0.1977\n",
      "  Valid: LossCls=0.4513, LossBbox=0.0009, Total=0.4702, Acc=0.8947, IoU=0.2039\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4702\n",
      "DEBUG train_multitask_model: Epoch 51, total_train_samples procesadas esta época: 151\n",
      "Epoch 51/120 Duración: 2.22s\n",
      "  Train: LossCls=0.1722, LossBbox=0.0012, Total=0.1954, Acc=1.0000, IoU=0.2039\n",
      "  Valid: LossCls=0.4413, LossBbox=0.0010, Total=0.4605, Acc=0.8947, IoU=0.2062\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4605\n",
      "DEBUG train_multitask_model: Epoch 52, total_train_samples procesadas esta época: 151\n",
      "Epoch 52/120 Duración: 2.22s\n",
      "  Train: LossCls=0.1930, LossBbox=0.0012, Total=0.2173, Acc=0.9934, IoU=0.1915\n",
      "  Valid: LossCls=0.4410, LossBbox=0.0009, Total=0.4599, Acc=0.8947, IoU=0.2103\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4599\n",
      "DEBUG train_multitask_model: Epoch 53, total_train_samples procesadas esta época: 151\n",
      "Epoch 53/120 Duración: 2.43s\n",
      "  Train: LossCls=0.1833, LossBbox=0.0012, Total=0.2072, Acc=0.9934, IoU=0.1988\n",
      "  Valid: LossCls=0.4456, LossBbox=0.0009, Total=0.4643, Acc=0.8947, IoU=0.2120\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 54, total_train_samples procesadas esta época: 151\n",
      "Epoch 54/120 Duración: 2.39s\n",
      "  Train: LossCls=0.1845, LossBbox=0.0012, Total=0.2090, Acc=0.9934, IoU=0.1889\n",
      "  Valid: LossCls=0.4461, LossBbox=0.0009, Total=0.4650, Acc=0.8947, IoU=0.2118\n",
      "  Val_loss_total no mejoró. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 55, total_train_samples procesadas esta época: 151\n",
      "Epoch 55/120 Duración: 2.37s\n",
      "  Train: LossCls=0.1469, LossBbox=0.0011, Total=0.1698, Acc=0.9934, IoU=0.1878\n",
      "  Valid: LossCls=0.4307, LossBbox=0.0009, Total=0.4490, Acc=0.9211, IoU=0.2180\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4490\n",
      "DEBUG train_multitask_model: Epoch 56, total_train_samples procesadas esta época: 151\n",
      "Epoch 56/120 Duración: 2.51s\n",
      "  Train: LossCls=0.1634, LossBbox=0.0011, Total=0.1856, Acc=1.0000, IoU=0.2206\n",
      "  Valid: LossCls=0.4380, LossBbox=0.0009, Total=0.4566, Acc=0.8947, IoU=0.2124\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 57, total_train_samples procesadas esta época: 151\n",
      "Epoch 57/120 Duración: 2.22s\n",
      "  Train: LossCls=0.1511, LossBbox=0.0010, Total=0.1704, Acc=1.0000, IoU=0.2212\n",
      "  Valid: LossCls=0.4407, LossBbox=0.0009, Total=0.4592, Acc=0.8947, IoU=0.2131\n",
      "  Val_loss_total no mejoró. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 58, total_train_samples procesadas esta época: 151\n",
      "Epoch 58/120 Duración: 2.22s\n",
      "  Train: LossCls=0.1661, LossBbox=0.0011, Total=0.1874, Acc=1.0000, IoU=0.2146\n",
      "  Valid: LossCls=0.4347, LossBbox=0.0009, Total=0.4529, Acc=0.8947, IoU=0.2141\n",
      "  Val_loss_total no mejoró. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 59, total_train_samples procesadas esta época: 151\n",
      "Epoch 59/120 Duración: 2.19s\n",
      "  Train: LossCls=0.1690, LossBbox=0.0012, Total=0.1921, Acc=1.0000, IoU=0.2208\n",
      "  Valid: LossCls=0.4345, LossBbox=0.0009, Total=0.4523, Acc=0.8947, IoU=0.2149\n",
      "  Val_loss_total no mejoró. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 60, total_train_samples procesadas esta época: 151\n",
      "Epoch 60/120 Duración: 2.24s\n",
      "  Train: LossCls=0.1424, LossBbox=0.0012, Total=0.1657, Acc=1.0000, IoU=0.2000\n",
      "  Valid: LossCls=0.4303, LossBbox=0.0009, Total=0.4478, Acc=0.8947, IoU=0.2162\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4478\n",
      "DEBUG train_multitask_model: Epoch 61, total_train_samples procesadas esta época: 151\n",
      "Epoch 61/120 Duración: 2.26s\n",
      "  Train: LossCls=0.1347, LossBbox=0.0011, Total=0.1568, Acc=1.0000, IoU=0.2080\n",
      "  Valid: LossCls=0.4323, LossBbox=0.0009, Total=0.4502, Acc=0.8947, IoU=0.2107\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 62, total_train_samples procesadas esta época: 151\n",
      "Epoch 62/120 Duración: 2.22s\n",
      "  Train: LossCls=0.1328, LossBbox=0.0011, Total=0.1554, Acc=1.0000, IoU=0.1920\n",
      "  Valid: LossCls=0.4199, LossBbox=0.0009, Total=0.4385, Acc=0.8947, IoU=0.2091\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4385\n",
      "DEBUG train_multitask_model: Epoch 63, total_train_samples procesadas esta época: 151\n",
      "Epoch 63/120 Duración: 2.18s\n",
      "  Train: LossCls=0.1336, LossBbox=0.0011, Total=0.1561, Acc=1.0000, IoU=0.1990\n",
      "  Valid: LossCls=0.4205, LossBbox=0.0009, Total=0.4393, Acc=0.8947, IoU=0.2140\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 64, total_train_samples procesadas esta época: 151\n",
      "Epoch 64/120 Duración: 2.23s\n",
      "  Train: LossCls=0.1369, LossBbox=0.0011, Total=0.1592, Acc=1.0000, IoU=0.2158\n",
      "  Valid: LossCls=0.4181, LossBbox=0.0009, Total=0.4369, Acc=0.8947, IoU=0.2120\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4369\n",
      "DEBUG train_multitask_model: Epoch 65, total_train_samples procesadas esta época: 151\n",
      "Epoch 65/120 Duración: 2.71s\n",
      "  Train: LossCls=0.1394, LossBbox=0.0011, Total=0.1604, Acc=1.0000, IoU=0.2170\n",
      "  Valid: LossCls=0.4206, LossBbox=0.0009, Total=0.4394, Acc=0.8947, IoU=0.2082\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 66, total_train_samples procesadas esta época: 151\n",
      "Epoch 66/120 Duración: 2.47s\n",
      "  Train: LossCls=0.1178, LossBbox=0.0009, Total=0.1368, Acc=0.9934, IoU=0.2253\n",
      "  Valid: LossCls=0.4128, LossBbox=0.0009, Total=0.4312, Acc=0.8947, IoU=0.2187\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4312\n",
      "DEBUG train_multitask_model: Epoch 67, total_train_samples procesadas esta época: 151\n",
      "Epoch 67/120 Duración: 2.48s\n",
      "  Train: LossCls=0.1157, LossBbox=0.0010, Total=0.1359, Acc=1.0000, IoU=0.2275\n",
      "  Valid: LossCls=0.3991, LossBbox=0.0009, Total=0.4177, Acc=0.9211, IoU=0.2172\n",
      "ERROR AL INTENTAR GUARDAR EL MODELO en './Resultados/pretrained_model_20250525_201424.pth': File ./Resultados/pretrained_model_20250525_201424.pth cannot be opened.\n",
      "DEBUG train_multitask_model: Epoch 68, total_train_samples procesadas esta época: 151\n",
      "Epoch 68/120 Duración: 2.40s\n",
      "  Train: LossCls=0.1214, LossBbox=0.0011, Total=0.1435, Acc=1.0000, IoU=0.1964\n",
      "  Valid: LossCls=0.4019, LossBbox=0.0009, Total=0.4201, Acc=0.9211, IoU=0.2207\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 69, total_train_samples procesadas esta época: 151\n",
      "Epoch 69/120 Duración: 2.42s\n",
      "  Train: LossCls=0.1064, LossBbox=0.0010, Total=0.1265, Acc=1.0000, IoU=0.2362\n",
      "  Valid: LossCls=0.3955, LossBbox=0.0009, Total=0.4137, Acc=0.8947, IoU=0.2211\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4137\n",
      "DEBUG train_multitask_model: Epoch 70, total_train_samples procesadas esta época: 151\n",
      "Epoch 70/120 Duración: 2.42s\n",
      "  Train: LossCls=0.1206, LossBbox=0.0010, Total=0.1404, Acc=1.0000, IoU=0.2315\n",
      "  Valid: LossCls=0.3972, LossBbox=0.0009, Total=0.4154, Acc=0.9211, IoU=0.2172\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 71, total_train_samples procesadas esta época: 151\n",
      "Epoch 71/120 Duración: 2.39s\n",
      "  Train: LossCls=0.1128, LossBbox=0.0009, Total=0.1313, Acc=1.0000, IoU=0.2413\n",
      "  Valid: LossCls=0.4010, LossBbox=0.0009, Total=0.4189, Acc=0.9211, IoU=0.2178\n",
      "  Val_loss_total no mejoró. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 72, total_train_samples procesadas esta época: 151\n",
      "Epoch 72/120 Duración: 2.41s\n",
      "  Train: LossCls=0.1114, LossBbox=0.0009, Total=0.1298, Acc=1.0000, IoU=0.2255\n",
      "  Valid: LossCls=0.4033, LossBbox=0.0009, Total=0.4210, Acc=0.8947, IoU=0.2218\n",
      "  Val_loss_total no mejoró. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 73, total_train_samples procesadas esta época: 151\n",
      "Epoch 73/120 Duración: 2.38s\n",
      "  Train: LossCls=0.1106, LossBbox=0.0010, Total=0.1299, Acc=1.0000, IoU=0.2217\n",
      "  Valid: LossCls=0.3977, LossBbox=0.0009, Total=0.4153, Acc=0.9211, IoU=0.2238\n",
      "  Val_loss_total no mejoró. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 74, total_train_samples procesadas esta época: 151\n",
      "Epoch 74/120 Duración: 2.48s\n",
      "  Train: LossCls=0.1008, LossBbox=0.0010, Total=0.1208, Acc=1.0000, IoU=0.2174\n",
      "  Valid: LossCls=0.3924, LossBbox=0.0009, Total=0.4103, Acc=0.8947, IoU=0.2213\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4103\n",
      "DEBUG train_multitask_model: Epoch 75, total_train_samples procesadas esta época: 151\n",
      "Epoch 75/120 Duración: 2.31s\n",
      "  Train: LossCls=0.1009, LossBbox=0.0010, Total=0.1202, Acc=1.0000, IoU=0.2303\n",
      "  Valid: LossCls=0.3961, LossBbox=0.0009, Total=0.4135, Acc=0.9211, IoU=0.2236\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 76, total_train_samples procesadas esta época: 151\n",
      "Epoch 76/120 Duración: 2.38s\n",
      "  Train: LossCls=0.1076, LossBbox=0.0011, Total=0.1288, Acc=1.0000, IoU=0.2168\n",
      "  Valid: LossCls=0.4039, LossBbox=0.0009, Total=0.4216, Acc=0.8947, IoU=0.2232\n",
      "  Val_loss_total no mejoró. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 77, total_train_samples procesadas esta época: 151\n",
      "Epoch 77/120 Duración: 2.35s\n",
      "  Train: LossCls=0.1109, LossBbox=0.0011, Total=0.1327, Acc=1.0000, IoU=0.1990\n",
      "  Valid: LossCls=0.3997, LossBbox=0.0009, Total=0.4174, Acc=0.9211, IoU=0.2228\n",
      "  Val_loss_total no mejoró. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 78, total_train_samples procesadas esta época: 151\n",
      "Epoch 78/120 Duración: 2.31s\n",
      "  Train: LossCls=0.1087, LossBbox=0.0010, Total=0.1281, Acc=1.0000, IoU=0.2244\n",
      "  Valid: LossCls=0.4024, LossBbox=0.0009, Total=0.4196, Acc=0.8947, IoU=0.2311\n",
      "  Val_loss_total no mejoró. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 79, total_train_samples procesadas esta época: 151\n",
      "Epoch 79/120 Duración: 2.64s\n",
      "  Train: LossCls=0.1086, LossBbox=0.0010, Total=0.1289, Acc=0.9934, IoU=0.2133\n",
      "  Valid: LossCls=0.4003, LossBbox=0.0008, Total=0.4169, Acc=0.8947, IoU=0.2384\n",
      "  Val_loss_total no mejoró. Paciencia: 5/15\n",
      "DEBUG train_multitask_model: Epoch 80, total_train_samples procesadas esta época: 151\n",
      "Epoch 80/120 Duración: 2.56s\n",
      "  Train: LossCls=0.0973, LossBbox=0.0009, Total=0.1162, Acc=1.0000, IoU=0.2095\n",
      "  Valid: LossCls=0.3963, LossBbox=0.0009, Total=0.4134, Acc=0.8947, IoU=0.2374\n",
      "  Val_loss_total no mejoró. Paciencia: 6/15\n",
      "DEBUG train_multitask_model: Epoch 81, total_train_samples procesadas esta época: 151\n",
      "Epoch 81/120 Duración: 2.47s\n",
      "  Train: LossCls=0.0892, LossBbox=0.0009, Total=0.1069, Acc=1.0000, IoU=0.2350\n",
      "  Valid: LossCls=0.3781, LossBbox=0.0009, Total=0.3957, Acc=0.8947, IoU=0.2347\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3957\n",
      "DEBUG train_multitask_model: Epoch 82, total_train_samples procesadas esta época: 151\n",
      "Epoch 82/120 Duración: 2.66s\n",
      "  Train: LossCls=0.0882, LossBbox=0.0010, Total=0.1081, Acc=1.0000, IoU=0.2402\n",
      "  Valid: LossCls=0.3734, LossBbox=0.0009, Total=0.3911, Acc=0.8947, IoU=0.2356\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3911\n",
      "DEBUG train_multitask_model: Epoch 83, total_train_samples procesadas esta época: 151\n",
      "Epoch 83/120 Duración: 2.42s\n",
      "  Train: LossCls=0.0891, LossBbox=0.0010, Total=0.1085, Acc=1.0000, IoU=0.2277\n",
      "  Valid: LossCls=0.3717, LossBbox=0.0009, Total=0.3896, Acc=0.8947, IoU=0.2312\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3896\n",
      "DEBUG train_multitask_model: Epoch 84, total_train_samples procesadas esta época: 151\n",
      "Epoch 84/120 Duración: 2.37s\n",
      "  Train: LossCls=0.0882, LossBbox=0.0009, Total=0.1070, Acc=1.0000, IoU=0.2278\n",
      "  Valid: LossCls=0.3700, LossBbox=0.0009, Total=0.3873, Acc=0.9211, IoU=0.2321\n",
      "ERROR AL INTENTAR GUARDAR EL MODELO en './Resultados/pretrained_model_20250525_201424.pth': File ./Resultados/pretrained_model_20250525_201424.pth cannot be opened.\n",
      "DEBUG train_multitask_model: Epoch 85, total_train_samples procesadas esta época: 151\n",
      "Epoch 85/120 Duración: 2.61s\n",
      "  Train: LossCls=0.0842, LossBbox=0.0009, Total=0.1025, Acc=1.0000, IoU=0.2203\n",
      "  Valid: LossCls=0.3643, LossBbox=0.0009, Total=0.3820, Acc=0.8947, IoU=0.2310\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3820\n",
      "DEBUG train_multitask_model: Epoch 86, total_train_samples procesadas esta época: 151\n",
      "Epoch 86/120 Duración: 2.59s\n",
      "  Train: LossCls=0.0944, LossBbox=0.0009, Total=0.1133, Acc=1.0000, IoU=0.2157\n",
      "  Valid: LossCls=0.3692, LossBbox=0.0009, Total=0.3868, Acc=0.8947, IoU=0.2320\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 87, total_train_samples procesadas esta época: 151\n",
      "Epoch 87/120 Duración: 2.37s\n",
      "  Train: LossCls=0.0873, LossBbox=0.0009, Total=0.1062, Acc=1.0000, IoU=0.2266\n",
      "  Valid: LossCls=0.3677, LossBbox=0.0009, Total=0.3854, Acc=0.8947, IoU=0.2343\n",
      "  Val_loss_total no mejoró. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 88, total_train_samples procesadas esta época: 151\n",
      "Epoch 88/120 Duración: 2.41s\n",
      "  Train: LossCls=0.1146, LossBbox=0.0009, Total=0.1334, Acc=1.0000, IoU=0.2341\n",
      "  Valid: LossCls=0.3800, LossBbox=0.0009, Total=0.3971, Acc=0.9211, IoU=0.2336\n",
      "  Val_loss_total no mejoró. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 89, total_train_samples procesadas esta época: 151\n",
      "Epoch 89/120 Duración: 2.36s\n",
      "  Train: LossCls=0.0973, LossBbox=0.0009, Total=0.1155, Acc=1.0000, IoU=0.2250\n",
      "  Valid: LossCls=0.3792, LossBbox=0.0008, Total=0.3957, Acc=0.8947, IoU=0.2357\n",
      "  Val_loss_total no mejoró. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 90, total_train_samples procesadas esta época: 151\n",
      "Epoch 90/120 Duración: 2.45s\n",
      "  Train: LossCls=0.0780, LossBbox=0.0009, Total=0.0958, Acc=1.0000, IoU=0.2351\n",
      "  Valid: LossCls=0.3749, LossBbox=0.0008, Total=0.3917, Acc=0.8947, IoU=0.2332\n",
      "  Val_loss_total no mejoró. Paciencia: 5/15\n",
      "DEBUG train_multitask_model: Epoch 91, total_train_samples procesadas esta época: 151\n",
      "Epoch 91/120 Duración: 2.45s\n",
      "  Train: LossCls=0.0925, LossBbox=0.0010, Total=0.1122, Acc=1.0000, IoU=0.2261\n",
      "  Valid: LossCls=0.3798, LossBbox=0.0008, Total=0.3965, Acc=0.8947, IoU=0.2308\n",
      "  Val_loss_total no mejoró. Paciencia: 6/15\n",
      "DEBUG train_multitask_model: Epoch 92, total_train_samples procesadas esta época: 151\n",
      "Epoch 92/120 Duración: 2.43s\n",
      "  Train: LossCls=0.0700, LossBbox=0.0009, Total=0.0873, Acc=1.0000, IoU=0.2180\n",
      "  Valid: LossCls=0.3810, LossBbox=0.0008, Total=0.3978, Acc=0.8947, IoU=0.2289\n",
      "  Val_loss_total no mejoró. Paciencia: 7/15\n",
      "DEBUG train_multitask_model: Epoch 93, total_train_samples procesadas esta época: 151\n",
      "Epoch 93/120 Duración: 2.46s\n",
      "  Train: LossCls=0.0665, LossBbox=0.0008, Total=0.0830, Acc=1.0000, IoU=0.2394\n",
      "  Valid: LossCls=0.3777, LossBbox=0.0008, Total=0.3940, Acc=0.8947, IoU=0.2351\n",
      "  Val_loss_total no mejoró. Paciencia: 8/15\n",
      "DEBUG train_multitask_model: Epoch 94, total_train_samples procesadas esta época: 151\n",
      "Epoch 94/120 Duración: 2.32s\n",
      "  Train: LossCls=0.0991, LossBbox=0.0008, Total=0.1159, Acc=0.9934, IoU=0.2478\n",
      "  Valid: LossCls=0.3641, LossBbox=0.0008, Total=0.3810, Acc=0.8947, IoU=0.2306\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3810\n",
      "DEBUG train_multitask_model: Epoch 95, total_train_samples procesadas esta época: 151\n",
      "Epoch 95/120 Duración: 2.36s\n",
      "  Train: LossCls=0.1018, LossBbox=0.0010, Total=0.1217, Acc=1.0000, IoU=0.2279\n",
      "  Valid: LossCls=0.3650, LossBbox=0.0008, Total=0.3815, Acc=0.8947, IoU=0.2281\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 96, total_train_samples procesadas esta época: 151\n",
      "Epoch 96/120 Duración: 2.45s\n",
      "  Train: LossCls=0.0771, LossBbox=0.0010, Total=0.0963, Acc=1.0000, IoU=0.2252\n",
      "  Valid: LossCls=0.3593, LossBbox=0.0008, Total=0.3761, Acc=0.8947, IoU=0.2233\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3761\n",
      "DEBUG train_multitask_model: Epoch 97, total_train_samples procesadas esta época: 151\n",
      "Epoch 97/120 Duración: 2.49s\n",
      "  Train: LossCls=0.0810, LossBbox=0.0008, Total=0.0970, Acc=1.0000, IoU=0.2453\n",
      "  Valid: LossCls=0.3465, LossBbox=0.0009, Total=0.3636, Acc=0.8947, IoU=0.2234\n",
      "ERROR AL INTENTAR GUARDAR EL MODELO en './Resultados/pretrained_model_20250525_201424.pth': File ./Resultados/pretrained_model_20250525_201424.pth cannot be opened.\n",
      "DEBUG train_multitask_model: Epoch 98, total_train_samples procesadas esta época: 151\n",
      "Epoch 98/120 Duración: 2.83s\n",
      "  Train: LossCls=0.0807, LossBbox=0.0007, Total=0.0952, Acc=1.0000, IoU=0.2700\n",
      "  Valid: LossCls=0.3493, LossBbox=0.0008, Total=0.3661, Acc=0.8947, IoU=0.2257\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 99, total_train_samples procesadas esta época: 151\n",
      "Epoch 99/120 Duración: 2.81s\n",
      "  Train: LossCls=0.0843, LossBbox=0.0009, Total=0.1027, Acc=1.0000, IoU=0.2327\n",
      "  Valid: LossCls=0.3536, LossBbox=0.0008, Total=0.3705, Acc=0.8947, IoU=0.2213\n",
      "  Val_loss_total no mejoró. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 100, total_train_samples procesadas esta época: 151\n",
      "Epoch 100/120 Duración: 2.38s\n",
      "  Train: LossCls=0.0783, LossBbox=0.0009, Total=0.0960, Acc=1.0000, IoU=0.2384\n",
      "  Valid: LossCls=0.3550, LossBbox=0.0009, Total=0.3723, Acc=0.8947, IoU=0.2254\n",
      "  Val_loss_total no mejoró. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 101, total_train_samples procesadas esta época: 151\n",
      "Epoch 101/120 Duración: 3.14s\n",
      "  Train: LossCls=0.0654, LossBbox=0.0008, Total=0.0819, Acc=1.0000, IoU=0.2622\n",
      "  Valid: LossCls=0.3502, LossBbox=0.0008, Total=0.3670, Acc=0.8947, IoU=0.2296\n",
      "  Val_loss_total no mejoró. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 102, total_train_samples procesadas esta época: 151\n",
      "Epoch 102/120 Duración: 2.40s\n",
      "  Train: LossCls=0.0796, LossBbox=0.0008, Total=0.0958, Acc=0.9934, IoU=0.2587\n",
      "  Valid: LossCls=0.3445, LossBbox=0.0008, Total=0.3612, Acc=0.8947, IoU=0.2314\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3612\n",
      "DEBUG train_multitask_model: Epoch 103, total_train_samples procesadas esta época: 151\n",
      "Epoch 103/120 Duración: 2.41s\n",
      "  Train: LossCls=0.0612, LossBbox=0.0008, Total=0.0771, Acc=1.0000, IoU=0.2380\n",
      "  Valid: LossCls=0.3478, LossBbox=0.0009, Total=0.3649, Acc=0.8947, IoU=0.2322\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 104, total_train_samples procesadas esta época: 151\n",
      "Epoch 104/120 Duración: 2.45s\n",
      "  Train: LossCls=0.0698, LossBbox=0.0008, Total=0.0859, Acc=1.0000, IoU=0.2560\n",
      "  Valid: LossCls=0.3453, LossBbox=0.0009, Total=0.3624, Acc=0.8947, IoU=0.2294\n",
      "  Val_loss_total no mejoró. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 105, total_train_samples procesadas esta época: 151\n",
      "Epoch 105/120 Duración: 2.39s\n",
      "  Train: LossCls=0.0681, LossBbox=0.0009, Total=0.0856, Acc=1.0000, IoU=0.2353\n",
      "  Valid: LossCls=0.3484, LossBbox=0.0008, Total=0.3651, Acc=0.8947, IoU=0.2363\n",
      "  Val_loss_total no mejoró. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 106, total_train_samples procesadas esta época: 151\n",
      "Epoch 106/120 Duración: 3.13s\n",
      "  Train: LossCls=0.0688, LossBbox=0.0008, Total=0.0838, Acc=0.9934, IoU=0.2533\n",
      "  Valid: LossCls=0.3539, LossBbox=0.0008, Total=0.3706, Acc=0.8947, IoU=0.2341\n",
      "  Val_loss_total no mejoró. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 107, total_train_samples procesadas esta época: 151\n",
      "Epoch 107/120 Duración: 2.46s\n",
      "  Train: LossCls=0.0654, LossBbox=0.0008, Total=0.0822, Acc=1.0000, IoU=0.2530\n",
      "  Valid: LossCls=0.3428, LossBbox=0.0008, Total=0.3594, Acc=0.8947, IoU=0.2376\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3594\n",
      "DEBUG train_multitask_model: Epoch 108, total_train_samples procesadas esta época: 151\n",
      "Epoch 108/120 Duración: 2.60s\n",
      "  Train: LossCls=0.0651, LossBbox=0.0009, Total=0.0823, Acc=1.0000, IoU=0.2378\n",
      "  Valid: LossCls=0.3397, LossBbox=0.0008, Total=0.3562, Acc=0.8947, IoU=0.2356\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3562\n",
      "DEBUG train_multitask_model: Epoch 109, total_train_samples procesadas esta época: 151\n",
      "Epoch 109/120 Duración: 2.99s\n",
      "  Train: LossCls=0.0611, LossBbox=0.0008, Total=0.0770, Acc=1.0000, IoU=0.2770\n",
      "  Valid: LossCls=0.3347, LossBbox=0.0008, Total=0.3509, Acc=0.8947, IoU=0.2415\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3509\n",
      "DEBUG train_multitask_model: Epoch 110, total_train_samples procesadas esta época: 151\n",
      "Epoch 110/120 Duración: 2.59s\n",
      "  Train: LossCls=0.0614, LossBbox=0.0008, Total=0.0774, Acc=1.0000, IoU=0.2586\n",
      "  Valid: LossCls=0.3448, LossBbox=0.0008, Total=0.3609, Acc=0.8947, IoU=0.2432\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 111, total_train_samples procesadas esta época: 151\n",
      "Epoch 111/120 Duración: 2.35s\n",
      "  Train: LossCls=0.0560, LossBbox=0.0008, Total=0.0719, Acc=1.0000, IoU=0.2503\n",
      "  Valid: LossCls=0.3495, LossBbox=0.0008, Total=0.3658, Acc=0.8947, IoU=0.2467\n",
      "  Val_loss_total no mejoró. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 112, total_train_samples procesadas esta época: 151\n",
      "Epoch 112/120 Duración: 2.35s\n",
      "  Train: LossCls=0.0614, LossBbox=0.0009, Total=0.0797, Acc=1.0000, IoU=0.2467\n",
      "  Valid: LossCls=0.3589, LossBbox=0.0008, Total=0.3752, Acc=0.8947, IoU=0.2387\n",
      "  Val_loss_total no mejoró. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 113, total_train_samples procesadas esta época: 151\n",
      "Epoch 113/120 Duración: 2.75s\n",
      "  Train: LossCls=0.0614, LossBbox=0.0007, Total=0.0753, Acc=1.0000, IoU=0.2636\n",
      "  Valid: LossCls=0.3663, LossBbox=0.0008, Total=0.3825, Acc=0.8947, IoU=0.2346\n",
      "  Val_loss_total no mejoró. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 114, total_train_samples procesadas esta época: 151\n",
      "Epoch 114/120 Duración: 2.84s\n",
      "  Train: LossCls=0.0661, LossBbox=0.0007, Total=0.0811, Acc=1.0000, IoU=0.2589\n",
      "  Valid: LossCls=0.3613, LossBbox=0.0008, Total=0.3775, Acc=0.8947, IoU=0.2380\n",
      "  Val_loss_total no mejoró. Paciencia: 5/15\n",
      "DEBUG train_multitask_model: Epoch 115, total_train_samples procesadas esta época: 151\n",
      "Epoch 115/120 Duración: 2.46s\n",
      "  Train: LossCls=0.0529, LossBbox=0.0008, Total=0.0686, Acc=1.0000, IoU=0.2461\n",
      "  Valid: LossCls=0.3478, LossBbox=0.0008, Total=0.3634, Acc=0.8947, IoU=0.2554\n",
      "  Val_loss_total no mejoró. Paciencia: 6/15\n",
      "DEBUG train_multitask_model: Epoch 116, total_train_samples procesadas esta época: 151\n",
      "Epoch 116/120 Duración: 2.84s\n",
      "  Train: LossCls=0.0583, LossBbox=0.0007, Total=0.0730, Acc=1.0000, IoU=0.2641\n",
      "  Valid: LossCls=0.3318, LossBbox=0.0008, Total=0.3482, Acc=0.9211, IoU=0.2451\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3482\n",
      "DEBUG train_multitask_model: Epoch 117, total_train_samples procesadas esta época: 151\n",
      "Epoch 117/120 Duración: 2.40s\n",
      "  Train: LossCls=0.0650, LossBbox=0.0008, Total=0.0805, Acc=1.0000, IoU=0.2389\n",
      "  Valid: LossCls=0.3264, LossBbox=0.0008, Total=0.3431, Acc=0.8947, IoU=0.2428\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3431\n",
      "DEBUG train_multitask_model: Epoch 118, total_train_samples procesadas esta época: 151\n",
      "Epoch 118/120 Duración: 2.30s\n",
      "  Train: LossCls=0.0794, LossBbox=0.0007, Total=0.0938, Acc=1.0000, IoU=0.2712\n",
      "  Valid: LossCls=0.3364, LossBbox=0.0008, Total=0.3529, Acc=0.8947, IoU=0.2459\n",
      "  Val_loss_total no mejoró. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 119, total_train_samples procesadas esta época: 151\n",
      "Epoch 119/120 Duración: 2.36s\n",
      "  Train: LossCls=0.0564, LossBbox=0.0008, Total=0.0717, Acc=1.0000, IoU=0.2489\n",
      "  Valid: LossCls=0.3388, LossBbox=0.0008, Total=0.3550, Acc=0.8947, IoU=0.2417\n",
      "  Val_loss_total no mejoró. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 120, total_train_samples procesadas esta época: 151\n",
      "Epoch 120/120 Duración: 2.47s\n",
      "  Train: LossCls=0.0696, LossBbox=0.0008, Total=0.0853, Acc=1.0000, IoU=0.2568\n",
      "  Valid: LossCls=0.3460, LossBbox=0.0008, Total=0.3619, Acc=0.8947, IoU=0.2446\n",
      "  Val_loss_total no mejoró. Paciencia: 3/15\n",
      "Cargando el mejor estado del modelo guardado al final del entrenamiento.\n",
      "Entrenamiento finalizado.\n",
      "Entrenamiento del script de Run completado.\n"
     ]
    }
   ],
   "source": [
    "#  DEFINICIÓN DE collate_fn_skip_none (colócala aquí o en una celda anterior si ya está)\n",
    "def collate_fn_skip_none(batch):\n",
    "    batch_original_len = len(batch)\n",
    "    batch_filtered = [item for item in batch if item is not None]\n",
    "    if batch_original_len != len(batch_filtered) and batch_original_len > 0:\n",
    "        pass # print(f\"DEBUG collate_fn: Filtradas {batch_original_len - len(batch_filtered)} muestras None.\")\n",
    "    if not batch_filtered:\n",
    "        return None\n",
    "    try:\n",
    "        return torch.utils.data.dataloader.default_collate(batch_filtered)\n",
    "    except Exception as e:\n",
    "        # print(f\"ERROR en default_collate dentro de collate_fn_skip_none: {e}\")\n",
    "        raise\n",
    "\n",
    "# if __name__ == '__main__': # Descomenta si ejecutas como script .py\n",
    "\n",
    "reset_seed(42) \n",
    "\n",
    "DATA_DIR_RUN = '../Datos/' \n",
    "BATCH_SIZE_RUN = 32 \n",
    "\n",
    "# DIR_Results DEBE estar definida globalmente (ej. DIR_Results = './Resultados/')\n",
    "if 'DIR_Results' not in globals():\n",
    "    print(\"ADVERTENCIA: DIR_Results no estaba definido globalmente. Usando './Resultados_default/' para esta ejecución.\")\n",
    "    DIR_Results = './Resultados_default/' \n",
    "\n",
    "# Convertir DIR_Results a una ruta absoluta y crearla\n",
    "absolute_dir_results = os.path.abspath(DIR_Results)\n",
    "os.makedirs(absolute_dir_results, exist_ok=True) \n",
    "print(f\"Los resultados se guardarán en el directorio: {absolute_dir_results}\")\n",
    "\n",
    "\n",
    "print(\"Cargando y preprocesando el DataFrame...\")\n",
    "img_dir_run = osp.join(DATA_DIR_RUN, \"images/images\")\n",
    "\n",
    "\n",
    "if not osp.exists(img_dir_run):\n",
    "    print(f\"ERROR: El directorio de imágenes no existe: {img_dir_run}\")\n",
    "path_train_csv = osp.join(DATA_DIR_RUN, \"train.csv\")\n",
    "if not osp.exists(path_train_csv):\n",
    "    print(f\"ERROR: El archivo 'train.csv' no se encontró en {DATA_DIR_RUN}\")\n",
    "try:\n",
    "    df_original_run = pd.read_csv(path_train_csv)\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: No se pudo leer 'train.csv': {e}\")\n",
    "df_original_run['class_id'] = df_original_run['class'].map(obj2id) \n",
    "df_original_run.dropna(subset=['class_id'], inplace=True)\n",
    "df_original_run['class_id'] = df_original_run['class_id'].astype(int)\n",
    "columns_f_run = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class', 'class_id']\n",
    "missing_cols = [col for col in columns_f_run if col not in df_original_run.columns]\n",
    "if missing_cols:\n",
    "    print(f\"ERROR: Faltan las siguientes columnas en train.csv: {missing_cols}.\")\n",
    "df_run = df_original_run[columns_f_run].copy()\n",
    "if not df_run.empty:\n",
    "    bbox_cols_run = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "    for col in bbox_cols_run:\n",
    "        df_run[col] = pd.to_numeric(df_run[col], errors='coerce')\n",
    "    df_run.dropna(subset=bbox_cols_run, inplace=True)\n",
    "    if not df_run.empty:\n",
    "        df_run['xmin'] = df_run['xmin'] / IMG_ORIG_W\n",
    "        df_run['xmax'] = df_run['xmax'] / IMG_ORIG_W\n",
    "        df_run['ymin'] = df_run['ymin'] / IMG_ORIG_H\n",
    "        df_run['ymax'] = df_run['ymax'] / IMG_ORIG_H\n",
    "        df_run[['xmin', 'ymin', 'xmax', 'ymax']] = df_run[['xmin', 'ymin', 'xmax', 'ymax']].clip(0.0, 1.0)\n",
    "        print(\"Bounding boxes en el script de Run normalizados y acotados a [0,1].\")\n",
    "    else:\n",
    "        print(\"ERROR: DataFrame para el script de Run vacío después de asegurar columnas de bbox numéricas.\")\n",
    "else:\n",
    "    print(\"ERROR: DataFrame para el script de Run está vacío inicialmente.\")\n",
    "if df_run.empty or 'class_id' not in df_run.columns or df_run['class_id'].isnull().all():\n",
    "    print(\"ERROR: DataFrame vacío o sin 'class_id' válidos para la partición estratificada.\")\n",
    "    train_df_run, val_df_run = pd.DataFrame(columns=df_run.columns), pd.DataFrame(columns=df_run.columns) \n",
    "else:\n",
    "    can_stratify = True\n",
    "    if df_run['class_id'].nunique() < 2 : \n",
    "        can_stratify = False\n",
    "    else:\n",
    "        value_counts = df_run['class_id'].value_counts()\n",
    "        if any(value_counts < 2): \n",
    "            can_stratify = False\n",
    "    if can_stratify:\n",
    "        try:\n",
    "            train_df_run, val_df_run = train_test_split(df_run, test_size=0.2, random_state=42, stratify=df_run['class_id'])\n",
    "        except ValueError as e: \n",
    "            print(f\"Advertencia: Error durante la partición estratificada ({e}). Usando partición no estratificada.\")\n",
    "            train_df_run, val_df_run = train_test_split(df_run, test_size=0.2, random_state=42)\n",
    "    else:\n",
    "        print(\"Advertencia: No hay suficientes muestras/clases para una partición estratificada. Usando partición no estratificada.\")\n",
    "        train_df_run, val_df_run = train_test_split(df_run, test_size=0.2, random_state=42)\n",
    "print(f\"DEBUG: Longitud de df_run: {len(df_run)}\")\n",
    "print(f\"DEBUG: Longitud de train_df_run: {len(train_df_run)}\")\n",
    "\n",
    "\n",
    "print(f\"Usando medias de ImageNet para el script de Run: {MEANS_IMAGENET}\")\n",
    "print(f\"Usando desviaciones estándar de ImageNet para el script de Run: {STDS_IMAGENET}\")\n",
    "\n",
    "print(\"DEBUG: Usando pipeline de transformación de entrenamiento MÍNIMO con BboxParams por DEFECTO.\")\n",
    "run_train_transforms = A.Compose([\n",
    "    A.Resize(height=TARGET_H, width=TARGET_W), \n",
    "    #A.HorizontalFlip(p=0.5),\n",
    "    #A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=0.2), # <<< MUY SUAVE y p baja\n",
    "    #A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.02, rotate_limit=5, p=0.2, border_mode=cv2.BORDER_CONSTANT), # 'value' eliminado; si da warning, comenta la línea.\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2() \n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "run_eval_transforms = A.Compose([ \n",
    "    A.Resize(height=TARGET_H, width=TARGET_W),\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "print(\"Creando Datasets y DataLoaders finales para el script de Run...\")\n",
    "# ... (Creación de train_dataset_run, val_dataset_run como antes) ...\n",
    "if not train_df_run.empty:\n",
    "    train_dataset_run = militarDataset(df=train_df_run, img_dir=img_dir_run, transform=run_train_transforms)\n",
    "else:\n",
    "    train_dataset_run = [] \n",
    "    print(\"Advertencia: train_df_run está vacío, train_dataset_run será una lista vacía.\")\n",
    "if not val_df_run.empty:\n",
    "    val_dataset_run = militarDataset(df=val_df_run, img_dir=img_dir_run, transform=run_eval_transforms)\n",
    "else:\n",
    "    val_dataset_run = []\n",
    "    print(\"Advertencia: val_df_run está vacío, val_dataset_run será una lista vacía.\")\n",
    "\n",
    "# ... (Bucle de inspección de train_dataset_run como antes) ...\n",
    "if len(train_dataset_run) > 0:\n",
    "    print(f\"\\nDEBUG: Inspeccionando las primeras (hasta) 5 muestras de train_dataset_run (longitud total: {len(train_dataset_run)}):\")\n",
    "    valid_samples_count_debug = 0\n",
    "    for i in range(min(5, len(train_dataset_run))):\n",
    "        # print(f\"  DEBUG: Intentando obtener train_dataset_run[{i}]...\") # Puede ser muy verboso\n",
    "        try:\n",
    "            sample = train_dataset_run[i] \n",
    "            if sample is None:\n",
    "                # print(f\"    DEBUG: train_dataset_run[{i}] devolvió None.\")\n",
    "                pass\n",
    "            else:\n",
    "                # img_tensor, cls_tensor, bbox_tensor = sample\n",
    "                # print(f\"    DEBUG: train_dataset_run[{i}] OK. img_shape={img_tensor.shape}, cls_id={cls_tensor.item()}, bbox={bbox_tensor.squeeze().tolist()}\")\n",
    "                valid_samples_count_debug += 1\n",
    "        except Exception as e:\n",
    "            # print(f\"    DEBUG: Error al obtener train_dataset_run[{i}]: {e}\")\n",
    "            pass\n",
    "    print(f\"DEBUG: De las primeras muestras inspeccionadas, {valid_samples_count_debug} fueron válidas.\\n\")\n",
    "    if len(train_df_run) > 0 and valid_samples_count_debug == 0 and len(train_dataset_run) > 0: \n",
    "        print(\"ALERTA DE DEBUG: Ninguna de las primeras muestras del dataset de entrenamiento es válida. Revisa los prints internos de 'militarDataset'.\")\n",
    "else:\n",
    "    print(\"DEBUG: train_dataset_run está vacío o es una lista vacía, no se pueden inspeccionar muestras.\")\n",
    "\n",
    "\n",
    "# ... (Creación de DataLoaders como antes) ...\n",
    "if len(train_dataset_run) > 0: \n",
    "    train_loader_run = DataLoader(train_dataset_run, batch_size=BATCH_SIZE_RUN, shuffle=True,\n",
    "                                  num_workers=0, generator=generator, collate_fn=collate_fn_skip_none)\n",
    "else:\n",
    "    train_loader_run = None \n",
    "    print(\"Advertencia: El DataLoader de entrenamiento (train_loader_run) no se creará porque el dataset está vacío.\")\n",
    "if len(val_dataset_run) > 0:\n",
    "    val_loader_run = DataLoader(val_dataset_run, batch_size=BATCH_SIZE_RUN, shuffle=False,\n",
    "                                num_workers=0, generator=generator, collate_fn=collate_fn_skip_none)\n",
    "else:\n",
    "    val_loader_run = None\n",
    "    print(\"Advertencia: El DataLoader de validación (val_loader_run) no se creará porque el dataset está vacío.\")\n",
    "\n",
    "device_run = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo para el script de Run: {device_run}\")\n",
    "\n",
    "\n",
    "model_run = ResNet50MultiTaskModel(num_classes=NUM_CLASSES, \n",
    "                                   freeze_backbone=True, \n",
    "                                   use_deeper_bbox_head=False).to(device_run)\n",
    "print(\"Usando cabeza de regresión de BBox MÁS PROFUNDA.\")\n",
    "\n",
    "\n",
    "classification_criterion_run = nn.CrossEntropyLoss() #(Probado: )\n",
    "bbox_criterion_run = nn.SmoothL1Loss() # 📌 AJUSTA AQUÍ (Probado: nn.L1Loss(); nn.SmoothL1Loss()) #Probar:  \n",
    "\n",
    "\n",
    "params_to_train_run = [param for param in model_run.parameters() if param.requires_grad]\n",
    "if not params_to_train_run:\n",
    "    print(\"ERROR: No hay parámetros para entrenar. Verifica 'freeze_backbone'.\")\n",
    "    optimizer_run = None\n",
    "    scheduler_run = None \n",
    "else:\n",
    "    optimizer_run = optim.Adam(params_to_train_run, lr=1e-3) # O el lr que estés usando\n",
    "    scheduler_run = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_run, \n",
    "        mode='min',     \n",
    "        factor=0.1,     \n",
    "        patience=7,     # Paciencia del scheduler\n",
    "        min_lr=1e-6     \n",
    "    )\n",
    "\n",
    "\n",
    "# Generar nombre de archivo con fecha y hora y usar RUTA ABSOLUTA ---\n",
    "ahora = datetime.now() \n",
    "timestamp_str = ahora.strftime(\"%Y%m%d_%H%M\") \n",
    "model_filename = f\"pretrained_model_{timestamp_str}.pth\"\n",
    "\n",
    "model_save_path_run = osp.join(absolute_dir_results, model_filename) \n",
    "\n",
    "# --- Generar nombre de archivo para guardar el modelo de ESTA EJECUCIÓN ---\n",
    "timestamp_str_run = ahora.strftime(\"%Y%m%d_%H%M%S\") # Segundos para mayor unicidad\n",
    "model_filename_run = f\"pretrained_model_{timestamp_str_run}.pth\"\n",
    "model_save_path_run = osp.join(DIR_Results, model_filename_run) \n",
    "print(f\"DEBUG: El modelo se guardará en la ruta absoluta: {model_save_path_run}\")\n",
    "\n",
    "\n",
    "print(\"Iniciando el proceso de entrenamiento del script de Run...\")\n",
    "APPLY_SIGMOID_FLAG_RUN = True \n",
    "print(f\"APPLY_SIGMOID_TO_BBOX_PRED para el script de Run está configurado a: {APPLY_SIGMOID_FLAG_RUN}\")\n",
    "\n",
    "if train_loader_run is not None and optimizer_run is not None: \n",
    "    trained_model_run, history_run = train_multitask_model(\n",
    "        model=model_run,\n",
    "        train_loader=train_loader_run,\n",
    "        val_loader=val_loader_run, \n",
    "        classification_criterion=classification_criterion_run,\n",
    "        bbox_criterion=bbox_criterion_run,\n",
    "        optimizer=optimizer_run,\n",
    "        device=device_run,\n",
    "        num_epochs=120, # 📌 AJUSTA AQUÍ \n",
    "        bbox_loss_weight=20.0, # 📌 AJUSTA AQUÍ \n",
    "        patience=15, # 📌 AJUSTA AQUÍ \n",
    "        model_save_path=model_save_path_run,\n",
    "        apply_sigmoid_to_bbox_pred=APPLY_SIGMOID_FLAG_RUN\n",
    "    )\n",
    "    print(\"Entrenamiento del script de Run completado.\")\n",
    "else:\n",
    "    print(\"No se ejecutó el entrenamiento del script de Run porque el train_loader_run está vacío/None o no hay parámetros para entrenar.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11672293,
     "sourceId": 97986,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.783225,
   "end_time": "2025-04-07T23:00:47.759016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T22:59:35.975791",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16394c8b0b3548a6bb7e6e85ba5b8edd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ceedf1613b3f443b873ba8471e890791",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aac01175d6064acab51e786670626698",
       "tabbable": null,
       "tooltip": null,
       "value": 0
      }
     },
     "3f3bbfbb2a5a4cc49ea2f20768f807c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "443b9d0093a240bf896a39621d7bee5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "65eb9bb216c84d4d8b3c16df62a3eca9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_702de51199b84f548dc10f0ff02dcef4",
       "placeholder": "​",
       "style": "IPY_MODEL_3f3bbfbb2a5a4cc49ea2f20768f807c6",
       "tabbable": null,
       "tooltip": null,
       "value": " 0/? [00:00&lt;?, ?it/s]"
      }
     },
     "702de51199b84f548dc10f0ff02dcef4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a99616741eb4ab7a541d30173dd8551": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aac01175d6064acab51e786670626698": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b2a7dd969aa748e793936bdc159cdc0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd70270271fa49678e0a595be7e997f5",
       "placeholder": "​",
       "style": "IPY_MODEL_443b9d0093a240bf896a39621d7bee5e",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "ceedf1613b3f443b873ba8471e890791": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "da7fa9424ee84549bafebc2adda3d104": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b2a7dd969aa748e793936bdc159cdc0d",
        "IPY_MODEL_16394c8b0b3548a6bb7e6e85ba5b8edd",
        "IPY_MODEL_65eb9bb216c84d4d8b3c16df62a3eca9"
       ],
       "layout": "IPY_MODEL_7a99616741eb4ab7a541d30173dd8551",
       "tabbable": null,
       "tooltip": null
      }
     },
     "dd70270271fa49678e0a595be7e997f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
