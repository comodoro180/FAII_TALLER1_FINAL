{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282215d1",
   "metadata": {
    "papermill": {
     "duration": 0.016676,
     "end_time": "2025-04-07T22:59:38.735429",
     "exception": false,
     "start_time": "2025-04-07T22:59:38.718753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2011d56",
   "metadata": {
    "papermill": {
     "duration": 0.009755,
     "end_time": "2025-04-07T22:59:38.755698",
     "exception": false,
     "start_time": "2025-04-07T22:59:38.745943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae19e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%pip install torchsummary albumentations wandb --quiet\\n%pip install tqdm \\n%pip install pandas \\n%pip install torch\\n%pip install PIL\\n%pip install torchvision\\n%pip install matplotlib\\n%pip install scikit-learn\\n%pip install scikit-image\\n%pip install setuptools\\n%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n%pip install optuna '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%pip install torchsummary albumentations wandb --quiet\n",
    "%pip install tqdm \n",
    "%pip install pandas \n",
    "%pip install torch\n",
    "%pip install PIL\n",
    "%pip install torchvision\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install scikit-image\n",
    "%pip install setuptools\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install optuna '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e826f10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allc0363\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.6'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\allc0363\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import typing as ty\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from itertools import chain, islice\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from skimage import io, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.ops import box_iou\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import wandb\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1dbbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e465e538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2675bbbd290>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un generador para el DataLoader\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa521595",
   "metadata": {
    "papermill": {
     "duration": 0.010047,
     "end_time": "2025-04-07T22:59:52.115831",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.105784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3511cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../Datos/' \n",
    "WORK_DIR = '../Datos/' \n",
    "DIR_Results = './Resultados/'\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "IMG_ORIG_H, IMG_ORIG_W = 720, 1280\n",
    "TARGET_H, TARGET_W = 224, 224 \n",
    "\n",
    "img_dir = osp.join(DATA_DIR, \"images/images\")\n",
    "df = pd.read_csv(osp.join(DATA_DIR, \"train.csv\"))\n",
    "\n",
    "obj2id  = {'f16':0,'cougar':1,'chinook':2,'ah64':3,'f15':4,'seahawk':5}\n",
    "#obj2id = {'f16':0, 'cougar':1, 'chinook':2, 'ah64':3, 'f15':4, 'seahawk':5}\n",
    "id2obj = {v: k for k, v in obj2id.items()} \n",
    "\n",
    "NUM_CLASSES = len(obj2id)\n",
    "MEANS_IMAGENET = [0.485, 0.456, 0.406] \n",
    "STDS_IMAGENET = [0.229, 0.224, 0.225]  \n",
    "\n",
    "df[\"class_id\"] = df[\"class\"].map(obj2id)\n",
    "columns_f=['filename','xmin','ymin','xmax','ymax','class','class_id']\n",
    "df= df[columns_f].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1301579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global: TARGET_H=224, TARGET_W=224, NUM_CLASSES=6\n",
      "Global: IMG_ORIG_H=720, IMG_ORIG_W=1280\n"
     ]
    }
   ],
   "source": [
    "print(f\"Global: TARGET_H={TARGET_H}, TARGET_W={TARGET_W}, NUM_CLASSES={NUM_CLASSES}\")\n",
    "print(f\"Global: IMG_ORIG_H={IMG_ORIG_H}, IMG_ORIG_W={IMG_ORIG_W}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d6fb3",
   "metadata": {
    "papermill": {
     "duration": 0.009851,
     "end_time": "2025-04-07T22:59:52.204505",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.194654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd3bd31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.225659Z",
     "iopub.status.busy": "2025-04-07T22:59:52.225404Z",
     "iopub.status.idle": "2025-04-07T22:59:52.325826Z",
     "shell.execute_reply": "2025-04-07T22:59:52.324926Z"
    },
    "papermill": {
     "duration": 0.112991,
     "end_time": "2025-04-07T22:59:52.327459",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.214468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_filename = osp.join(DATA_DIR, \"images/images\",'image_00077.jpeg')\n",
    "\n",
    "img1 = cv2.imread(img_filename)\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = io.imread(img_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5efba73b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.349085Z",
     "iopub.status.busy": "2025-04-07T22:59:52.348843Z",
     "iopub.status.idle": "2025-04-07T22:59:52.352980Z",
     "shell.execute_reply": "2025-04-07T22:59:52.352286Z"
    },
    "papermill": {
     "duration": 0.016291,
     "end_time": "2025-04-07T22:59:52.354133",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.337842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "(3, 720, 1280)\n"
     ]
    }
   ],
   "source": [
    "print(img1.shape)\n",
    "print(img1.transpose((2,0,1)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6543d9ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.376495Z",
     "iopub.status.busy": "2025-04-07T22:59:52.376268Z",
     "iopub.status.idle": "2025-04-07T22:59:55.005361Z",
     "shell.execute_reply": "2025-04-07T22:59:55.004526Z"
    },
    "papermill": {
     "duration": 2.641242,
     "end_time": "2025-04-07T22:59:55.006753",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.365511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 189/189 [00:01<00:00, 131.40it/s]\n"
     ]
    }
   ],
   "source": [
    "list_image = list(df.filename)\n",
    "data_shape = []\n",
    "data_dim = []\n",
    "data_w = []\n",
    "data_h = []\n",
    "\n",
    "for i in tqdm(list_image): ## tqdm(list_image)dura 40 segundos\n",
    "    ruta_imagen = osp.join(img_dir, i)\n",
    "    imagen = io.imread(ruta_imagen)\n",
    "    shapes = imagen.shape\n",
    "    dimen = imagen.ndim\n",
    "    imagen = Image.open(ruta_imagen)\n",
    "    w, h = imagen.size\n",
    "    \n",
    "    data_w.append(w)\n",
    "    data_h.append(h)\n",
    "    data_shape.append(shapes)\n",
    "    data_dim.append(dimen)\n",
    "\n",
    "data_w_h = pd.DataFrame([list_image,data_shape,data_dim,data_w,data_h]).T.rename(columns={0:'filename',1:'shapes',2:'ndim',3:'w',4:'h'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e071a90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.030465Z",
     "iopub.status.busy": "2025-04-07T22:59:55.030178Z",
     "iopub.status.idle": "2025-04-07T22:59:55.039998Z",
     "shell.execute_reply": "2025-04-07T22:59:55.039336Z"
    },
    "papermill": {
     "duration": 0.022737,
     "end_time": "2025-04-07T22:59:55.041156",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.018419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w\n",
       "1280    189\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_h['w'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d6b57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.064527Z",
     "iopub.status.busy": "2025-04-07T22:59:55.064283Z",
     "iopub.status.idle": "2025-04-07T22:59:55.069700Z",
     "shell.execute_reply": "2025-04-07T22:59:55.069042Z"
    },
    "papermill": {
     "duration": 0.018239,
     "end_time": "2025-04-07T22:59:55.070844",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.052605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ndim\n",
       "3    189\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_h['ndim'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f41c81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.094434Z",
     "iopub.status.busy": "2025-04-07T22:59:55.094166Z",
     "iopub.status.idle": "2025-04-07T22:59:55.100319Z",
     "shell.execute_reply": "2025-04-07T22:59:55.099444Z"
    },
    "papermill": {
     "duration": 0.019167,
     "end_time": "2025-04-07T22:59:55.101580",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.082413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shapes\n",
       "(720, 1280, 3)    189\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_h['shapes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae60b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.125406Z",
     "iopub.status.busy": "2025-04-07T22:59:55.125136Z",
     "iopub.status.idle": "2025-04-07T22:59:55.131514Z",
     "shell.execute_reply": "2025-04-07T22:59:55.130710Z"
    },
    "papermill": {
     "duration": 0.019562,
     "end_time": "2025-04-07T22:59:55.132734",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.113172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_id\n",
       "0    41\n",
       "1    37\n",
       "2    35\n",
       "3    34\n",
       "4    23\n",
       "5    19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a308b33b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.157130Z",
     "iopub.status.busy": "2025-04-07T22:59:55.156885Z",
     "iopub.status.idle": "2025-04-07T22:59:55.162977Z",
     "shell.execute_reply": "2025-04-07T22:59:55.162127Z"
    },
    "papermill": {
     "duration": 0.019619,
     "end_time": "2025-04-07T22:59:55.164326",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.144707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "f16        41\n",
       "cougar     37\n",
       "chinook    35\n",
       "ah64       34\n",
       "f15        23\n",
       "seahawk    19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ae5293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.188357Z",
     "iopub.status.busy": "2025-04-07T22:59:55.188113Z",
     "iopub.status.idle": "2025-04-07T22:59:55.193849Z",
     "shell.execute_reply": "2025-04-07T22:59:55.193147Z"
    },
    "papermill": {
     "duration": 0.01912,
     "end_time": "2025-04-07T22:59:55.195028",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.175908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 7), (0, 7))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['xmin']>=df['xmax']].shape, df[df['ymin']>=df['ymax']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa249fc",
   "metadata": {
    "papermill": {
     "duration": 0.011273,
     "end_time": "2025-04-07T22:59:55.246598",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.235325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalizamos los bboxes (En la siguiente monitoria hablaremos de la importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed1e5e2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.270360Z",
     "iopub.status.busy": "2025-04-07T22:59:55.270085Z",
     "iopub.status.idle": "2025-04-07T22:59:55.291960Z",
     "shell.execute_reply": "2025-04-07T22:59:55.291089Z"
    },
    "papermill": {
     "duration": 0.035167,
     "end_time": "2025-04-07T22:59:55.293184",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.258017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ymin        ymax        xmin         xmax\n",
      "count  189.000000  189.000000  189.000000   189.000000\n",
      "mean   186.396825  425.455026  401.238095   902.666667\n",
      "std    112.079883  103.348946  232.361996   213.588688\n",
      "min      1.000000  154.000000    1.000000   298.000000\n",
      "25%    109.000000  359.000000  210.000000   730.000000\n",
      "50%    188.000000  417.000000  418.000000   901.000000\n",
      "75%    267.000000  494.000000  572.000000  1071.000000\n",
      "max    440.000000  702.000000  944.000000  1280.000000\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"ymin\", \"ymax\", \"xmin\", \"xmax\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10389b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizaci贸n de Bounding Boxes.\n",
    "# Las coordenadas se convierten a relativas [0,1].\n",
    "df[[\"ymin\", \"ymax\"]] = df[[\"ymin\", \"ymax\"]].div(IMG_ORIG_H, axis=0)\n",
    "df[[\"xmin\", \"xmax\"]] = df[[\"xmin\", \"xmax\"]].div(IMG_ORIG_W, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "accb9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que los bboxes est茅n acotados a [0,1] despu茅s de la normalizaci贸n\n",
    "df[['xmin', 'ymin', 'xmax', 'ymax']] = df[['xmin', 'ymin', 'xmax', 'ymax']].clip(0.0, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bc1f4af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.349071Z",
     "iopub.status.busy": "2025-04-07T22:59:55.348826Z",
     "iopub.status.idle": "2025-04-07T22:59:55.361872Z",
     "shell.execute_reply": "2025-04-07T22:59:55.361223Z"
    },
    "papermill": {
     "duration": 0.026846,
     "end_time": "2025-04-07T22:59:55.363577",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.336731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ymin        ymax        xmin        xmax\n",
      "count  189.000000  189.000000  189.000000  189.000000\n",
      "mean     0.258884    0.590910    0.313467    0.705208\n",
      "std      0.155667    0.143540    0.181533    0.166866\n",
      "min      0.001389    0.213889    0.000781    0.232813\n",
      "25%      0.151389    0.498611    0.164062    0.570312\n",
      "50%      0.261111    0.579167    0.326562    0.703906\n",
      "75%      0.370833    0.686111    0.446875    0.836719\n",
      "max      0.611111    0.975000    0.737500    1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"ymin\", \"ymax\", \"xmin\", \"xmax\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca908b2f",
   "metadata": {
    "papermill": {
     "duration": 0.011617,
     "end_time": "2025-04-07T22:59:55.387443",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.375826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Particionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c0a403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.412138Z",
     "iopub.status.busy": "2025-04-07T22:59:55.411871Z",
     "iopub.status.idle": "2025-04-07T22:59:55.418848Z",
     "shell.execute_reply": "2025-04-07T22:59:55.418165Z"
    },
    "papermill": {
     "duration": 0.020781,
     "end_time": "2025-04-07T22:59:55.420086",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.399305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c24d0582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.444859Z",
     "iopub.status.busy": "2025-04-07T22:59:55.444635Z",
     "iopub.status.idle": "2025-04-07T22:59:55.450846Z",
     "shell.execute_reply": "2025-04-07T22:59:55.449988Z"
    },
    "papermill": {
     "duration": 0.019809,
     "end_time": "2025-04-07T22:59:55.452158",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.432349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "f16        21.854305\n",
       "cougar     19.867550\n",
       "chinook    18.543046\n",
       "ah64       17.880795\n",
       "f15        11.920530\n",
       "seahawk     9.933775\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class'].value_counts(1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aae1ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.476944Z",
     "iopub.status.busy": "2025-04-07T22:59:55.476726Z",
     "iopub.status.idle": "2025-04-07T22:59:55.482578Z",
     "shell.execute_reply": "2025-04-07T22:59:55.481788Z"
    },
    "papermill": {
     "duration": 0.019392,
     "end_time": "2025-04-07T22:59:55.483775",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.464383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_id\n",
       "0    21.052632\n",
       "3    18.421053\n",
       "2    18.421053\n",
       "1    18.421053\n",
       "4    13.157895\n",
       "5    10.526316\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['class_id'].value_counts(1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28a5e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. Funciones y Clases Auxiliares ---\n",
    "def reset_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7551c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# DEFINICIN DE collate_fn_skip_none \n",
    "def collate_fn_skip_none(batch):\n",
    "    batch_original_len = len(batch)\n",
    "    batch_filtered = [item for item in batch if item is not None]\n",
    "    \n",
    "    if batch_original_len != len(batch_filtered) and batch_original_len > 0 :\n",
    "        # print(f\"DEBUG collate_fn: Original batch len: {batch_original_len}, Filtered batch len: {len(batch_filtered)}. {batch_original_len - len(batch_filtered)} muestra(s) eran None.\")\n",
    "        pass\n",
    "\n",
    "    if not batch_filtered:\n",
    "        # print(\"DEBUG collate_fn: Entire batch is None after filtering.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return torch.utils.data.dataloader.default_collate(batch_filtered)\n",
    "    except Exception as e:\n",
    "        # print(f\"ERROR en default_collate dentro de collate_fn_skip_none: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03522bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiciones de Clases de Transformaci贸n\n",
    "class ToTensorDict:\n",
    "    def __call__(self, sample):\n",
    "        image, bbox, class_id = sample['image'], sample['bbox'], sample['class_id']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample['image'] = torch.from_numpy(image.copy()).float().div(255.0)\n",
    "        sample['bbox'] = bbox \n",
    "        sample['class_id'] = class_id\n",
    "        return sample\n",
    "\n",
    "class NormalizeDict:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.tensor(mean, dtype=torch.float32).view(3, 1, 1)\n",
    "        self.std = torch.tensor(std, dtype=torch.float32).view(3, 1, 1)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = (sample['image'] - self.mean) / self.std\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d194f",
   "metadata": {
    "papermill": {
     "duration": 0.011616,
     "end_time": "2025-04-07T22:59:55.507333",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.495717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Clase para estructura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4067aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class militarDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, labeled=True): \n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.labeled = labeled \n",
    "        print(f\"DEBUG militarDataset: Inicializado con {len(self.df)} filas. Transformaciones: {'S铆' if self.transform else 'No'}. Labeled: {self.labeled}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        if idx >= len(self.df):\n",
    "            print(f\"DEBUG militarDataset: ndice {idx} fuera de rango para DataFrame (len {len(self.df)}). Devolviendo None.\")\n",
    "            return None\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        img_filename = row.get('filename', f\"DESCONOCIDO_idx_{idx}\")\n",
    "        \n",
    "        try:\n",
    "            img_path = os.path.join(self.img_dir, img_filename)\n",
    "            if not osp.exists(img_path):\n",
    "                print(f\"DEBUG militarDataset: RUTA DE IMAGEN NO EXISTE {img_path} para {img_filename}. Saltando.\")\n",
    "                return None\n",
    "            pil_image = Image.open(img_path).convert('RGB')\n",
    "            numpy_image = np.array(pil_image)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"DEBUG militarDataset: FileNotFoundError para {img_path} ({img_filename}). Saltando.\")\n",
    "            return None\n",
    "        except UnidentifiedImageError:\n",
    "            print(f\"DEBUG militarDataset: UnidentifiedImageError para {img_path} ({img_filename}). Saltando.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"DEBUG militarDataset: Error cargando imagen {img_filename} ({img_path}): {e}. Saltando.\")\n",
    "            return None\n",
    "        \n",
    "        # --- SI ES PARA TEST (NO ETIQUETADO) ---\n",
    "        if not self.labeled:\n",
    "            sample_to_transform = {'image': numpy_image}\n",
    "            if self.transform:\n",
    "                try:\n",
    "                    transformed = self.transform(**sample_to_transform)\n",
    "                    image_tensor = transformed['image']\n",
    "                    return image_tensor #  Devolver solo la imagen transformada\n",
    "                except Exception as e:\n",
    "                    print(f\"DEBUG militarDataset: Error aplicando transformaci贸n (test) para {img_filename} (idx {idx}): {e}. Saltando.\")\n",
    "                    return None\n",
    "            else: # Si no hay transformaciones (aunque para test deber铆as al menos tener Resize, Normalize, ToTensorV2)\n",
    "                return torch.from_numpy(numpy_image.transpose((2, 0, 1))).float().div(255.0)\n",
    "\n",
    "        # --- SI ES PARA ENTRENAMIENTO/VALIDACIN (ETIQUETADO) ---\n",
    "        try:\n",
    "            bbox_coords = row[['xmin', 'ymin', 'xmax', 'ymax']].values.astype(np.float32)\n",
    "            class_id_val = int(row['class_id'])\n",
    "        except KeyError as e:\n",
    "            print(f\"DEBUG militarDataset: Falta columna {e} para {img_filename} (idx {idx}) aunque labeled=True. Saltando.\")\n",
    "            return None\n",
    "        except ValueError as e:\n",
    "            print(f\"DEBUG militarDataset: Valor inv谩lido en bbox o class_id para {img_filename} (idx {idx}): {e}. Saltando.\")\n",
    "            return None\n",
    "\n",
    "        \n",
    "        if not (0 <= class_id_val < NUM_CLASSES):\n",
    "            print(f\"DEBUG militarDataset: class_id {class_id_val} fuera de rango [0, {NUM_CLASSES-1}] para {img_filename} (idx {idx}). Saltando.\")\n",
    "            return None\n",
    "\n",
    "        sample_to_transform = {\n",
    "            'image': numpy_image,\n",
    "            'bboxes': [bbox_coords.tolist()], \n",
    "            'class_labels': [class_id_val] \n",
    "        }\n",
    "\n",
    "        image_tensor, class_id_tensor, bbox_tensor = None, None, None\n",
    "\n",
    "        if self.transform:\n",
    "            try:\n",
    "                transformed = self.transform(**sample_to_transform)\n",
    "                \n",
    "                img_from_transform = transformed.get('image')\n",
    "                bboxes_from_transform = transformed.get('bboxes')\n",
    "                class_labels_from_transform = transformed.get('class_labels')\n",
    "\n",
    "                if img_from_transform is None:\n",
    "                    print(f\"DEBUG militarDataset: 'image' es None post-transformaci贸n para {img_filename} (idx {idx}). Saltando.\")\n",
    "                    return None\n",
    "                image_tensor = img_from_transform\n",
    "\n",
    "                if bboxes_from_transform and len(bboxes_from_transform) > 0:\n",
    "                    current_bbox = bboxes_from_transform[0]\n",
    "                    if isinstance(current_bbox, (list, tuple, np.ndarray)) and len(current_bbox) == 4:\n",
    "                        bbox_tensor = torch.tensor(current_bbox, dtype=torch.float32).unsqueeze(0)\n",
    "                        \n",
    "                        if class_labels_from_transform and len(class_labels_from_transform) > 0:\n",
    "                            _class_id_item = class_labels_from_transform[0]\n",
    "                            if not (0 <= _class_id_item < NUM_CLASSES):\n",
    "                                print(f\"DEBUG militarDataset: class_id {_class_id_item} post-transform fuera de rango para {img_filename} (idx {idx}). Saltando.\")\n",
    "                                return None\n",
    "                            class_id_tensor = torch.tensor(_class_id_item, dtype=torch.long)\n",
    "                        else:\n",
    "                            print(f\"DEBUG militarDataset: class_labels perdidas post-transformaci贸n para {img_filename} (idx {idx}). Saltando.\")\n",
    "                            return None \n",
    "                    else:\n",
    "                        print(f\"DEBUG militarDataset: Formato de bbox inesperado para {img_filename} (idx {idx}) post-transformaci贸n. Saltando.\")\n",
    "                        return None\n",
    "                else: \n",
    "                    print(f\"DEBUG militarDataset: Bbox para {img_filename} (idx {idx}) removido o vac铆o post-transformaci贸n. Saltando.\")\n",
    "                    return None\n",
    "                \n",
    "                if not (isinstance(image_tensor, torch.Tensor) and \n",
    "                        isinstance(class_id_tensor, torch.Tensor) and \n",
    "                        isinstance(bbox_tensor, torch.Tensor)):\n",
    "                    print(f\"DEBUG militarDataset: Componente no es Tensor para {img_filename} (idx {idx}) post-transform. Saltando.\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"DEBUG militarDataset: Error aplicando/procesando transformaci贸n (train/val) para {img_filename} (idx {idx}): {e}. Saltando.\")\n",
    "                return None\n",
    "        else: \n",
    "            if not (0 <= class_id_val < NUM_CLASSES):\n",
    "                print(f\"DEBUG militarDataset: class_id {class_id_val} (sin transform) fuera de rango para {img_filename} (idx {idx}). Saltando.\")\n",
    "                return None\n",
    "            image_tensor = torch.from_numpy(numpy_image.transpose((2, 0, 1))).float().div(255.0)\n",
    "            bbox_tensor = torch.tensor(bbox_coords, dtype=torch.float32).unsqueeze(0)\n",
    "            class_id_tensor = torch.tensor(class_id_val, dtype=torch.long)\n",
    "        \n",
    "        return image_tensor, class_id_tensor, bbox_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7f2b4",
   "metadata": {
    "papermill": {
     "duration": 0.022342,
     "end_time": "2025-04-07T22:59:56.589719",
     "exception": false,
     "start_time": "2025-04-07T22:59:56.567377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalizaci贸n (Ahora de los p铆xeles, es diferente a la normalizaci贸n anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52a6a252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando medias de ImageNet: [0.485, 0.456, 0.406]\n",
      "Usando desviaciones est谩ndar de ImageNet: [0.229, 0.224, 0.225]\n"
     ]
    }
   ],
   "source": [
    "# Definir medias y desviaciones est谩ndar\n",
    "MEANS_IMAGENET = [0.485, 0.456, 0.406]\n",
    "STDS_IMAGENET = [0.229, 0.224, 0.225]\n",
    "print(f\"Usando medias de ImageNet: {MEANS_IMAGENET}\")\n",
    "print(f\"Usando desviaciones est谩ndar de ImageNet: {STDS_IMAGENET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27d62a",
   "metadata": {
    "papermill": {
     "duration": 0.021929,
     "end_time": "2025-04-07T22:59:59.630713",
     "exception": false,
     "start_time": "2025-04-07T22:59:59.608784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18a80dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allc0363\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\albumentations\\core\\validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\allc0363\\AppData\\Local\\Temp\\ipykernel_34400\\3914898059.py:6: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
      "  A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT, value = 0),\n"
     ]
    }
   ],
   "source": [
    "train_transforms = A.Compose([\n",
    "    A.Resize(height=TARGET_H, width=TARGET_W),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2), \n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT, value = 0), \n",
    "    # A.CoarseDropout(max_holes=8, max_height=TARGET_H//10, max_width=TARGET_W//10, min_holes=1, min_height=TARGET_H//20, min_width=TARGET_W//20, fill_value=0, p=0.3),\n",
    "    # Normalizaci贸n est谩ndar de ResNet. max_pixel_value=255.0 asegura la divisi贸n por 255.\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2() # Convierte imagen a tensor PyTorch (C, H, W). No afecta bboxes.\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels'], min_area=16, min_visibility=0.2)) # pascal_voc: [xmin, ymin, xmax, ymax]\n",
    "\n",
    "eval_transforms = A.Compose([\n",
    "    A.Resize(height=TARGET_H, width=TARGET_W),\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels'])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d857848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Definiendo transformaciones globales train_transforms y eval_transforms con pipeline MNIMO.\n",
      "DEBUG: Creando train_dataset y val_dataset GLOBALES con las transformaciones simplificadas.\n",
      "DEBUG militarDataset: Inicializado con 151 filas. Transformaciones: S铆. Labeled: True\n",
      "DEBUG: train_dataset global creado con 151 items.\n",
      "DEBUG militarDataset: Inicializado con 38 filas. Transformaciones: S铆. Labeled: True\n",
      "DEBUG: val_dataset global creado con 38 items.\n"
     ]
    }
   ],
   "source": [
    "# train_transforms y eval_transforms globales\n",
    "\n",
    "print(\"DEBUG: Definiendo transformaciones globales train_transforms y eval_transforms con pipeline MNIMO.\")\n",
    "\n",
    "# ---  MODIFICACIN DRSTICA DE train_transforms (global) ---\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(height=TARGET_H, width=TARGET_W), # Necesario\n",
    "    # --- Temporalmente SIN otras aumentaciones ---\n",
    "    # A.HorizontalFlip(p=0.5),\n",
    "    # A.VerticalFlip(p=0.2),\n",
    "    # A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3), # Intensidad reducida\n",
    "    # A.ShiftScaleRotate(shift_limit=0.03, scale_limit=0.03, rotate_limit=10, p=0.3, \n",
    "    #                    border_mode=cv2.BORDER_CONSTANT), # 'value' eliminado o comentada la l铆nea entera si da warning\n",
    "    \n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0), # Necesario\n",
    "    ToTensorV2() # Necesario\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', \n",
    "                             label_fields=['class_labels'], \n",
    "                             min_area=1,       #  VALOR MS PERMISIVO POSIBLE\n",
    "                             min_visibility=0.0 #  VALOR MS PERMISIVO POSIBLE\n",
    "                            ))\n",
    "\n",
    "\n",
    "eval_transforms = A.Compose([ \n",
    "    A.Resize(height=TARGET_H, width=TARGET_W),\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "\n",
    "print(\"DEBUG: Creando train_dataset y val_dataset GLOBALES con las transformaciones simplificadas.\")\n",
    "\n",
    "if 'train_df' in locals() and not train_df.empty: # Comprueba si train_df existe y no est谩 vac铆o\n",
    "    train_dataset = militarDataset(df=train_df, img_dir=img_dir, transform=train_transforms)\n",
    "    print(f\"DEBUG: train_dataset global creado con {len(train_dataset)} items.\")\n",
    "else:\n",
    "    print(\"Advertencia: train_df global no est谩 definido o est谩 vac铆o. No se cre贸 train_dataset global.\")\n",
    "    train_dataset = [] # o None\n",
    "\n",
    "if 'val_df' in locals() and not val_df.empty: # Comprueba si val_df existe y no est谩 vac铆o\n",
    "    val_dataset = militarDataset(df=val_df, img_dir=img_dir, transform=eval_transforms)\n",
    "    print(f\"DEBUG: val_dataset global creado con {len(val_dataset)} items.\")\n",
    "else:\n",
    "    print(\"Advertencia: val_df global no est谩 definido o est谩 vac铆o. No se cre贸 val_dataset global.\")\n",
    "    val_dataset = [] # o None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4191b",
   "metadata": {
    "papermill": {
     "duration": 0.021938,
     "end_time": "2025-04-07T23:00:00.139010",
     "exception": false,
     "start_time": "2025-04-07T23:00:00.117072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0aee77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50MultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_classes=6, dropout=0.5, freeze_backbone=True, use_deeper_bbox_head=False): # Nuevo argumento\n",
    "        super(ResNet50MultiTaskModel, self).__init__()\n",
    "\n",
    "        # Cargar el modelo base ResNet50 pre-entrenado\n",
    "        base_model = resnet50(weights=ResNet50_Weights.DEFAULT) #\n",
    "\n",
    "        # Congelar los pesos del backbone si se especifica\n",
    "        if freeze_backbone: #\n",
    "            for param in base_model.parameters(): #\n",
    "                param.requires_grad = False #\n",
    "\n",
    "        # Extractor de caracter铆sticas (todas las capas de ResNet excepto avgpool y fc)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2]) #\n",
    "        \n",
    "        # Pooling adaptativo para obtener un tama帽o de salida fijo\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1)) #\n",
    "        \n",
    "        # Capa para aplanar las caracter铆sticas\n",
    "        self.flatten = nn.Flatten() #\n",
    "\n",
    "        # --- Cabeza de Clasificaci贸n ---\n",
    "        self.classification_dropout = nn.Dropout(dropout) #\n",
    "        # La capa de entrada para el clasificador es 2048 (salida de ResNet50 antes de avgpool)\n",
    "        self.classifier = nn.Linear(base_model.fc.in_features, num_classes) #\n",
    "\n",
    "        # --- Cabeza de Regresi贸n de Bounding Box ---\n",
    "        self.bbox_dropout = nn.Dropout(dropout) #\n",
    "        \n",
    "        if use_deeper_bbox_head:\n",
    "            print(\"Usando cabeza de regresi贸n de BBox m谩s profunda.\")\n",
    "            self.bbox_regressor = nn.Sequential(\n",
    "                nn.Linear(base_model.fc.in_features, 1024), # base_model.fc.in_features es 2048\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout), # Dropout adicional dentro de la cabeza\n",
    "                nn.Linear(1024, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 4) # Salida de 4 coordenadas para el bbox\n",
    "            )\n",
    "            # Inicializaci贸n de pesos para la cabeza m谩s profunda (opcional pero puede ayudar)\n",
    "            for m in self.bbox_regressor.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.zeros_(m.bias)\n",
    "        else:\n",
    "            print(\"Usando cabeza de regresi贸n de BBox simple (Linear).\")\n",
    "            self.bbox_regressor = nn.Linear(base_model.fc.in_features, 4) #\n",
    "            # Inicializaci贸n de pesos para la cabeza simple (opcional)\n",
    "            nn.init.xavier_uniform_(self.bbox_regressor.weight)\n",
    "            # if self.bbox_regressor.bias is not None:\n",
    "            #     nn.init.zeros_(self.bbox_regressor.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        features = self.feature_extractor(x) #\n",
    "        pooled_features = self.pooling(features) #\n",
    "        flattened_features = self.flatten(pooled_features) #\n",
    "\n",
    "        # Clasificaci贸n\n",
    "        class_features_dropout = self.classification_dropout(flattened_features) #\n",
    "        class_output = self.classifier(class_features_dropout) #\n",
    "\n",
    "        # Regresi贸n de Bounding Box\n",
    "        bbox_features_dropout = self.bbox_dropout(flattened_features) #\n",
    "        bbox_output = self.bbox_regressor(bbox_features_dropout) #\n",
    "        \n",
    "        return class_output, bbox_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734b8f7",
   "metadata": {
    "papermill": {
     "duration": 0.033065,
     "end_time": "2025-04-07T23:00:04.930437",
     "exception": false,
     "start_time": "2025-04-07T23:00:04.897372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3f18cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_bbox: torch.Tensor, y_pred_bbox: torch.Tensor, apply_sigmoid_to_pred=False):\n",
    "    \n",
    "    if y_true_bbox.device != y_pred_bbox.device:\n",
    "        y_true_bbox = y_true_bbox.to(y_pred_bbox.device)\n",
    "    if apply_sigmoid_to_pred:\n",
    "         y_pred_bbox = torch.sigmoid(y_pred_bbox)\n",
    "    if y_true_bbox.ndim == 3 and y_true_bbox.shape[1] == 1:\n",
    "        y_true_bbox = y_true_bbox.squeeze(1)\n",
    "    if y_pred_bbox.ndim == 3 and y_pred_bbox.shape[1] == 1:\n",
    "        y_pred_bbox = y_pred_bbox.squeeze(1)\n",
    "    if y_true_bbox.shape[0] == 0 or y_pred_bbox.shape[0] == 0:\n",
    "        return torch.tensor(0.0, device=y_pred_bbox.device)\n",
    "    pairwise_iou_matrix = box_iou(y_true_bbox, y_pred_bbox)\n",
    "    if pairwise_iou_matrix.shape[0] == pairwise_iou_matrix.shape[1]:\n",
    "        return torch.diag(pairwise_iou_matrix).mean()\n",
    "    elif pairwise_iou_matrix.numel() > 0:\n",
    "        return pairwise_iou_matrix.mean()\n",
    "    else:\n",
    "        return torch.tensor(0.0, device=y_pred_bbox.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10fb7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(y_pred_class: torch.Tensor, y_true_class: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Calcula la precisi贸n de la clasificaci贸n.\n",
    "\n",
    "    Args:\n",
    "        y_pred_class (torch.Tensor): Logits o probabilidades predichas por el modelo.\n",
    "                                     Shape: (batch_size, num_classes)\n",
    "        y_true_class (torch.Tensor): Etiquetas de clase verdaderas.\n",
    "                                     Shape: (batch_size,) o (batch_size, 1)\n",
    "    Returns:\n",
    "        torch.Tensor: Precisi贸n.\n",
    "    \"\"\"\n",
    "    # Obtener las clases predichas tomando el argmax\n",
    "    pred_labels = torch.argmax(y_pred_class, dim=1)\n",
    "\n",
    "    # Asegurar que y_true_class tenga la misma forma que pred_labels\n",
    "    if y_true_class.ndim == 2 and y_true_class.shape[1] == 1:\n",
    "        y_true_class = y_true_class.squeeze(1)\n",
    "\n",
    "    # Comparar con las etiquetas verdaderas\n",
    "    correct = torch.eq(pred_labels, y_true_class).float() # Convertir a float para la suma\n",
    "    total = torch.ones_like(correct) # Un tensor de unos con la misma forma\n",
    "\n",
    "    # Calcular la precisi贸n\n",
    "    acc = torch.sum(correct) / torch.sum(total) \n",
    "    # result = torch.divide(torch.sum(correct), torch.sum(total)) \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2384060b",
   "metadata": {
    "papermill": {
     "duration": 0.023501,
     "end_time": "2025-04-07T23:00:05.088388",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.064887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c9610d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:05.136026Z",
     "iopub.status.busy": "2025-04-07T23:00:05.135732Z",
     "iopub.status.idle": "2025-04-07T23:00:05.140464Z",
     "shell.execute_reply": "2025-04-07T23:00:05.139643Z"
    },
    "papermill": {
     "duration": 0.030006,
     "end_time": "2025-04-07T23:00:05.141652",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.111646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn_multitask(class_preds: torch.Tensor, bbox_preds: torch.Tensor,\n",
    "                      true_classes: torch.Tensor, true_bboxes: torch.Tensor,\n",
    "                      alpha: float = 0.5):\n",
    "    \"\"\"\n",
    "    Calcula la p茅rdida combinada para clasificaci贸n y regresi贸n de bounding box.\n",
    "\n",
    "    Args:\n",
    "        class_preds (torch.Tensor): Predicciones de clase del modelo (logits).\n",
    "                                     Shape: (batch_size, num_classes)\n",
    "        bbox_preds (torch.Tensor): Predicciones de bounding box del modelo.\n",
    "                                   Shape: (batch_size, 4)\n",
    "        true_classes (torch.Tensor): Etiquetas de clase verdaderas.\n",
    "                                     Shape: (batch_size,) o (batch_size, 1) - deben ser long ints.\n",
    "        true_bboxes (torch.Tensor): Coordenadas de bounding box verdaderas.\n",
    "                                    Shape: (batch_size, 4)\n",
    "        alpha (float): Peso para balancear la p茅rdida de regresi贸n.\n",
    "                       total_loss = (1-alpha)*cls_loss + alpha*reg_loss\n",
    "    Returns:\n",
    "        dict: Un diccionario con 'total_loss', 'cls_loss', 'reg_loss'.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que true_classes tenga el tipo de dato correcto para CrossEntropyLoss\n",
    "    true_classes = true_classes.long()\n",
    "    if true_classes.ndim == 2 and true_classes.shape[1] == 1:\n",
    "        true_classes = true_classes.squeeze(1) # (batch_size, 1) -> (batch_size,)\n",
    "\n",
    "    # P茅rdida de Clasificaci贸n\n",
    "    # class_preds son logits, true_classes son 铆ndices de clase\n",
    "    cls_loss = F.cross_entropy(class_preds, true_classes)\n",
    "\n",
    "    # P茅rdida de Regresi贸n para Bounding Box\n",
    "    # bbox_preds y true_bboxes deben tener la misma forma [N, 4]\n",
    "    reg_loss = F.mse_loss(bbox_preds, true_bboxes)\n",
    "    # Alternativa: reg_loss = F.l1_loss(bbox_preds, true_bboxes)\n",
    "\n",
    "    # P茅rdida Total Combinada\n",
    "    total_loss = (1 - alpha) * cls_loss + alpha * reg_loss\n",
    "\n",
    "    return {\n",
    "        'total_loss': total_loss,\n",
    "        'reg_loss': reg_loss,\n",
    "        'cls_loss': cls_loss\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31423eb",
   "metadata": {
    "papermill": {
     "duration": 0.023293,
     "end_time": "2025-04-07T23:00:05.188467",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.165174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85e5a0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:05.236504Z",
     "iopub.status.busy": "2025-04-07T23:00:05.236170Z",
     "iopub.status.idle": "2025-04-07T23:00:05.241135Z",
     "shell.execute_reply": "2025-04-07T23:00:05.240248Z"
    },
    "papermill": {
     "duration": 0.030676,
     "end_time": "2025-04-07T23:00:05.242576",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.211900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def printer_callback(logs: dict): # ty.Dict[str, ty.Any] si usas type hints\n",
    "    \"\"\"\n",
    "    Imprime los logs del entrenamiento.\n",
    "    \"\"\"\n",
    "    # print every 10 steps - asumiendo que 'iters' est谩 en logs\n",
    "    if 'iters' in logs and logs['iters'] % 10 != 0: # Cambi茅 == a != para imprimir cada 10\n",
    "        if logs['iters'] != 1: # Imprimir siempre la primera iteraci贸n\n",
    "            return\n",
    "\n",
    "    print(f\"Iteraci贸n #: {logs.get('iters', 'N/A')}\") # Usar .get para evitar KeyError\n",
    "    for name, value in logs.items():\n",
    "        if name == 'iters':\n",
    "            continue\n",
    "\n",
    "        if isinstance(value, (float, int)): # type(value) in [float, int] es menos idiom谩tico\n",
    "            value_str = f\"{value:.4f}\" if isinstance(value, float) else str(value)\n",
    "        elif isinstance(value, torch.Tensor):\n",
    "            # value_str = f\"{value.item():.4f}\" if value.numel() == 1 else str(value)\n",
    "            value_str = f\"{torch.round(value, decimals=4).item() if value.numel() == 1 else str(value.round(decimals=4))}\"\n",
    "        else:\n",
    "            value_str = str(value)\n",
    "        print(f\"\\t{name} = {value_str}\")\n",
    "    print(\"-\" * 30) # Separador\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd653d",
   "metadata": {
    "papermill": {
     "duration": 0.02323,
     "end_time": "2025-04-07T23:00:05.289353",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.266123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ce5d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time # Para medir la duraci贸n de las 茅pocas\n",
    "import copy # Para guardar el mejor estado del modelo\n",
    "import os   # Para la modificaci贸n de guardado del modelo\n",
    "\n",
    "\n",
    "def train_multitask_model(\n",
    "    model, train_loader, val_loader, classification_criterion, bbox_criterion,\n",
    "    optimizer, device, num_epochs=30, bbox_loss_weight=1.0, patience=5,\n",
    "    model_save_path=\"best_multitask_model.pth\", apply_sigmoid_to_bbox_pred=False,\n",
    "    scheduler=None # \n",
    "):\n",
    "    # reset_seed(42) # Puedes llamarlo fuera o dentro si quieres resetear en cada llamada.\n",
    "\n",
    "    history = {\n",
    "        'train_loss_cls': [], 'train_loss_bbox': [], 'train_loss_total': [],\n",
    "        'train_acc': [], 'train_iou': [],\n",
    "        'val_loss_cls': [], 'val_loss_bbox': [], 'val_loss_total': [],\n",
    "        'val_acc': [], 'val_iou': []\n",
    "    }\n",
    "\n",
    "    best_val_loss_total = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    print(f\"Iniciando entrenamiento por {num_epochs} 茅pocas en dispositivo: {device}.\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # --- Fase de Entrenamiento ---\n",
    "        model.train()\n",
    "        running_train_loss_cls = 0.0\n",
    "        running_train_loss_bbox = 0.0\n",
    "        running_train_loss_total = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_samples = 0\n",
    "        sum_train_iou = 0.0 # Acumulador para la suma de IoUs (no promediado a煤n)\n",
    "        num_train_batches_with_iou = 0 # Contador para batches donde se calcul贸 IoU\n",
    "\n",
    "        for batch_idx, batch_data in enumerate(train_loader):\n",
    "            if batch_data is None:\n",
    "                continue \n",
    "            \n",
    "            images, class_labels, bbox_labels_raw = batch_data\n",
    "            \n",
    "            images = images.to(device)\n",
    "            class_labels = class_labels.to(device).long()\n",
    "            \n",
    "            if bbox_labels_raw.ndim == 3 and bbox_labels_raw.shape[1] == 1:\n",
    "                 bbox_labels = bbox_labels_raw.to(device).float().squeeze(1)\n",
    "            elif bbox_labels_raw.ndim == 2 and bbox_labels_raw.shape[-1] == 4:\n",
    "                 bbox_labels = bbox_labels_raw.to(device).float()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            class_logits, bbox_preds_raw = model(images)\n",
    "\n",
    "            bbox_preds = torch.sigmoid(bbox_preds_raw) if apply_sigmoid_to_bbox_pred else bbox_preds_raw\n",
    "            \n",
    "            loss_cls = classification_criterion(class_logits, class_labels)\n",
    "            loss_bbox = bbox_criterion(bbox_preds, bbox_labels) \n",
    "            total_loss = loss_cls + bbox_loss_weight * loss_bbox\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = images.size(0) # Usar images.size(0) para el tama帽o real del batch\n",
    "            running_train_loss_cls += loss_cls.item() * batch_size\n",
    "            running_train_loss_bbox += loss_bbox.item() * batch_size\n",
    "            running_train_loss_total += total_loss.item() * batch_size\n",
    "\n",
    "            _, predicted_classes = torch.max(class_logits, 1)\n",
    "            correct_train_preds += (predicted_classes == class_labels).sum().item()\n",
    "            total_train_samples += batch_size \n",
    "            \n",
    "            # Calcula IoU solo si hay bboxes v谩lidos en el batch para evitar errores\n",
    "            if bbox_labels.numel() > 0 and bbox_preds.numel() > 0:\n",
    "                 # iou_metric deber铆a devolver la suma de IoUs para el batch o el IoU promedio del batch\n",
    "                 # Si devuelve la suma de IoUs, est谩 bien. Si devuelve el promedio, multiplica por batch_size.\n",
    "                 # Asumamos que iou_metric devuelve el IoU promedio del batch.\n",
    "                iou_batch_avg = iou_metric(bbox_labels.detach(), bbox_preds.detach(), apply_sigmoid_to_pred=False)\n",
    "                if torch.is_tensor(iou_batch_avg) and iou_batch_avg.numel() == 1 : # Asegurarse que es un escalar\n",
    "                    sum_train_iou += iou_batch_avg.item() * batch_size\n",
    "                    num_train_batches_with_iou += batch_size # o simplemente num_train_batches_with_iou += 1 si iou_metric devuelve suma\n",
    "                # else:\n",
    "                    # print(f\"Advertencia: iou_metric devolvi贸 un valor inesperado: {iou_batch_avg}\")\n",
    "\n",
    "        print(f\"DEBUG train_multitask_model: Epoch {epoch+1}, total_train_samples procesadas esta 茅poca: {total_train_samples}\")\n",
    "\n",
    "        epoch_train_loss_cls = running_train_loss_cls / total_train_samples if total_train_samples > 0 else 0.0\n",
    "        epoch_train_loss_bbox = running_train_loss_bbox / total_train_samples if total_train_samples > 0 else 0.0\n",
    "        epoch_train_loss_total = running_train_loss_total / total_train_samples if total_train_samples > 0 else 0.0\n",
    "        epoch_train_acc = correct_train_preds / total_train_samples if total_train_samples > 0 else 0.0\n",
    "        # epoch_train_iou = sum_train_iou / num_train_batches_with_iou if num_train_batches_with_iou > 0 else 0.0 # Si iou_metric devuelve promedio y contamos batches\n",
    "        epoch_train_iou = sum_train_iou / total_train_samples if total_train_samples > 0 else 0.0 # Si iou_metric devuelve promedio y sum_train_iou acumula (promedio*tama帽o_batch)\n",
    "\n",
    "\n",
    "        history['train_loss_cls'].append(epoch_train_loss_cls)\n",
    "        history['train_loss_bbox'].append(epoch_train_loss_bbox)\n",
    "        history['train_loss_total'].append(epoch_train_loss_total)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['train_iou'].append(epoch_train_iou)\n",
    "\n",
    "        # --- Fase de Validaci贸n ---\n",
    "        model.eval()\n",
    "        running_val_loss_cls = 0.0\n",
    "        running_val_loss_bbox = 0.0\n",
    "        running_val_loss_total = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_samples_val = 0\n",
    "        sum_val_iou = 0.0 # Acumulador para la suma de IoUs\n",
    "        num_val_batches_with_iou = 0 # Contador para batches donde se calcul贸 IoU\n",
    "        current_epoch_val_loss_total = float('inf')\n",
    "\n",
    "        if val_loader is not None and len(val_loader) > 0:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx_val, batch_data_val in enumerate(val_loader):\n",
    "                    if batch_data_val is None:\n",
    "                        continue\n",
    "                    \n",
    "                    images_val, class_labels_val, bbox_labels_raw_val = batch_data_val\n",
    "\n",
    "                    images_val = images_val.to(device)\n",
    "                    class_labels_val = class_labels_val.to(device).long()\n",
    "\n",
    "                    if bbox_labels_raw_val.ndim == 3 and bbox_labels_raw_val.shape[1] == 1:\n",
    "                        bbox_labels_val = bbox_labels_raw_val.to(device).float().squeeze(1)\n",
    "                    elif bbox_labels_raw_val.ndim == 2 and bbox_labels_raw_val.shape[-1] == 4:\n",
    "                        bbox_labels_val = bbox_labels_raw_val.to(device).float()\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    class_logits_val, bbox_preds_raw_val = model(images_val)\n",
    "                    bbox_preds_val = torch.sigmoid(bbox_preds_raw_val) if apply_sigmoid_to_bbox_pred else bbox_preds_raw_val\n",
    "\n",
    "                    loss_cls_val = classification_criterion(class_logits_val, class_labels_val)\n",
    "                    loss_bbox_val = bbox_criterion(bbox_preds_val, bbox_labels_val)\n",
    "                    total_loss_val = loss_cls_val + bbox_loss_weight * loss_bbox_val\n",
    "                    \n",
    "                    batch_size_val = images_val.size(0)\n",
    "                    running_val_loss_cls += loss_cls_val.item() * batch_size_val\n",
    "                    running_val_loss_bbox += loss_bbox_val.item() * batch_size_val\n",
    "                    running_val_loss_total += total_loss_val.item() * batch_size_val\n",
    "\n",
    "                    _, predicted_classes_val = torch.max(class_logits_val, 1)\n",
    "                    correct_val_preds += (predicted_classes_val == class_labels_val).sum().item()\n",
    "                    total_val_samples_val += batch_size_val\n",
    "                    \n",
    "                    if bbox_labels_val.numel() > 0 and bbox_preds_val.numel() > 0:\n",
    "                        iou_batch_avg_val = iou_metric(bbox_labels_val.detach(), bbox_preds_val.detach(), apply_sigmoid_to_pred=False)\n",
    "                        if torch.is_tensor(iou_batch_avg_val) and iou_batch_avg_val.numel() == 1:\n",
    "                            sum_val_iou += iou_batch_avg_val.item() * batch_size_val\n",
    "                            num_val_batches_with_iou += batch_size_val\n",
    "            \n",
    "            epoch_val_loss_cls = running_val_loss_cls / total_val_samples_val if total_val_samples_val > 0 else 0.0\n",
    "            epoch_val_loss_bbox = running_val_loss_bbox / total_val_samples_val if total_val_samples_val > 0 else 0.0\n",
    "            current_epoch_val_loss_total = running_val_loss_total / total_val_samples_val if total_val_samples_val > 0 else float('inf')\n",
    "            epoch_val_acc = correct_val_preds / total_val_samples_val if total_val_samples_val > 0 else 0.0\n",
    "            # epoch_val_iou = sum_val_iou / num_val_batches_with_iou if num_val_batches_with_iou > 0 else 0.0\n",
    "            epoch_val_iou = sum_val_iou / total_val_samples_val if total_val_samples_val > 0 else 0.0\n",
    "\n",
    "\n",
    "        else: \n",
    "            epoch_val_loss_cls, epoch_val_loss_bbox = 0.0, 0.0\n",
    "            current_epoch_val_loss_total = float('inf') \n",
    "            epoch_val_acc, epoch_val_iou = 0.0, 0.0\n",
    "            total_val_samples_val = 0\n",
    "\n",
    "        history['val_loss_cls'].append(epoch_val_loss_cls)\n",
    "        history['val_loss_bbox'].append(epoch_val_loss_bbox)\n",
    "        history['val_loss_total'].append(current_epoch_val_loss_total)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        history['val_iou'].append(epoch_val_iou)\n",
    "\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} Duraci贸n: {epoch_duration:.2f}s\")\n",
    "        print(f\"  Train: LossCls={epoch_train_loss_cls:.4f}, LossBbox={epoch_train_loss_bbox:.4f}, Total={epoch_train_loss_total:.4f}, Acc={epoch_train_acc:.4f}, IoU={epoch_train_iou:.4f}\")\n",
    "        \n",
    "        if total_val_samples_val > 0:\n",
    "            print(f\"  Valid: LossCls={epoch_val_loss_cls:.4f}, LossBbox={epoch_val_loss_bbox:.4f}, Total={current_epoch_val_loss_total:.4f}, Acc={epoch_val_acc:.4f}, IoU={epoch_val_iou:.4f}\")\n",
    "        else:\n",
    "            print(\"  Valid: No hay datos de validaci贸n para esta 茅poca.\")\n",
    "\n",
    "        #  L贸gica de Scheduler (si se proporciona)\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                if total_val_samples_val > 0: \n",
    "                    scheduler.step(current_epoch_val_loss_total) #  LLAMADA AL SCHEDULER\n",
    "                # else: Opcionalmente, si no hay validaci贸n, no hacer step o basarse en train_loss\n",
    "            else: # Para otros schedulers que hacen step por 茅poca sin argumentos\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Opcional: imprimir la tasa de aprendizaje actual\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"  Current LR: {current_lr:.1e}\")\n",
    "\n",
    "\n",
    "        # L贸gica de Early Stopping y guardado del mejor modelo\n",
    "        if total_val_samples_val > 0: \n",
    "            if current_epoch_val_loss_total < best_val_loss_total:\n",
    "                best_val_loss_total = current_epoch_val_loss_total\n",
    "                if model is not None:\n",
    "                    best_model_state = copy.deepcopy(model.state_dict())\n",
    "                    try:\n",
    "                        torch.save(best_model_state, model_save_path)\n",
    "                        print(f\"  Mejor modelo guardado en '{model_save_path}' con val_loss_total: {best_val_loss_total:.4f}\")\n",
    "                    except Exception as e_save:\n",
    "                        print(f\"ERROR AL INTENTAR GUARDAR EL MODELO en '{model_save_path}': {e_save}\")\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                print(f\"  Val_loss_total no mejor贸. Paciencia: {epochs_no_improve}/{patience}\")\n",
    "            \n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping activado despu茅s de {epoch+1} 茅pocas.\")\n",
    "                break\n",
    "        elif epoch == 0 and best_model_state is None : \n",
    "             if model is not None:\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                try:\n",
    "                    torch.save(best_model_state, model_save_path)\n",
    "                    print(f\"  Modelo de la primera 茅poca guardado (sin validaci贸n activa) en '{model_save_path}'\")\n",
    "                except Exception as e_save:\n",
    "                    print(f\"ERROR AL INTENTAR GUARDAR EL MODELO (primera 茅poca sin val) en '{model_save_path}': {e_save}\")\n",
    "\n",
    "    if best_model_state:\n",
    "        print(\"Cargando el mejor estado del modelo guardado al final del entrenamiento.\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "    else:\n",
    "        print(\"No se guard贸 ning煤n 'mejor modelo'. El modelo tiene los pesos de la 煤ltima 茅poca entrenada.\")\n",
    "    \n",
    "    print(\"Entrenamiento finalizado.\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f17c1a",
   "metadata": {
    "papermill": {
     "duration": 0.024267,
     "end_time": "2025-04-07T23:00:05.397282",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.373015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0af4a9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los resultados se guardar谩n en el directorio: c:\\Users\\allc0363\\OneDrive\\MCD - Icesi\\Semestre 2\\Fundamentos 2\\Taller 1\\FAII_TALLER1\\Notebooks\\Resultados\n",
      "Cargando y preprocesando el DataFrame...\n",
      "Bounding boxes en el script de Run normalizados y acotados a [0,1].\n",
      "DEBUG: Longitud de df_run: 189\n",
      "DEBUG: Longitud de train_df_run: 151\n",
      "Usando medias de ImageNet para el script de Run: [0.485, 0.456, 0.406]\n",
      "Usando desviaciones est谩ndar de ImageNet para el script de Run: [0.229, 0.224, 0.225]\n",
      "DEBUG: Usando pipeline de transformaci贸n de entrenamiento MNIMO con BboxParams por DEFECTO.\n",
      "Creando Datasets y DataLoaders finales para el script de Run...\n",
      "DEBUG militarDataset: Inicializado con 151 filas. Transformaciones: S铆. Labeled: True\n",
      "DEBUG militarDataset: Inicializado con 38 filas. Transformaciones: S铆. Labeled: True\n",
      "\n",
      "DEBUG: Inspeccionando las primeras (hasta) 5 muestras de train_dataset_run (longitud total: 151):\n",
      "DEBUG: De las primeras muestras inspeccionadas, 5 fueron v谩lidas.\n",
      "\n",
      "Usando dispositivo para el script de Run: cuda\n",
      "Usando cabeza de regresi贸n de BBox simple (Linear).\n",
      "Usando cabeza de regresi贸n de BBox MS PROFUNDA.\n",
      "DEBUG: El modelo se guardar谩 en la ruta absoluta: ./Resultados/pretrained_model_20250525_201424.pth\n",
      "Iniciando el proceso de entrenamiento del script de Run...\n",
      "APPLY_SIGMOID_TO_BBOX_PRED para el script de Run est谩 configurado a: True\n",
      "Iniciando entrenamiento por 120 茅pocas en dispositivo: cuda.\n",
      "DEBUG train_multitask_model: Epoch 1, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 1/120 Duraci贸n: 2.51s\n",
      "  Train: LossCls=1.7735, LossBbox=0.0592, Total=2.9573, Acc=0.2252, IoU=0.0000\n",
      "  Valid: LossCls=1.6751, LossBbox=0.0226, Total=2.1280, Acc=0.3684, IoU=0.0000\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 2.1280\n",
      "DEBUG train_multitask_model: Epoch 2, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 2/120 Duraci贸n: 2.28s\n",
      "  Train: LossCls=1.5967, LossBbox=0.0194, Total=1.9853, Acc=0.4570, IoU=0.0012\n",
      "  Valid: LossCls=1.5512, LossBbox=0.0059, Total=1.6687, Acc=0.4474, IoU=0.0076\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.6687\n",
      "DEBUG train_multitask_model: Epoch 3, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 3/120 Duraci贸n: 2.36s\n",
      "  Train: LossCls=1.4746, LossBbox=0.0069, Total=1.6120, Acc=0.5762, IoU=0.0025\n",
      "  Valid: LossCls=1.4412, LossBbox=0.0023, Total=1.4870, Acc=0.5263, IoU=0.0110\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.4870\n",
      "DEBUG train_multitask_model: Epoch 4, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 4/120 Duraci贸n: 2.30s\n",
      "  Train: LossCls=1.3538, LossBbox=0.0033, Total=1.4202, Acc=0.6291, IoU=0.0233\n",
      "  Valid: LossCls=1.3504, LossBbox=0.0019, Total=1.3875, Acc=0.6053, IoU=0.0226\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.3875\n",
      "DEBUG train_multitask_model: Epoch 5, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 5/120 Duraci贸n: 2.26s\n",
      "  Train: LossCls=1.2279, LossBbox=0.0033, Total=1.2933, Acc=0.7616, IoU=0.0292\n",
      "  Valid: LossCls=1.2741, LossBbox=0.0019, Total=1.3124, Acc=0.6316, IoU=0.0318\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.3124\n",
      "DEBUG train_multitask_model: Epoch 6, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 6/120 Duraci贸n: 2.27s\n",
      "  Train: LossCls=1.1323, LossBbox=0.0029, Total=1.1905, Acc=0.8278, IoU=0.0190\n",
      "  Valid: LossCls=1.1998, LossBbox=0.0020, Total=1.2403, Acc=0.6579, IoU=0.0386\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.2403\n",
      "DEBUG train_multitask_model: Epoch 7, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 7/120 Duraci贸n: 2.41s\n",
      "  Train: LossCls=1.0574, LossBbox=0.0029, Total=1.1155, Acc=0.8344, IoU=0.0309\n",
      "  Valid: LossCls=1.1315, LossBbox=0.0021, Total=1.1727, Acc=0.7632, IoU=0.0552\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.1727\n",
      "DEBUG train_multitask_model: Epoch 8, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 8/120 Duraci贸n: 2.31s\n",
      "  Train: LossCls=0.9719, LossBbox=0.0028, Total=1.0272, Acc=0.8874, IoU=0.0359\n",
      "  Valid: LossCls=1.0753, LossBbox=0.0019, Total=1.1138, Acc=0.7895, IoU=0.0743\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.1138\n",
      "DEBUG train_multitask_model: Epoch 9, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 9/120 Duraci贸n: 2.47s\n",
      "  Train: LossCls=0.9020, LossBbox=0.0028, Total=0.9570, Acc=0.9073, IoU=0.0497\n",
      "  Valid: LossCls=1.0249, LossBbox=0.0018, Total=1.0605, Acc=0.7895, IoU=0.0835\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.0605\n",
      "DEBUG train_multitask_model: Epoch 10, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 10/120 Duraci贸n: 2.42s\n",
      "  Train: LossCls=0.8410, LossBbox=0.0029, Total=0.8985, Acc=0.9139, IoU=0.0589\n",
      "  Valid: LossCls=0.9741, LossBbox=0.0017, Total=1.0072, Acc=0.8158, IoU=0.0921\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 1.0072\n",
      "DEBUG train_multitask_model: Epoch 11, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 11/120 Duraci贸n: 2.43s\n",
      "  Train: LossCls=0.8116, LossBbox=0.0023, Total=0.8582, Acc=0.9404, IoU=0.0756\n",
      "  Valid: LossCls=0.9395, LossBbox=0.0015, Total=0.9701, Acc=0.8158, IoU=0.1081\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.9701\n",
      "DEBUG train_multitask_model: Epoch 12, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 12/120 Duraci贸n: 2.29s\n",
      "  Train: LossCls=0.7461, LossBbox=0.0023, Total=0.7926, Acc=0.9338, IoU=0.0839\n",
      "  Valid: LossCls=0.9057, LossBbox=0.0015, Total=0.9356, Acc=0.8421, IoU=0.1209\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.9356\n",
      "DEBUG train_multitask_model: Epoch 13, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 13/120 Duraci贸n: 2.25s\n",
      "  Train: LossCls=0.6719, LossBbox=0.0023, Total=0.7176, Acc=0.9338, IoU=0.1018\n",
      "  Valid: LossCls=0.8744, LossBbox=0.0015, Total=0.9034, Acc=0.8158, IoU=0.1325\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.9034\n",
      "DEBUG train_multitask_model: Epoch 14, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 14/120 Duraci贸n: 2.32s\n",
      "  Train: LossCls=0.6467, LossBbox=0.0023, Total=0.6924, Acc=0.9338, IoU=0.1091\n",
      "  Valid: LossCls=0.8440, LossBbox=0.0014, Total=0.8721, Acc=0.8421, IoU=0.1451\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.8721\n",
      "DEBUG train_multitask_model: Epoch 15, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 15/120 Duraci贸n: 2.25s\n",
      "  Train: LossCls=0.6159, LossBbox=0.0021, Total=0.6573, Acc=0.9338, IoU=0.1356\n",
      "  Valid: LossCls=0.8161, LossBbox=0.0014, Total=0.8436, Acc=0.8421, IoU=0.1525\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.8436\n",
      "DEBUG train_multitask_model: Epoch 16, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 16/120 Duraci贸n: 2.26s\n",
      "  Train: LossCls=0.5668, LossBbox=0.0020, Total=0.6073, Acc=0.9536, IoU=0.1258\n",
      "  Valid: LossCls=0.7864, LossBbox=0.0014, Total=0.8136, Acc=0.8421, IoU=0.1532\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.8136\n",
      "DEBUG train_multitask_model: Epoch 17, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 17/120 Duraci贸n: 2.25s\n",
      "  Train: LossCls=0.5610, LossBbox=0.0019, Total=0.5985, Acc=0.9338, IoU=0.1509\n",
      "  Valid: LossCls=0.7658, LossBbox=0.0013, Total=0.7924, Acc=0.8421, IoU=0.1558\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7924\n",
      "DEBUG train_multitask_model: Epoch 18, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 18/120 Duraci贸n: 2.22s\n",
      "  Train: LossCls=0.5368, LossBbox=0.0019, Total=0.5753, Acc=0.9470, IoU=0.1578\n",
      "  Valid: LossCls=0.7434, LossBbox=0.0013, Total=0.7688, Acc=0.8421, IoU=0.1590\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7688\n",
      "DEBUG train_multitask_model: Epoch 19, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 19/120 Duraci贸n: 2.27s\n",
      "  Train: LossCls=0.5262, LossBbox=0.0020, Total=0.5655, Acc=0.9404, IoU=0.1404\n",
      "  Valid: LossCls=0.7270, LossBbox=0.0012, Total=0.7516, Acc=0.8684, IoU=0.1629\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7516\n",
      "DEBUG train_multitask_model: Epoch 20, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 20/120 Duraci贸n: 2.27s\n",
      "  Train: LossCls=0.4621, LossBbox=0.0019, Total=0.5010, Acc=0.9669, IoU=0.1570\n",
      "  Valid: LossCls=0.7078, LossBbox=0.0012, Total=0.7321, Acc=0.8684, IoU=0.1653\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7321\n",
      "DEBUG train_multitask_model: Epoch 21, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 21/120 Duraci贸n: 2.30s\n",
      "  Train: LossCls=0.4659, LossBbox=0.0020, Total=0.5064, Acc=0.9735, IoU=0.1370\n",
      "  Valid: LossCls=0.6907, LossBbox=0.0012, Total=0.7143, Acc=0.8684, IoU=0.1728\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.7143\n",
      "DEBUG train_multitask_model: Epoch 22, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 22/120 Duraci贸n: 2.23s\n",
      "  Train: LossCls=0.4636, LossBbox=0.0017, Total=0.4976, Acc=0.9470, IoU=0.1368\n",
      "  Valid: LossCls=0.6725, LossBbox=0.0012, Total=0.6955, Acc=0.8684, IoU=0.1761\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6955\n",
      "DEBUG train_multitask_model: Epoch 23, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 23/120 Duraci贸n: 2.27s\n",
      "  Train: LossCls=0.4220, LossBbox=0.0019, Total=0.4598, Acc=0.9735, IoU=0.1381\n",
      "  Valid: LossCls=0.6545, LossBbox=0.0011, Total=0.6774, Acc=0.8684, IoU=0.1755\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6774\n",
      "DEBUG train_multitask_model: Epoch 24, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 24/120 Duraci贸n: 2.26s\n",
      "  Train: LossCls=0.3895, LossBbox=0.0018, Total=0.4249, Acc=0.9801, IoU=0.1422\n",
      "  Valid: LossCls=0.6416, LossBbox=0.0011, Total=0.6642, Acc=0.8684, IoU=0.1775\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6642\n",
      "DEBUG train_multitask_model: Epoch 25, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 25/120 Duraci贸n: 2.27s\n",
      "  Train: LossCls=0.3868, LossBbox=0.0018, Total=0.4235, Acc=0.9801, IoU=0.1405\n",
      "  Valid: LossCls=0.6272, LossBbox=0.0011, Total=0.6499, Acc=0.8684, IoU=0.1758\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6499\n",
      "DEBUG train_multitask_model: Epoch 26, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 26/120 Duraci贸n: 2.38s\n",
      "  Train: LossCls=0.3863, LossBbox=0.0017, Total=0.4204, Acc=0.9603, IoU=0.1571\n",
      "  Valid: LossCls=0.6224, LossBbox=0.0011, Total=0.6443, Acc=0.8684, IoU=0.1784\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6443\n",
      "DEBUG train_multitask_model: Epoch 27, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 27/120 Duraci贸n: 2.32s\n",
      "  Train: LossCls=0.3702, LossBbox=0.0018, Total=0.4069, Acc=0.9801, IoU=0.1332\n",
      "  Valid: LossCls=0.6012, LossBbox=0.0011, Total=0.6231, Acc=0.8684, IoU=0.1821\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6231\n",
      "DEBUG train_multitask_model: Epoch 28, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 28/120 Duraci贸n: 2.27s\n",
      "  Train: LossCls=0.3310, LossBbox=0.0016, Total=0.3630, Acc=0.9934, IoU=0.1622\n",
      "  Valid: LossCls=0.5953, LossBbox=0.0011, Total=0.6168, Acc=0.8684, IoU=0.1821\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6168\n",
      "DEBUG train_multitask_model: Epoch 29, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 29/120 Duraci贸n: 2.29s\n",
      "  Train: LossCls=0.3379, LossBbox=0.0018, Total=0.3729, Acc=0.9669, IoU=0.1467\n",
      "  Valid: LossCls=0.5853, LossBbox=0.0011, Total=0.6065, Acc=0.8684, IoU=0.1797\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.6065\n",
      "DEBUG train_multitask_model: Epoch 30, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 30/120 Duraci贸n: 2.35s\n",
      "  Train: LossCls=0.3345, LossBbox=0.0017, Total=0.3680, Acc=0.9868, IoU=0.1709\n",
      "  Valid: LossCls=0.5744, LossBbox=0.0011, Total=0.5957, Acc=0.8684, IoU=0.1788\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5957\n",
      "DEBUG train_multitask_model: Epoch 31, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 31/120 Duraci贸n: 2.36s\n",
      "  Train: LossCls=0.3094, LossBbox=0.0016, Total=0.3414, Acc=0.9868, IoU=0.1539\n",
      "  Valid: LossCls=0.5679, LossBbox=0.0010, Total=0.5888, Acc=0.8684, IoU=0.1801\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5888\n",
      "DEBUG train_multitask_model: Epoch 32, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 32/120 Duraci贸n: 2.34s\n",
      "  Train: LossCls=0.3047, LossBbox=0.0016, Total=0.3365, Acc=0.9934, IoU=0.1469\n",
      "  Valid: LossCls=0.5631, LossBbox=0.0010, Total=0.5837, Acc=0.8684, IoU=0.1869\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5837\n",
      "DEBUG train_multitask_model: Epoch 33, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 33/120 Duraci贸n: 2.47s\n",
      "  Train: LossCls=0.3337, LossBbox=0.0014, Total=0.3623, Acc=0.9603, IoU=0.1740\n",
      "  Valid: LossCls=0.5492, LossBbox=0.0010, Total=0.5700, Acc=0.8684, IoU=0.1824\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5700\n",
      "DEBUG train_multitask_model: Epoch 34, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 34/120 Duraci贸n: 2.48s\n",
      "  Train: LossCls=0.3003, LossBbox=0.0015, Total=0.3306, Acc=0.9934, IoU=0.1652\n",
      "  Valid: LossCls=0.5438, LossBbox=0.0011, Total=0.5648, Acc=0.8684, IoU=0.1858\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5648\n",
      "DEBUG train_multitask_model: Epoch 35, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 35/120 Duraci贸n: 2.34s\n",
      "  Train: LossCls=0.2740, LossBbox=0.0018, Total=0.3099, Acc=0.9801, IoU=0.1549\n",
      "  Valid: LossCls=0.5396, LossBbox=0.0010, Total=0.5606, Acc=0.8684, IoU=0.1837\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5606\n",
      "DEBUG train_multitask_model: Epoch 36, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 36/120 Duraci贸n: 2.35s\n",
      "  Train: LossCls=0.2628, LossBbox=0.0014, Total=0.2908, Acc=0.9868, IoU=0.1822\n",
      "  Valid: LossCls=0.5384, LossBbox=0.0010, Total=0.5588, Acc=0.8947, IoU=0.1878\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5588\n",
      "DEBUG train_multitask_model: Epoch 37, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 37/120 Duraci贸n: 2.34s\n",
      "  Train: LossCls=0.2533, LossBbox=0.0016, Total=0.2843, Acc=0.9934, IoU=0.1757\n",
      "  Valid: LossCls=0.5246, LossBbox=0.0010, Total=0.5447, Acc=0.8947, IoU=0.1916\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5447\n",
      "DEBUG train_multitask_model: Epoch 38, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 38/120 Duraci贸n: 2.31s\n",
      "  Train: LossCls=0.2320, LossBbox=0.0015, Total=0.2611, Acc=1.0000, IoU=0.1623\n",
      "  Valid: LossCls=0.5154, LossBbox=0.0010, Total=0.5353, Acc=0.8947, IoU=0.1971\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5353\n",
      "DEBUG train_multitask_model: Epoch 39, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 39/120 Duraci贸n: 2.28s\n",
      "  Train: LossCls=0.2595, LossBbox=0.0013, Total=0.2859, Acc=0.9934, IoU=0.1728\n",
      "  Valid: LossCls=0.5145, LossBbox=0.0010, Total=0.5344, Acc=0.8947, IoU=0.1926\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5344\n",
      "DEBUG train_multitask_model: Epoch 40, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 40/120 Duraci贸n: 2.33s\n",
      "  Train: LossCls=0.2521, LossBbox=0.0013, Total=0.2782, Acc=0.9735, IoU=0.1620\n",
      "  Valid: LossCls=0.5100, LossBbox=0.0010, Total=0.5293, Acc=0.8947, IoU=0.2005\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5293\n",
      "DEBUG train_multitask_model: Epoch 41, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 41/120 Duraci贸n: 2.39s\n",
      "  Train: LossCls=0.2121, LossBbox=0.0014, Total=0.2398, Acc=1.0000, IoU=0.1893\n",
      "  Valid: LossCls=0.5029, LossBbox=0.0010, Total=0.5223, Acc=0.8947, IoU=0.1953\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5223\n",
      "DEBUG train_multitask_model: Epoch 42, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 42/120 Duraci贸n: 2.33s\n",
      "  Train: LossCls=0.2128, LossBbox=0.0013, Total=0.2382, Acc=1.0000, IoU=0.1857\n",
      "  Valid: LossCls=0.4965, LossBbox=0.0010, Total=0.5158, Acc=0.8947, IoU=0.1943\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5158\n",
      "DEBUG train_multitask_model: Epoch 43, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 43/120 Duraci贸n: 2.20s\n",
      "  Train: LossCls=0.2066, LossBbox=0.0013, Total=0.2321, Acc=0.9934, IoU=0.1721\n",
      "  Valid: LossCls=0.4946, LossBbox=0.0010, Total=0.5141, Acc=0.8947, IoU=0.1870\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5141\n",
      "DEBUG train_multitask_model: Epoch 44, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 44/120 Duraci贸n: 2.20s\n",
      "  Train: LossCls=0.2035, LossBbox=0.0012, Total=0.2272, Acc=1.0000, IoU=0.1869\n",
      "  Valid: LossCls=0.4911, LossBbox=0.0010, Total=0.5104, Acc=0.8947, IoU=0.1889\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5104\n",
      "DEBUG train_multitask_model: Epoch 45, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 45/120 Duraci贸n: 2.21s\n",
      "  Train: LossCls=0.2037, LossBbox=0.0012, Total=0.2269, Acc=0.9934, IoU=0.1959\n",
      "  Valid: LossCls=0.4879, LossBbox=0.0010, Total=0.5074, Acc=0.8947, IoU=0.1928\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.5074\n",
      "DEBUG train_multitask_model: Epoch 46, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 46/120 Duraci贸n: 2.25s\n",
      "  Train: LossCls=0.1896, LossBbox=0.0012, Total=0.2139, Acc=1.0000, IoU=0.1894\n",
      "  Valid: LossCls=0.4770, LossBbox=0.0010, Total=0.4963, Acc=0.8947, IoU=0.2005\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4963\n",
      "DEBUG train_multitask_model: Epoch 47, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 47/120 Duraci贸n: 2.22s\n",
      "  Train: LossCls=0.2061, LossBbox=0.0013, Total=0.2321, Acc=0.9934, IoU=0.1948\n",
      "  Valid: LossCls=0.4694, LossBbox=0.0009, Total=0.4882, Acc=0.8947, IoU=0.2069\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4882\n",
      "DEBUG train_multitask_model: Epoch 48, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 48/120 Duraci贸n: 2.18s\n",
      "  Train: LossCls=0.1898, LossBbox=0.0012, Total=0.2147, Acc=0.9934, IoU=0.1846\n",
      "  Valid: LossCls=0.4608, LossBbox=0.0010, Total=0.4802, Acc=0.9211, IoU=0.2009\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4802\n",
      "DEBUG train_multitask_model: Epoch 49, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 49/120 Duraci贸n: 2.19s\n",
      "  Train: LossCls=0.1911, LossBbox=0.0012, Total=0.2160, Acc=0.9934, IoU=0.2028\n",
      "  Valid: LossCls=0.4518, LossBbox=0.0010, Total=0.4709, Acc=0.8947, IoU=0.2045\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4709\n",
      "DEBUG train_multitask_model: Epoch 50, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 50/120 Duraci贸n: 2.22s\n",
      "  Train: LossCls=0.1962, LossBbox=0.0011, Total=0.2190, Acc=0.9934, IoU=0.1977\n",
      "  Valid: LossCls=0.4513, LossBbox=0.0009, Total=0.4702, Acc=0.8947, IoU=0.2039\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4702\n",
      "DEBUG train_multitask_model: Epoch 51, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 51/120 Duraci贸n: 2.22s\n",
      "  Train: LossCls=0.1722, LossBbox=0.0012, Total=0.1954, Acc=1.0000, IoU=0.2039\n",
      "  Valid: LossCls=0.4413, LossBbox=0.0010, Total=0.4605, Acc=0.8947, IoU=0.2062\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4605\n",
      "DEBUG train_multitask_model: Epoch 52, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 52/120 Duraci贸n: 2.22s\n",
      "  Train: LossCls=0.1930, LossBbox=0.0012, Total=0.2173, Acc=0.9934, IoU=0.1915\n",
      "  Valid: LossCls=0.4410, LossBbox=0.0009, Total=0.4599, Acc=0.8947, IoU=0.2103\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4599\n",
      "DEBUG train_multitask_model: Epoch 53, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 53/120 Duraci贸n: 2.43s\n",
      "  Train: LossCls=0.1833, LossBbox=0.0012, Total=0.2072, Acc=0.9934, IoU=0.1988\n",
      "  Valid: LossCls=0.4456, LossBbox=0.0009, Total=0.4643, Acc=0.8947, IoU=0.2120\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 54, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 54/120 Duraci贸n: 2.39s\n",
      "  Train: LossCls=0.1845, LossBbox=0.0012, Total=0.2090, Acc=0.9934, IoU=0.1889\n",
      "  Valid: LossCls=0.4461, LossBbox=0.0009, Total=0.4650, Acc=0.8947, IoU=0.2118\n",
      "  Val_loss_total no mejor贸. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 55, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 55/120 Duraci贸n: 2.37s\n",
      "  Train: LossCls=0.1469, LossBbox=0.0011, Total=0.1698, Acc=0.9934, IoU=0.1878\n",
      "  Valid: LossCls=0.4307, LossBbox=0.0009, Total=0.4490, Acc=0.9211, IoU=0.2180\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4490\n",
      "DEBUG train_multitask_model: Epoch 56, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 56/120 Duraci贸n: 2.51s\n",
      "  Train: LossCls=0.1634, LossBbox=0.0011, Total=0.1856, Acc=1.0000, IoU=0.2206\n",
      "  Valid: LossCls=0.4380, LossBbox=0.0009, Total=0.4566, Acc=0.8947, IoU=0.2124\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 57, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 57/120 Duraci贸n: 2.22s\n",
      "  Train: LossCls=0.1511, LossBbox=0.0010, Total=0.1704, Acc=1.0000, IoU=0.2212\n",
      "  Valid: LossCls=0.4407, LossBbox=0.0009, Total=0.4592, Acc=0.8947, IoU=0.2131\n",
      "  Val_loss_total no mejor贸. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 58, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 58/120 Duraci贸n: 2.22s\n",
      "  Train: LossCls=0.1661, LossBbox=0.0011, Total=0.1874, Acc=1.0000, IoU=0.2146\n",
      "  Valid: LossCls=0.4347, LossBbox=0.0009, Total=0.4529, Acc=0.8947, IoU=0.2141\n",
      "  Val_loss_total no mejor贸. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 59, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 59/120 Duraci贸n: 2.19s\n",
      "  Train: LossCls=0.1690, LossBbox=0.0012, Total=0.1921, Acc=1.0000, IoU=0.2208\n",
      "  Valid: LossCls=0.4345, LossBbox=0.0009, Total=0.4523, Acc=0.8947, IoU=0.2149\n",
      "  Val_loss_total no mejor贸. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 60, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 60/120 Duraci贸n: 2.24s\n",
      "  Train: LossCls=0.1424, LossBbox=0.0012, Total=0.1657, Acc=1.0000, IoU=0.2000\n",
      "  Valid: LossCls=0.4303, LossBbox=0.0009, Total=0.4478, Acc=0.8947, IoU=0.2162\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4478\n",
      "DEBUG train_multitask_model: Epoch 61, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 61/120 Duraci贸n: 2.26s\n",
      "  Train: LossCls=0.1347, LossBbox=0.0011, Total=0.1568, Acc=1.0000, IoU=0.2080\n",
      "  Valid: LossCls=0.4323, LossBbox=0.0009, Total=0.4502, Acc=0.8947, IoU=0.2107\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 62, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 62/120 Duraci贸n: 2.22s\n",
      "  Train: LossCls=0.1328, LossBbox=0.0011, Total=0.1554, Acc=1.0000, IoU=0.1920\n",
      "  Valid: LossCls=0.4199, LossBbox=0.0009, Total=0.4385, Acc=0.8947, IoU=0.2091\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4385\n",
      "DEBUG train_multitask_model: Epoch 63, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 63/120 Duraci贸n: 2.18s\n",
      "  Train: LossCls=0.1336, LossBbox=0.0011, Total=0.1561, Acc=1.0000, IoU=0.1990\n",
      "  Valid: LossCls=0.4205, LossBbox=0.0009, Total=0.4393, Acc=0.8947, IoU=0.2140\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 64, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 64/120 Duraci贸n: 2.23s\n",
      "  Train: LossCls=0.1369, LossBbox=0.0011, Total=0.1592, Acc=1.0000, IoU=0.2158\n",
      "  Valid: LossCls=0.4181, LossBbox=0.0009, Total=0.4369, Acc=0.8947, IoU=0.2120\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4369\n",
      "DEBUG train_multitask_model: Epoch 65, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 65/120 Duraci贸n: 2.71s\n",
      "  Train: LossCls=0.1394, LossBbox=0.0011, Total=0.1604, Acc=1.0000, IoU=0.2170\n",
      "  Valid: LossCls=0.4206, LossBbox=0.0009, Total=0.4394, Acc=0.8947, IoU=0.2082\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 66, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 66/120 Duraci贸n: 2.47s\n",
      "  Train: LossCls=0.1178, LossBbox=0.0009, Total=0.1368, Acc=0.9934, IoU=0.2253\n",
      "  Valid: LossCls=0.4128, LossBbox=0.0009, Total=0.4312, Acc=0.8947, IoU=0.2187\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4312\n",
      "DEBUG train_multitask_model: Epoch 67, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 67/120 Duraci贸n: 2.48s\n",
      "  Train: LossCls=0.1157, LossBbox=0.0010, Total=0.1359, Acc=1.0000, IoU=0.2275\n",
      "  Valid: LossCls=0.3991, LossBbox=0.0009, Total=0.4177, Acc=0.9211, IoU=0.2172\n",
      "ERROR AL INTENTAR GUARDAR EL MODELO en './Resultados/pretrained_model_20250525_201424.pth': File ./Resultados/pretrained_model_20250525_201424.pth cannot be opened.\n",
      "DEBUG train_multitask_model: Epoch 68, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 68/120 Duraci贸n: 2.40s\n",
      "  Train: LossCls=0.1214, LossBbox=0.0011, Total=0.1435, Acc=1.0000, IoU=0.1964\n",
      "  Valid: LossCls=0.4019, LossBbox=0.0009, Total=0.4201, Acc=0.9211, IoU=0.2207\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 69, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 69/120 Duraci贸n: 2.42s\n",
      "  Train: LossCls=0.1064, LossBbox=0.0010, Total=0.1265, Acc=1.0000, IoU=0.2362\n",
      "  Valid: LossCls=0.3955, LossBbox=0.0009, Total=0.4137, Acc=0.8947, IoU=0.2211\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4137\n",
      "DEBUG train_multitask_model: Epoch 70, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 70/120 Duraci贸n: 2.42s\n",
      "  Train: LossCls=0.1206, LossBbox=0.0010, Total=0.1404, Acc=1.0000, IoU=0.2315\n",
      "  Valid: LossCls=0.3972, LossBbox=0.0009, Total=0.4154, Acc=0.9211, IoU=0.2172\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 71, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 71/120 Duraci贸n: 2.39s\n",
      "  Train: LossCls=0.1128, LossBbox=0.0009, Total=0.1313, Acc=1.0000, IoU=0.2413\n",
      "  Valid: LossCls=0.4010, LossBbox=0.0009, Total=0.4189, Acc=0.9211, IoU=0.2178\n",
      "  Val_loss_total no mejor贸. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 72, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 72/120 Duraci贸n: 2.41s\n",
      "  Train: LossCls=0.1114, LossBbox=0.0009, Total=0.1298, Acc=1.0000, IoU=0.2255\n",
      "  Valid: LossCls=0.4033, LossBbox=0.0009, Total=0.4210, Acc=0.8947, IoU=0.2218\n",
      "  Val_loss_total no mejor贸. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 73, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 73/120 Duraci贸n: 2.38s\n",
      "  Train: LossCls=0.1106, LossBbox=0.0010, Total=0.1299, Acc=1.0000, IoU=0.2217\n",
      "  Valid: LossCls=0.3977, LossBbox=0.0009, Total=0.4153, Acc=0.9211, IoU=0.2238\n",
      "  Val_loss_total no mejor贸. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 74, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 74/120 Duraci贸n: 2.48s\n",
      "  Train: LossCls=0.1008, LossBbox=0.0010, Total=0.1208, Acc=1.0000, IoU=0.2174\n",
      "  Valid: LossCls=0.3924, LossBbox=0.0009, Total=0.4103, Acc=0.8947, IoU=0.2213\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.4103\n",
      "DEBUG train_multitask_model: Epoch 75, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 75/120 Duraci贸n: 2.31s\n",
      "  Train: LossCls=0.1009, LossBbox=0.0010, Total=0.1202, Acc=1.0000, IoU=0.2303\n",
      "  Valid: LossCls=0.3961, LossBbox=0.0009, Total=0.4135, Acc=0.9211, IoU=0.2236\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 76, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 76/120 Duraci贸n: 2.38s\n",
      "  Train: LossCls=0.1076, LossBbox=0.0011, Total=0.1288, Acc=1.0000, IoU=0.2168\n",
      "  Valid: LossCls=0.4039, LossBbox=0.0009, Total=0.4216, Acc=0.8947, IoU=0.2232\n",
      "  Val_loss_total no mejor贸. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 77, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 77/120 Duraci贸n: 2.35s\n",
      "  Train: LossCls=0.1109, LossBbox=0.0011, Total=0.1327, Acc=1.0000, IoU=0.1990\n",
      "  Valid: LossCls=0.3997, LossBbox=0.0009, Total=0.4174, Acc=0.9211, IoU=0.2228\n",
      "  Val_loss_total no mejor贸. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 78, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 78/120 Duraci贸n: 2.31s\n",
      "  Train: LossCls=0.1087, LossBbox=0.0010, Total=0.1281, Acc=1.0000, IoU=0.2244\n",
      "  Valid: LossCls=0.4024, LossBbox=0.0009, Total=0.4196, Acc=0.8947, IoU=0.2311\n",
      "  Val_loss_total no mejor贸. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 79, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 79/120 Duraci贸n: 2.64s\n",
      "  Train: LossCls=0.1086, LossBbox=0.0010, Total=0.1289, Acc=0.9934, IoU=0.2133\n",
      "  Valid: LossCls=0.4003, LossBbox=0.0008, Total=0.4169, Acc=0.8947, IoU=0.2384\n",
      "  Val_loss_total no mejor贸. Paciencia: 5/15\n",
      "DEBUG train_multitask_model: Epoch 80, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 80/120 Duraci贸n: 2.56s\n",
      "  Train: LossCls=0.0973, LossBbox=0.0009, Total=0.1162, Acc=1.0000, IoU=0.2095\n",
      "  Valid: LossCls=0.3963, LossBbox=0.0009, Total=0.4134, Acc=0.8947, IoU=0.2374\n",
      "  Val_loss_total no mejor贸. Paciencia: 6/15\n",
      "DEBUG train_multitask_model: Epoch 81, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 81/120 Duraci贸n: 2.47s\n",
      "  Train: LossCls=0.0892, LossBbox=0.0009, Total=0.1069, Acc=1.0000, IoU=0.2350\n",
      "  Valid: LossCls=0.3781, LossBbox=0.0009, Total=0.3957, Acc=0.8947, IoU=0.2347\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3957\n",
      "DEBUG train_multitask_model: Epoch 82, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 82/120 Duraci贸n: 2.66s\n",
      "  Train: LossCls=0.0882, LossBbox=0.0010, Total=0.1081, Acc=1.0000, IoU=0.2402\n",
      "  Valid: LossCls=0.3734, LossBbox=0.0009, Total=0.3911, Acc=0.8947, IoU=0.2356\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3911\n",
      "DEBUG train_multitask_model: Epoch 83, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 83/120 Duraci贸n: 2.42s\n",
      "  Train: LossCls=0.0891, LossBbox=0.0010, Total=0.1085, Acc=1.0000, IoU=0.2277\n",
      "  Valid: LossCls=0.3717, LossBbox=0.0009, Total=0.3896, Acc=0.8947, IoU=0.2312\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3896\n",
      "DEBUG train_multitask_model: Epoch 84, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 84/120 Duraci贸n: 2.37s\n",
      "  Train: LossCls=0.0882, LossBbox=0.0009, Total=0.1070, Acc=1.0000, IoU=0.2278\n",
      "  Valid: LossCls=0.3700, LossBbox=0.0009, Total=0.3873, Acc=0.9211, IoU=0.2321\n",
      "ERROR AL INTENTAR GUARDAR EL MODELO en './Resultados/pretrained_model_20250525_201424.pth': File ./Resultados/pretrained_model_20250525_201424.pth cannot be opened.\n",
      "DEBUG train_multitask_model: Epoch 85, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 85/120 Duraci贸n: 2.61s\n",
      "  Train: LossCls=0.0842, LossBbox=0.0009, Total=0.1025, Acc=1.0000, IoU=0.2203\n",
      "  Valid: LossCls=0.3643, LossBbox=0.0009, Total=0.3820, Acc=0.8947, IoU=0.2310\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3820\n",
      "DEBUG train_multitask_model: Epoch 86, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 86/120 Duraci贸n: 2.59s\n",
      "  Train: LossCls=0.0944, LossBbox=0.0009, Total=0.1133, Acc=1.0000, IoU=0.2157\n",
      "  Valid: LossCls=0.3692, LossBbox=0.0009, Total=0.3868, Acc=0.8947, IoU=0.2320\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 87, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 87/120 Duraci贸n: 2.37s\n",
      "  Train: LossCls=0.0873, LossBbox=0.0009, Total=0.1062, Acc=1.0000, IoU=0.2266\n",
      "  Valid: LossCls=0.3677, LossBbox=0.0009, Total=0.3854, Acc=0.8947, IoU=0.2343\n",
      "  Val_loss_total no mejor贸. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 88, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 88/120 Duraci贸n: 2.41s\n",
      "  Train: LossCls=0.1146, LossBbox=0.0009, Total=0.1334, Acc=1.0000, IoU=0.2341\n",
      "  Valid: LossCls=0.3800, LossBbox=0.0009, Total=0.3971, Acc=0.9211, IoU=0.2336\n",
      "  Val_loss_total no mejor贸. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 89, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 89/120 Duraci贸n: 2.36s\n",
      "  Train: LossCls=0.0973, LossBbox=0.0009, Total=0.1155, Acc=1.0000, IoU=0.2250\n",
      "  Valid: LossCls=0.3792, LossBbox=0.0008, Total=0.3957, Acc=0.8947, IoU=0.2357\n",
      "  Val_loss_total no mejor贸. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 90, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 90/120 Duraci贸n: 2.45s\n",
      "  Train: LossCls=0.0780, LossBbox=0.0009, Total=0.0958, Acc=1.0000, IoU=0.2351\n",
      "  Valid: LossCls=0.3749, LossBbox=0.0008, Total=0.3917, Acc=0.8947, IoU=0.2332\n",
      "  Val_loss_total no mejor贸. Paciencia: 5/15\n",
      "DEBUG train_multitask_model: Epoch 91, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 91/120 Duraci贸n: 2.45s\n",
      "  Train: LossCls=0.0925, LossBbox=0.0010, Total=0.1122, Acc=1.0000, IoU=0.2261\n",
      "  Valid: LossCls=0.3798, LossBbox=0.0008, Total=0.3965, Acc=0.8947, IoU=0.2308\n",
      "  Val_loss_total no mejor贸. Paciencia: 6/15\n",
      "DEBUG train_multitask_model: Epoch 92, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 92/120 Duraci贸n: 2.43s\n",
      "  Train: LossCls=0.0700, LossBbox=0.0009, Total=0.0873, Acc=1.0000, IoU=0.2180\n",
      "  Valid: LossCls=0.3810, LossBbox=0.0008, Total=0.3978, Acc=0.8947, IoU=0.2289\n",
      "  Val_loss_total no mejor贸. Paciencia: 7/15\n",
      "DEBUG train_multitask_model: Epoch 93, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 93/120 Duraci贸n: 2.46s\n",
      "  Train: LossCls=0.0665, LossBbox=0.0008, Total=0.0830, Acc=1.0000, IoU=0.2394\n",
      "  Valid: LossCls=0.3777, LossBbox=0.0008, Total=0.3940, Acc=0.8947, IoU=0.2351\n",
      "  Val_loss_total no mejor贸. Paciencia: 8/15\n",
      "DEBUG train_multitask_model: Epoch 94, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 94/120 Duraci贸n: 2.32s\n",
      "  Train: LossCls=0.0991, LossBbox=0.0008, Total=0.1159, Acc=0.9934, IoU=0.2478\n",
      "  Valid: LossCls=0.3641, LossBbox=0.0008, Total=0.3810, Acc=0.8947, IoU=0.2306\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3810\n",
      "DEBUG train_multitask_model: Epoch 95, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 95/120 Duraci贸n: 2.36s\n",
      "  Train: LossCls=0.1018, LossBbox=0.0010, Total=0.1217, Acc=1.0000, IoU=0.2279\n",
      "  Valid: LossCls=0.3650, LossBbox=0.0008, Total=0.3815, Acc=0.8947, IoU=0.2281\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 96, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 96/120 Duraci贸n: 2.45s\n",
      "  Train: LossCls=0.0771, LossBbox=0.0010, Total=0.0963, Acc=1.0000, IoU=0.2252\n",
      "  Valid: LossCls=0.3593, LossBbox=0.0008, Total=0.3761, Acc=0.8947, IoU=0.2233\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3761\n",
      "DEBUG train_multitask_model: Epoch 97, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 97/120 Duraci贸n: 2.49s\n",
      "  Train: LossCls=0.0810, LossBbox=0.0008, Total=0.0970, Acc=1.0000, IoU=0.2453\n",
      "  Valid: LossCls=0.3465, LossBbox=0.0009, Total=0.3636, Acc=0.8947, IoU=0.2234\n",
      "ERROR AL INTENTAR GUARDAR EL MODELO en './Resultados/pretrained_model_20250525_201424.pth': File ./Resultados/pretrained_model_20250525_201424.pth cannot be opened.\n",
      "DEBUG train_multitask_model: Epoch 98, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 98/120 Duraci贸n: 2.83s\n",
      "  Train: LossCls=0.0807, LossBbox=0.0007, Total=0.0952, Acc=1.0000, IoU=0.2700\n",
      "  Valid: LossCls=0.3493, LossBbox=0.0008, Total=0.3661, Acc=0.8947, IoU=0.2257\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 99, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 99/120 Duraci贸n: 2.81s\n",
      "  Train: LossCls=0.0843, LossBbox=0.0009, Total=0.1027, Acc=1.0000, IoU=0.2327\n",
      "  Valid: LossCls=0.3536, LossBbox=0.0008, Total=0.3705, Acc=0.8947, IoU=0.2213\n",
      "  Val_loss_total no mejor贸. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 100, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 100/120 Duraci贸n: 2.38s\n",
      "  Train: LossCls=0.0783, LossBbox=0.0009, Total=0.0960, Acc=1.0000, IoU=0.2384\n",
      "  Valid: LossCls=0.3550, LossBbox=0.0009, Total=0.3723, Acc=0.8947, IoU=0.2254\n",
      "  Val_loss_total no mejor贸. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 101, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 101/120 Duraci贸n: 3.14s\n",
      "  Train: LossCls=0.0654, LossBbox=0.0008, Total=0.0819, Acc=1.0000, IoU=0.2622\n",
      "  Valid: LossCls=0.3502, LossBbox=0.0008, Total=0.3670, Acc=0.8947, IoU=0.2296\n",
      "  Val_loss_total no mejor贸. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 102, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 102/120 Duraci贸n: 2.40s\n",
      "  Train: LossCls=0.0796, LossBbox=0.0008, Total=0.0958, Acc=0.9934, IoU=0.2587\n",
      "  Valid: LossCls=0.3445, LossBbox=0.0008, Total=0.3612, Acc=0.8947, IoU=0.2314\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3612\n",
      "DEBUG train_multitask_model: Epoch 103, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 103/120 Duraci贸n: 2.41s\n",
      "  Train: LossCls=0.0612, LossBbox=0.0008, Total=0.0771, Acc=1.0000, IoU=0.2380\n",
      "  Valid: LossCls=0.3478, LossBbox=0.0009, Total=0.3649, Acc=0.8947, IoU=0.2322\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 104, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 104/120 Duraci贸n: 2.45s\n",
      "  Train: LossCls=0.0698, LossBbox=0.0008, Total=0.0859, Acc=1.0000, IoU=0.2560\n",
      "  Valid: LossCls=0.3453, LossBbox=0.0009, Total=0.3624, Acc=0.8947, IoU=0.2294\n",
      "  Val_loss_total no mejor贸. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 105, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 105/120 Duraci贸n: 2.39s\n",
      "  Train: LossCls=0.0681, LossBbox=0.0009, Total=0.0856, Acc=1.0000, IoU=0.2353\n",
      "  Valid: LossCls=0.3484, LossBbox=0.0008, Total=0.3651, Acc=0.8947, IoU=0.2363\n",
      "  Val_loss_total no mejor贸. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 106, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 106/120 Duraci贸n: 3.13s\n",
      "  Train: LossCls=0.0688, LossBbox=0.0008, Total=0.0838, Acc=0.9934, IoU=0.2533\n",
      "  Valid: LossCls=0.3539, LossBbox=0.0008, Total=0.3706, Acc=0.8947, IoU=0.2341\n",
      "  Val_loss_total no mejor贸. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 107, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 107/120 Duraci贸n: 2.46s\n",
      "  Train: LossCls=0.0654, LossBbox=0.0008, Total=0.0822, Acc=1.0000, IoU=0.2530\n",
      "  Valid: LossCls=0.3428, LossBbox=0.0008, Total=0.3594, Acc=0.8947, IoU=0.2376\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3594\n",
      "DEBUG train_multitask_model: Epoch 108, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 108/120 Duraci贸n: 2.60s\n",
      "  Train: LossCls=0.0651, LossBbox=0.0009, Total=0.0823, Acc=1.0000, IoU=0.2378\n",
      "  Valid: LossCls=0.3397, LossBbox=0.0008, Total=0.3562, Acc=0.8947, IoU=0.2356\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3562\n",
      "DEBUG train_multitask_model: Epoch 109, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 109/120 Duraci贸n: 2.99s\n",
      "  Train: LossCls=0.0611, LossBbox=0.0008, Total=0.0770, Acc=1.0000, IoU=0.2770\n",
      "  Valid: LossCls=0.3347, LossBbox=0.0008, Total=0.3509, Acc=0.8947, IoU=0.2415\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3509\n",
      "DEBUG train_multitask_model: Epoch 110, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 110/120 Duraci贸n: 2.59s\n",
      "  Train: LossCls=0.0614, LossBbox=0.0008, Total=0.0774, Acc=1.0000, IoU=0.2586\n",
      "  Valid: LossCls=0.3448, LossBbox=0.0008, Total=0.3609, Acc=0.8947, IoU=0.2432\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 111, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 111/120 Duraci贸n: 2.35s\n",
      "  Train: LossCls=0.0560, LossBbox=0.0008, Total=0.0719, Acc=1.0000, IoU=0.2503\n",
      "  Valid: LossCls=0.3495, LossBbox=0.0008, Total=0.3658, Acc=0.8947, IoU=0.2467\n",
      "  Val_loss_total no mejor贸. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 112, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 112/120 Duraci贸n: 2.35s\n",
      "  Train: LossCls=0.0614, LossBbox=0.0009, Total=0.0797, Acc=1.0000, IoU=0.2467\n",
      "  Valid: LossCls=0.3589, LossBbox=0.0008, Total=0.3752, Acc=0.8947, IoU=0.2387\n",
      "  Val_loss_total no mejor贸. Paciencia: 3/15\n",
      "DEBUG train_multitask_model: Epoch 113, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 113/120 Duraci贸n: 2.75s\n",
      "  Train: LossCls=0.0614, LossBbox=0.0007, Total=0.0753, Acc=1.0000, IoU=0.2636\n",
      "  Valid: LossCls=0.3663, LossBbox=0.0008, Total=0.3825, Acc=0.8947, IoU=0.2346\n",
      "  Val_loss_total no mejor贸. Paciencia: 4/15\n",
      "DEBUG train_multitask_model: Epoch 114, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 114/120 Duraci贸n: 2.84s\n",
      "  Train: LossCls=0.0661, LossBbox=0.0007, Total=0.0811, Acc=1.0000, IoU=0.2589\n",
      "  Valid: LossCls=0.3613, LossBbox=0.0008, Total=0.3775, Acc=0.8947, IoU=0.2380\n",
      "  Val_loss_total no mejor贸. Paciencia: 5/15\n",
      "DEBUG train_multitask_model: Epoch 115, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 115/120 Duraci贸n: 2.46s\n",
      "  Train: LossCls=0.0529, LossBbox=0.0008, Total=0.0686, Acc=1.0000, IoU=0.2461\n",
      "  Valid: LossCls=0.3478, LossBbox=0.0008, Total=0.3634, Acc=0.8947, IoU=0.2554\n",
      "  Val_loss_total no mejor贸. Paciencia: 6/15\n",
      "DEBUG train_multitask_model: Epoch 116, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 116/120 Duraci贸n: 2.84s\n",
      "  Train: LossCls=0.0583, LossBbox=0.0007, Total=0.0730, Acc=1.0000, IoU=0.2641\n",
      "  Valid: LossCls=0.3318, LossBbox=0.0008, Total=0.3482, Acc=0.9211, IoU=0.2451\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3482\n",
      "DEBUG train_multitask_model: Epoch 117, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 117/120 Duraci贸n: 2.40s\n",
      "  Train: LossCls=0.0650, LossBbox=0.0008, Total=0.0805, Acc=1.0000, IoU=0.2389\n",
      "  Valid: LossCls=0.3264, LossBbox=0.0008, Total=0.3431, Acc=0.8947, IoU=0.2428\n",
      "  Mejor modelo guardado en './Resultados/pretrained_model_20250525_201424.pth' con val_loss_total: 0.3431\n",
      "DEBUG train_multitask_model: Epoch 118, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 118/120 Duraci贸n: 2.30s\n",
      "  Train: LossCls=0.0794, LossBbox=0.0007, Total=0.0938, Acc=1.0000, IoU=0.2712\n",
      "  Valid: LossCls=0.3364, LossBbox=0.0008, Total=0.3529, Acc=0.8947, IoU=0.2459\n",
      "  Val_loss_total no mejor贸. Paciencia: 1/15\n",
      "DEBUG train_multitask_model: Epoch 119, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 119/120 Duraci贸n: 2.36s\n",
      "  Train: LossCls=0.0564, LossBbox=0.0008, Total=0.0717, Acc=1.0000, IoU=0.2489\n",
      "  Valid: LossCls=0.3388, LossBbox=0.0008, Total=0.3550, Acc=0.8947, IoU=0.2417\n",
      "  Val_loss_total no mejor贸. Paciencia: 2/15\n",
      "DEBUG train_multitask_model: Epoch 120, total_train_samples procesadas esta 茅poca: 151\n",
      "Epoch 120/120 Duraci贸n: 2.47s\n",
      "  Train: LossCls=0.0696, LossBbox=0.0008, Total=0.0853, Acc=1.0000, IoU=0.2568\n",
      "  Valid: LossCls=0.3460, LossBbox=0.0008, Total=0.3619, Acc=0.8947, IoU=0.2446\n",
      "  Val_loss_total no mejor贸. Paciencia: 3/15\n",
      "Cargando el mejor estado del modelo guardado al final del entrenamiento.\n",
      "Entrenamiento finalizado.\n",
      "Entrenamiento del script de Run completado.\n"
     ]
    }
   ],
   "source": [
    "#  DEFINICIN DE collate_fn_skip_none (col贸cala aqu铆 o en una celda anterior si ya est谩)\n",
    "def collate_fn_skip_none(batch):\n",
    "    batch_original_len = len(batch)\n",
    "    batch_filtered = [item for item in batch if item is not None]\n",
    "    if batch_original_len != len(batch_filtered) and batch_original_len > 0:\n",
    "        pass # print(f\"DEBUG collate_fn: Filtradas {batch_original_len - len(batch_filtered)} muestras None.\")\n",
    "    if not batch_filtered:\n",
    "        return None\n",
    "    try:\n",
    "        return torch.utils.data.dataloader.default_collate(batch_filtered)\n",
    "    except Exception as e:\n",
    "        # print(f\"ERROR en default_collate dentro de collate_fn_skip_none: {e}\")\n",
    "        raise\n",
    "\n",
    "# if __name__ == '__main__': # Descomenta si ejecutas como script .py\n",
    "\n",
    "reset_seed(42) \n",
    "\n",
    "DATA_DIR_RUN = '../Datos/' \n",
    "BATCH_SIZE_RUN = 32 \n",
    "\n",
    "# DIR_Results DEBE estar definida globalmente (ej. DIR_Results = './Resultados/')\n",
    "if 'DIR_Results' not in globals():\n",
    "    print(\"ADVERTENCIA: DIR_Results no estaba definido globalmente. Usando './Resultados_default/' para esta ejecuci贸n.\")\n",
    "    DIR_Results = './Resultados_default/' \n",
    "\n",
    "# Convertir DIR_Results a una ruta absoluta y crearla\n",
    "absolute_dir_results = os.path.abspath(DIR_Results)\n",
    "os.makedirs(absolute_dir_results, exist_ok=True) \n",
    "print(f\"Los resultados se guardar谩n en el directorio: {absolute_dir_results}\")\n",
    "\n",
    "\n",
    "print(\"Cargando y preprocesando el DataFrame...\")\n",
    "img_dir_run = osp.join(DATA_DIR_RUN, \"images/images\")\n",
    "\n",
    "\n",
    "if not osp.exists(img_dir_run):\n",
    "    print(f\"ERROR: El directorio de im谩genes no existe: {img_dir_run}\")\n",
    "path_train_csv = osp.join(DATA_DIR_RUN, \"train.csv\")\n",
    "if not osp.exists(path_train_csv):\n",
    "    print(f\"ERROR: El archivo 'train.csv' no se encontr贸 en {DATA_DIR_RUN}\")\n",
    "try:\n",
    "    df_original_run = pd.read_csv(path_train_csv)\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: No se pudo leer 'train.csv': {e}\")\n",
    "df_original_run['class_id'] = df_original_run['class'].map(obj2id) \n",
    "df_original_run.dropna(subset=['class_id'], inplace=True)\n",
    "df_original_run['class_id'] = df_original_run['class_id'].astype(int)\n",
    "columns_f_run = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class', 'class_id']\n",
    "missing_cols = [col for col in columns_f_run if col not in df_original_run.columns]\n",
    "if missing_cols:\n",
    "    print(f\"ERROR: Faltan las siguientes columnas en train.csv: {missing_cols}.\")\n",
    "df_run = df_original_run[columns_f_run].copy()\n",
    "if not df_run.empty:\n",
    "    bbox_cols_run = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "    for col in bbox_cols_run:\n",
    "        df_run[col] = pd.to_numeric(df_run[col], errors='coerce')\n",
    "    df_run.dropna(subset=bbox_cols_run, inplace=True)\n",
    "    if not df_run.empty:\n",
    "        df_run['xmin'] = df_run['xmin'] / IMG_ORIG_W\n",
    "        df_run['xmax'] = df_run['xmax'] / IMG_ORIG_W\n",
    "        df_run['ymin'] = df_run['ymin'] / IMG_ORIG_H\n",
    "        df_run['ymax'] = df_run['ymax'] / IMG_ORIG_H\n",
    "        df_run[['xmin', 'ymin', 'xmax', 'ymax']] = df_run[['xmin', 'ymin', 'xmax', 'ymax']].clip(0.0, 1.0)\n",
    "        print(\"Bounding boxes en el script de Run normalizados y acotados a [0,1].\")\n",
    "    else:\n",
    "        print(\"ERROR: DataFrame para el script de Run vac铆o despu茅s de asegurar columnas de bbox num茅ricas.\")\n",
    "else:\n",
    "    print(\"ERROR: DataFrame para el script de Run est谩 vac铆o inicialmente.\")\n",
    "if df_run.empty or 'class_id' not in df_run.columns or df_run['class_id'].isnull().all():\n",
    "    print(\"ERROR: DataFrame vac铆o o sin 'class_id' v谩lidos para la partici贸n estratificada.\")\n",
    "    train_df_run, val_df_run = pd.DataFrame(columns=df_run.columns), pd.DataFrame(columns=df_run.columns) \n",
    "else:\n",
    "    can_stratify = True\n",
    "    if df_run['class_id'].nunique() < 2 : \n",
    "        can_stratify = False\n",
    "    else:\n",
    "        value_counts = df_run['class_id'].value_counts()\n",
    "        if any(value_counts < 2): \n",
    "            can_stratify = False\n",
    "    if can_stratify:\n",
    "        try:\n",
    "            train_df_run, val_df_run = train_test_split(df_run, test_size=0.2, random_state=42, stratify=df_run['class_id'])\n",
    "        except ValueError as e: \n",
    "            print(f\"Advertencia: Error durante la partici贸n estratificada ({e}). Usando partici贸n no estratificada.\")\n",
    "            train_df_run, val_df_run = train_test_split(df_run, test_size=0.2, random_state=42)\n",
    "    else:\n",
    "        print(\"Advertencia: No hay suficientes muestras/clases para una partici贸n estratificada. Usando partici贸n no estratificada.\")\n",
    "        train_df_run, val_df_run = train_test_split(df_run, test_size=0.2, random_state=42)\n",
    "print(f\"DEBUG: Longitud de df_run: {len(df_run)}\")\n",
    "print(f\"DEBUG: Longitud de train_df_run: {len(train_df_run)}\")\n",
    "\n",
    "\n",
    "print(f\"Usando medias de ImageNet para el script de Run: {MEANS_IMAGENET}\")\n",
    "print(f\"Usando desviaciones est谩ndar de ImageNet para el script de Run: {STDS_IMAGENET}\")\n",
    "\n",
    "print(\"DEBUG: Usando pipeline de transformaci贸n de entrenamiento MNIMO con BboxParams por DEFECTO.\")\n",
    "run_train_transforms = A.Compose([\n",
    "    A.Resize(height=TARGET_H, width=TARGET_W), \n",
    "    #A.HorizontalFlip(p=0.5),\n",
    "    #A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=0.2), # <<< MUY SUAVE y p baja\n",
    "    #A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.02, rotate_limit=5, p=0.2, border_mode=cv2.BORDER_CONSTANT), # 'value' eliminado; si da warning, comenta la l铆nea.\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2() \n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "run_eval_transforms = A.Compose([ \n",
    "    A.Resize(height=TARGET_H, width=TARGET_W),\n",
    "    A.Normalize(mean=MEANS_IMAGENET, std=STDS_IMAGENET, max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "print(\"Creando Datasets y DataLoaders finales para el script de Run...\")\n",
    "# ... (Creaci贸n de train_dataset_run, val_dataset_run como antes) ...\n",
    "if not train_df_run.empty:\n",
    "    train_dataset_run = militarDataset(df=train_df_run, img_dir=img_dir_run, transform=run_train_transforms)\n",
    "else:\n",
    "    train_dataset_run = [] \n",
    "    print(\"Advertencia: train_df_run est谩 vac铆o, train_dataset_run ser谩 una lista vac铆a.\")\n",
    "if not val_df_run.empty:\n",
    "    val_dataset_run = militarDataset(df=val_df_run, img_dir=img_dir_run, transform=run_eval_transforms)\n",
    "else:\n",
    "    val_dataset_run = []\n",
    "    print(\"Advertencia: val_df_run est谩 vac铆o, val_dataset_run ser谩 una lista vac铆a.\")\n",
    "\n",
    "# ... (Bucle de inspecci贸n de train_dataset_run como antes) ...\n",
    "if len(train_dataset_run) > 0:\n",
    "    print(f\"\\nDEBUG: Inspeccionando las primeras (hasta) 5 muestras de train_dataset_run (longitud total: {len(train_dataset_run)}):\")\n",
    "    valid_samples_count_debug = 0\n",
    "    for i in range(min(5, len(train_dataset_run))):\n",
    "        # print(f\"  DEBUG: Intentando obtener train_dataset_run[{i}]...\") # Puede ser muy verboso\n",
    "        try:\n",
    "            sample = train_dataset_run[i] \n",
    "            if sample is None:\n",
    "                # print(f\"    DEBUG: train_dataset_run[{i}] devolvi贸 None.\")\n",
    "                pass\n",
    "            else:\n",
    "                # img_tensor, cls_tensor, bbox_tensor = sample\n",
    "                # print(f\"    DEBUG: train_dataset_run[{i}] OK. img_shape={img_tensor.shape}, cls_id={cls_tensor.item()}, bbox={bbox_tensor.squeeze().tolist()}\")\n",
    "                valid_samples_count_debug += 1\n",
    "        except Exception as e:\n",
    "            # print(f\"    DEBUG: Error al obtener train_dataset_run[{i}]: {e}\")\n",
    "            pass\n",
    "    print(f\"DEBUG: De las primeras muestras inspeccionadas, {valid_samples_count_debug} fueron v谩lidas.\\n\")\n",
    "    if len(train_df_run) > 0 and valid_samples_count_debug == 0 and len(train_dataset_run) > 0: \n",
    "        print(\"ALERTA DE DEBUG: Ninguna de las primeras muestras del dataset de entrenamiento es v谩lida. Revisa los prints internos de 'militarDataset'.\")\n",
    "else:\n",
    "    print(\"DEBUG: train_dataset_run est谩 vac铆o o es una lista vac铆a, no se pueden inspeccionar muestras.\")\n",
    "\n",
    "\n",
    "# ... (Creaci贸n de DataLoaders como antes) ...\n",
    "if len(train_dataset_run) > 0: \n",
    "    train_loader_run = DataLoader(train_dataset_run, batch_size=BATCH_SIZE_RUN, shuffle=True,\n",
    "                                  num_workers=0, generator=generator, collate_fn=collate_fn_skip_none)\n",
    "else:\n",
    "    train_loader_run = None \n",
    "    print(\"Advertencia: El DataLoader de entrenamiento (train_loader_run) no se crear谩 porque el dataset est谩 vac铆o.\")\n",
    "if len(val_dataset_run) > 0:\n",
    "    val_loader_run = DataLoader(val_dataset_run, batch_size=BATCH_SIZE_RUN, shuffle=False,\n",
    "                                num_workers=0, generator=generator, collate_fn=collate_fn_skip_none)\n",
    "else:\n",
    "    val_loader_run = None\n",
    "    print(\"Advertencia: El DataLoader de validaci贸n (val_loader_run) no se crear谩 porque el dataset est谩 vac铆o.\")\n",
    "\n",
    "device_run = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo para el script de Run: {device_run}\")\n",
    "\n",
    "\n",
    "model_run = ResNet50MultiTaskModel(num_classes=NUM_CLASSES, \n",
    "                                   freeze_backbone=True, \n",
    "                                   use_deeper_bbox_head=False).to(device_run)\n",
    "print(\"Usando cabeza de regresi贸n de BBox MS PROFUNDA.\")\n",
    "\n",
    "\n",
    "classification_criterion_run = nn.CrossEntropyLoss() #(Probado: )\n",
    "bbox_criterion_run = nn.SmoothL1Loss() #  AJUSTA AQU (Probado: nn.L1Loss(); nn.SmoothL1Loss()) #Probar:  \n",
    "\n",
    "\n",
    "params_to_train_run = [param for param in model_run.parameters() if param.requires_grad]\n",
    "if not params_to_train_run:\n",
    "    print(\"ERROR: No hay par谩metros para entrenar. Verifica 'freeze_backbone'.\")\n",
    "    optimizer_run = None\n",
    "    scheduler_run = None \n",
    "else:\n",
    "    optimizer_run = optim.Adam(params_to_train_run, lr=1e-3) # O el lr que est茅s usando\n",
    "    scheduler_run = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_run, \n",
    "        mode='min',     \n",
    "        factor=0.1,     \n",
    "        patience=7,     # Paciencia del scheduler\n",
    "        min_lr=1e-6     \n",
    "    )\n",
    "\n",
    "\n",
    "# Generar nombre de archivo con fecha y hora y usar RUTA ABSOLUTA ---\n",
    "ahora = datetime.now() \n",
    "timestamp_str = ahora.strftime(\"%Y%m%d_%H%M\") \n",
    "model_filename = f\"pretrained_model_{timestamp_str}.pth\"\n",
    "\n",
    "model_save_path_run = osp.join(absolute_dir_results, model_filename) \n",
    "\n",
    "# --- Generar nombre de archivo para guardar el modelo de ESTA EJECUCIN ---\n",
    "timestamp_str_run = ahora.strftime(\"%Y%m%d_%H%M%S\") # Segundos para mayor unicidad\n",
    "model_filename_run = f\"pretrained_model_{timestamp_str_run}.pth\"\n",
    "model_save_path_run = osp.join(DIR_Results, model_filename_run) \n",
    "print(f\"DEBUG: El modelo se guardar谩 en la ruta absoluta: {model_save_path_run}\")\n",
    "\n",
    "\n",
    "print(\"Iniciando el proceso de entrenamiento del script de Run...\")\n",
    "APPLY_SIGMOID_FLAG_RUN = True \n",
    "print(f\"APPLY_SIGMOID_TO_BBOX_PRED para el script de Run est谩 configurado a: {APPLY_SIGMOID_FLAG_RUN}\")\n",
    "\n",
    "if train_loader_run is not None and optimizer_run is not None: \n",
    "    trained_model_run, history_run = train_multitask_model(\n",
    "        model=model_run,\n",
    "        train_loader=train_loader_run,\n",
    "        val_loader=val_loader_run, \n",
    "        classification_criterion=classification_criterion_run,\n",
    "        bbox_criterion=bbox_criterion_run,\n",
    "        optimizer=optimizer_run,\n",
    "        device=device_run,\n",
    "        num_epochs=120, #  AJUSTA AQU \n",
    "        bbox_loss_weight=20.0, #  AJUSTA AQU \n",
    "        patience=15, #  AJUSTA AQU \n",
    "        model_save_path=model_save_path_run,\n",
    "        apply_sigmoid_to_bbox_pred=APPLY_SIGMOID_FLAG_RUN\n",
    "    )\n",
    "    print(\"Entrenamiento del script de Run completado.\")\n",
    "else:\n",
    "    print(\"No se ejecut贸 el entrenamiento del script de Run porque el train_loader_run est谩 vac铆o/None o no hay par谩metros para entrenar.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11672293,
     "sourceId": 97986,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.783225,
   "end_time": "2025-04-07T23:00:47.759016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T22:59:35.975791",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16394c8b0b3548a6bb7e6e85ba5b8edd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ceedf1613b3f443b873ba8471e890791",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aac01175d6064acab51e786670626698",
       "tabbable": null,
       "tooltip": null,
       "value": 0
      }
     },
     "3f3bbfbb2a5a4cc49ea2f20768f807c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "443b9d0093a240bf896a39621d7bee5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "65eb9bb216c84d4d8b3c16df62a3eca9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_702de51199b84f548dc10f0ff02dcef4",
       "placeholder": "",
       "style": "IPY_MODEL_3f3bbfbb2a5a4cc49ea2f20768f807c6",
       "tabbable": null,
       "tooltip": null,
       "value": "0/?[00:00&lt;?,?it/s]"
      }
     },
     "702de51199b84f548dc10f0ff02dcef4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a99616741eb4ab7a541d30173dd8551": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aac01175d6064acab51e786670626698": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b2a7dd969aa748e793936bdc159cdc0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd70270271fa49678e0a595be7e997f5",
       "placeholder": "",
       "style": "IPY_MODEL_443b9d0093a240bf896a39621d7bee5e",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "ceedf1613b3f443b873ba8471e890791": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "da7fa9424ee84549bafebc2adda3d104": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b2a7dd969aa748e793936bdc159cdc0d",
        "IPY_MODEL_16394c8b0b3548a6bb7e6e85ba5b8edd",
        "IPY_MODEL_65eb9bb216c84d4d8b3c16df62a3eca9"
       ],
       "layout": "IPY_MODEL_7a99616741eb4ab7a541d30173dd8551",
       "tabbable": null,
       "tooltip": null
      }
     },
     "dd70270271fa49678e0a595be7e997f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
