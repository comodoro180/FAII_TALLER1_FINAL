{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282215d1",
   "metadata": {
    "papermill": {
     "duration": 0.016676,
     "end_time": "2025-04-07T22:59:38.735429",
     "exception": false,
     "start_time": "2025-04-07T22:59:38.718753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2011d56",
   "metadata": {
    "papermill": {
     "duration": 0.009755,
     "end_time": "2025-04-07T22:59:38.755698",
     "exception": false,
     "start_time": "2025-04-07T22:59:38.745943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae19e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade pip\n",
    "#%pip install torchsummary albumentations wandb --quiet\n",
    "#%pip install tqdm \n",
    "#%pip install pandas \n",
    "#%pip install torch\n",
    "#%pip install PIL\n",
    "#%pip install torchvision\n",
    "#%pip install matplotlib\n",
    "#%pip install scikit-learn\n",
    "#%pip install scikit-image\n",
    "#%pip install setuptools\n",
    "#%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "#%pip install optuna\n",
    "#%pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ac13a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:38.804873Z",
     "iopub.status.busy": "2025-04-07T22:59:38.804599Z",
     "iopub.status.idle": "2025-04-07T22:59:51.818964Z",
     "shell.execute_reply": "2025-04-07T22:59:51.817909Z"
    },
    "papermill": {
     "duration": 13.026975,
     "end_time": "2025-04-07T22:59:51.820468",
     "exception": false,
     "start_time": "2025-04-07T22:59:38.793493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from numpy.typing import NDArray\n",
    "from functools import reduce\n",
    "from itertools import islice\n",
    "import wandb\n",
    "import math\n",
    "from itertools import chain\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchsummary import summary\n",
    "# Import albumentations library in order to -use pre-built augmentations\n",
    "import albumentations as A\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import os.path as osp\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as ty\n",
    "import cv2\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412b155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:51.843032Z",
     "iopub.status.busy": "2025-04-07T22:59:51.842573Z",
     "iopub.status.idle": "2025-04-07T22:59:52.093339Z",
     "shell.execute_reply": "2025-04-07T22:59:52.092352Z"
    },
    "papermill": {
     "duration": 0.263758,
     "end_time": "2025-04-07T22:59:52.095071",
     "exception": false,
     "start_time": "2025-04-07T22:59:51.831313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device}')\n",
    "test = torch.ones((100, 100)).to(device)\n",
    "del test\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un generador para el DataLoader\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa521595",
   "metadata": {
    "papermill": {
     "duration": 0.010047,
     "end_time": "2025-04-07T22:59:52.115831",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.105784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a6cb4",
   "metadata": {
    "papermill": {
     "duration": 0.009893,
     "end_time": "2025-04-07T22:59:52.136142",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.126249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is done in order to control randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc69f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.157490Z",
     "iopub.status.busy": "2025-04-07T22:59:52.157170Z",
     "iopub.status.idle": "2025-04-07T22:59:52.182855Z",
     "shell.execute_reply": "2025-04-07T22:59:52.181895Z"
    },
    "papermill": {
     "duration": 0.037932,
     "end_time": "2025-04-07T22:59:52.184354",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.146422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './Datos/' #'/kaggle/input/fa-ii-2025-i-object-localization/'\n",
    "WORK_DIR = './Datos/' #'/kaggle/working'\n",
    "DIR_Results = './Resultados/'\n",
    "os.makedirs(DIR_Results, exist_ok=True)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "img_dir = osp.join(DATA_DIR, \"images/images\")\n",
    "\n",
    "df = pd.read_csv(osp.join(DATA_DIR, \"train.csv\"))\n",
    "\n",
    "obj2id  = {'f16':0,'cougar':1,'chinook':2,'ah64':3,'f15':4,'seahawk':5}\n",
    "\n",
    "id2obj  = {0:'f16',1:'cougar',2:'chinook',3:'ah64',4:'f15',5:'seahawk'}\n",
    "\n",
    "df[\"class_id\"] = df[\"class\"].map(obj2id)\n",
    "\n",
    "columns_f=['filename','xmin','ymin','xmax','ymax','class','class_id']\n",
    "\n",
    "df= df[columns_f].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d6fb3",
   "metadata": {
    "papermill": {
     "duration": 0.009851,
     "end_time": "2025-04-07T22:59:52.204505",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.194654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3bd31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.225659Z",
     "iopub.status.busy": "2025-04-07T22:59:52.225404Z",
     "iopub.status.idle": "2025-04-07T22:59:52.325826Z",
     "shell.execute_reply": "2025-04-07T22:59:52.324926Z"
    },
    "papermill": {
     "duration": 0.112991,
     "end_time": "2025-04-07T22:59:52.327459",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.214468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_filename = osp.join(DATA_DIR, \"images/images\",'image_00077.jpeg')\n",
    "\n",
    "img1 = cv2.imread(img_filename)\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = io.imread(img_filename) # no necesita bgr2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efba73b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.349085Z",
     "iopub.status.busy": "2025-04-07T22:59:52.348843Z",
     "iopub.status.idle": "2025-04-07T22:59:52.352980Z",
     "shell.execute_reply": "2025-04-07T22:59:52.352286Z"
    },
    "papermill": {
     "duration": 0.016291,
     "end_time": "2025-04-07T22:59:52.354133",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.337842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(img1.shape)\n",
    "print(img1.transpose((2,0,1)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543d9ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:52.376495Z",
     "iopub.status.busy": "2025-04-07T22:59:52.376268Z",
     "iopub.status.idle": "2025-04-07T22:59:55.005361Z",
     "shell.execute_reply": "2025-04-07T22:59:55.004526Z"
    },
    "papermill": {
     "duration": 2.641242,
     "end_time": "2025-04-07T22:59:55.006753",
     "exception": false,
     "start_time": "2025-04-07T22:59:52.365511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_image = list(df.filename)\n",
    "data_shape = []\n",
    "data_dim = []\n",
    "data_w = []\n",
    "data_h = []\n",
    "\n",
    "for i in tqdm(list_image): ## tqdm(list_image)dura 40 segundos\n",
    "    ruta_imagen = osp.join(img_dir, i)\n",
    "    imagen = io.imread(ruta_imagen)\n",
    "    shapes = imagen.shape\n",
    "    dimen = imagen.ndim\n",
    "    imagen = Image.open(ruta_imagen)\n",
    "    w, h = imagen.size\n",
    "    data_w.append(w)\n",
    "    data_h.append(h)\n",
    "    data_shape.append(shapes)\n",
    "    data_dim.append(dimen)\n",
    "\n",
    "data_w_h = pd.DataFrame([list_image,data_shape,data_dim,data_w,data_h]).T.rename(columns={0:'filename',1:'shapes',2:'ndim',3:'w',4:'h'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071a90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.030465Z",
     "iopub.status.busy": "2025-04-07T22:59:55.030178Z",
     "iopub.status.idle": "2025-04-07T22:59:55.039998Z",
     "shell.execute_reply": "2025-04-07T22:59:55.039336Z"
    },
    "papermill": {
     "duration": 0.022737,
     "end_time": "2025-04-07T22:59:55.041156",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.018419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_w_h['w'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6b57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.064527Z",
     "iopub.status.busy": "2025-04-07T22:59:55.064283Z",
     "iopub.status.idle": "2025-04-07T22:59:55.069700Z",
     "shell.execute_reply": "2025-04-07T22:59:55.069042Z"
    },
    "papermill": {
     "duration": 0.018239,
     "end_time": "2025-04-07T22:59:55.070844",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.052605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_w_h['ndim'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f41c81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.094434Z",
     "iopub.status.busy": "2025-04-07T22:59:55.094166Z",
     "iopub.status.idle": "2025-04-07T22:59:55.100319Z",
     "shell.execute_reply": "2025-04-07T22:59:55.099444Z"
    },
    "papermill": {
     "duration": 0.019167,
     "end_time": "2025-04-07T22:59:55.101580",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.082413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_w_h['shapes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae60b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.125406Z",
     "iopub.status.busy": "2025-04-07T22:59:55.125136Z",
     "iopub.status.idle": "2025-04-07T22:59:55.131514Z",
     "shell.execute_reply": "2025-04-07T22:59:55.130710Z"
    },
    "papermill": {
     "duration": 0.019562,
     "end_time": "2025-04-07T22:59:55.132734",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.113172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['class_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308b33b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.157130Z",
     "iopub.status.busy": "2025-04-07T22:59:55.156885Z",
     "iopub.status.idle": "2025-04-07T22:59:55.162977Z",
     "shell.execute_reply": "2025-04-07T22:59:55.162127Z"
    },
    "papermill": {
     "duration": 0.019619,
     "end_time": "2025-04-07T22:59:55.164326",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.144707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae5293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.188357Z",
     "iopub.status.busy": "2025-04-07T22:59:55.188113Z",
     "iopub.status.idle": "2025-04-07T22:59:55.193849Z",
     "shell.execute_reply": "2025-04-07T22:59:55.193147Z"
    },
    "papermill": {
     "duration": 0.01912,
     "end_time": "2025-04-07T22:59:55.195028",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.175908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df['xmin']>=df['xmax']].shape, df[df['ymin']>=df['ymax']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8cfa04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.219482Z",
     "iopub.status.busy": "2025-04-07T22:59:55.219262Z",
     "iopub.status.idle": "2025-04-07T22:59:55.222279Z",
     "shell.execute_reply": "2025-04-07T22:59:55.221682Z"
    },
    "papermill": {
     "duration": 0.016304,
     "end_time": "2025-04-07T22:59:55.223477",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.207173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_real=720\n",
    "w_real=1280\n",
    "h, w, c = 255, 400, 3 # The heigh, width and number of channels of each image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa249fc",
   "metadata": {
    "papermill": {
     "duration": 0.011273,
     "end_time": "2025-04-07T22:59:55.246598",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.235325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalizamos los bboxes (En la siguiente monitoria hablaremos de la importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e5e2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.270360Z",
     "iopub.status.busy": "2025-04-07T22:59:55.270085Z",
     "iopub.status.idle": "2025-04-07T22:59:55.291960Z",
     "shell.execute_reply": "2025-04-07T22:59:55.291089Z"
    },
    "papermill": {
     "duration": 0.035167,
     "end_time": "2025-04-07T22:59:55.293184",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.258017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df[[\"ymin\", \"ymax\", \"xmin\", \"xmax\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee0ab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.317800Z",
     "iopub.status.busy": "2025-04-07T22:59:55.317546Z",
     "iopub.status.idle": "2025-04-07T22:59:55.323804Z",
     "shell.execute_reply": "2025-04-07T22:59:55.322979Z"
    },
    "papermill": {
     "duration": 0.019947,
     "end_time": "2025-04-07T22:59:55.324979",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.305032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalizar las columnas ymin, ymax, xmin, xmax\n",
    "df[[\"ymin\", \"ymax\"]] = df[[\"ymin\", \"ymax\"]].div(h_real, axis=0)\n",
    "df[[\"xmin\", \"xmax\"]] = df[[\"xmin\", \"xmax\"]].div(w_real, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1f4af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.349071Z",
     "iopub.status.busy": "2025-04-07T22:59:55.348826Z",
     "iopub.status.idle": "2025-04-07T22:59:55.361872Z",
     "shell.execute_reply": "2025-04-07T22:59:55.361223Z"
    },
    "papermill": {
     "duration": 0.026846,
     "end_time": "2025-04-07T22:59:55.363577",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.336731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df[[\"ymin\", \"ymax\", \"xmin\", \"xmax\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca908b2f",
   "metadata": {
    "papermill": {
     "duration": 0.011617,
     "end_time": "2025-04-07T22:59:55.387443",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.375826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Particionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c0a403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.412138Z",
     "iopub.status.busy": "2025-04-07T22:59:55.411871Z",
     "iopub.status.idle": "2025-04-07T22:59:55.418848Z",
     "shell.execute_reply": "2025-04-07T22:59:55.418165Z"
    },
    "papermill": {
     "duration": 0.020781,
     "end_time": "2025-04-07T22:59:55.420086",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.399305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    #df, stratify=df['class_id'], test_size=0.25, random_state=42\n",
    "    df, stratify=df['class_id'], test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d0582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.444859Z",
     "iopub.status.busy": "2025-04-07T22:59:55.444635Z",
     "iopub.status.idle": "2025-04-07T22:59:55.450846Z",
     "shell.execute_reply": "2025-04-07T22:59:55.449988Z"
    },
    "papermill": {
     "duration": 0.019809,
     "end_time": "2025-04-07T22:59:55.452158",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.432349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['class'].value_counts(1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae1ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.476944Z",
     "iopub.status.busy": "2025-04-07T22:59:55.476726Z",
     "iopub.status.idle": "2025-04-07T22:59:55.482578Z",
     "shell.execute_reply": "2025-04-07T22:59:55.481788Z"
    },
    "papermill": {
     "duration": 0.019392,
     "end_time": "2025-04-07T22:59:55.483775",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.464383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_df['class_id'].value_counts(1) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d194f",
   "metadata": {
    "papermill": {
     "duration": 0.011616,
     "end_time": "2025-04-07T22:59:55.507333",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.495717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Clase para estructura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734531e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.531764Z",
     "iopub.status.busy": "2025-04-07T22:59:55.531506Z",
     "iopub.status.idle": "2025-04-07T22:59:55.539633Z",
     "shell.execute_reply": "2025-04-07T22:59:55.538783Z"
    },
    "papermill": {
     "duration": 0.02187,
     "end_time": "2025-04-07T22:59:55.540939",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.519069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_func_inp_signature = ty.Dict[str, NDArray[np.float64]]\n",
    "transform_func_signature = ty.Callable[\n",
    "    [transform_func_inp_signature],\n",
    "    transform_func_inp_signature\n",
    "]\n",
    "\n",
    "class militarDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Location image dataset\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        root_dir: str, \n",
    "        labeled: bool = True,\n",
    "        transform: ty.Optional[ty.List[transform_func_signature]] = None,\n",
    "        output_size: ty.Optional[tuple] = None  # Añadir parámetro para tamaño de salida\n",
    "    ) -> None:\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.labeled = labeled\n",
    "        self.output_size = output_size  # Almacenar el tamaño de salida\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> transform_func_signature: \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Read image\n",
    "        img_name = os.path.join(self.root_dir, self.df.filename.iloc[idx])\n",
    "        #img_name = os.path.join(self.root_dir, self.df.iloc[idx]['filename'])\n",
    "        image = io.imread(img_name)\n",
    "        #image = cv2.imread(img_name)\n",
    "        \n",
    "        \n",
    "        #print(f\"Dimensiones originales de la imagen: {image.shape}\")  # Agregar para depuración\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_name}\")\n",
    "            \n",
    "        if image.ndim == 2:  # Si la imagen está en escala de grises\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)  # Convertir a RGB\n",
    "        elif image.shape[2] == 4:  # Si la imagen es RGBA\n",
    "            image = image[:, :, :3] \n",
    "            \n",
    "        # Redimensionar la imagen si se especifica un tamaño de salida\n",
    "        if self.output_size:\n",
    "            image = cv2.resize(image, self.output_size)  # Redimensionar la imagen\n",
    "        \n",
    "        sample = {'image': image}\n",
    "        \n",
    "        if self.labeled:\n",
    "            # Read labels\n",
    "            img_class = self.df.class_id.iloc[idx]\n",
    "            img_bbox = self.df.iloc[idx, 1:5]\n",
    "\n",
    "            img_bbox = np.array([img_bbox]).astype('float')\n",
    "            img_class = np.array([img_class]).astype('int')\n",
    "            sample.update({'bbox': img_bbox, 'class_id': img_class})\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0606d826",
   "metadata": {
    "papermill": {
     "duration": 0.01208,
     "end_time": "2025-04-07T22:59:55.564871",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.552791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Funciones para dibujar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb64d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.589325Z",
     "iopub.status.busy": "2025-04-07T22:59:55.589054Z",
     "iopub.status.idle": "2025-04-07T22:59:55.596792Z",
     "shell.execute_reply": "2025-04-07T22:59:55.595950Z"
    },
    "papermill": {
     "duration": 0.021368,
     "end_time": "2025-04-07T22:59:55.598075",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.576707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_bbox(img, bbox, color,thickness: int = 3):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    img = cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color, thickness)\n",
    "    return img\n",
    "\n",
    "def normalize_bbox(bbox, h: int, w: int):\n",
    "    \"\"\"Escala las coordenadas normalizadas al tamaño real de la imagen.\"\"\"\n",
    "    return [\n",
    "        int(bbox[0] * w),  # xmin\n",
    "        int(bbox[1] * h),  # ymin\n",
    "        int(bbox[2] * w),  # xmax\n",
    "        int(bbox[3] * h),  # ymax\n",
    "    ]\n",
    "\n",
    "def draw_bboxes(imgs, bboxes, colors,thickness):\n",
    "    \"\"\"Dibuja múltiples cuadros delimitadores en imágenes, escalando según h y w.\"\"\"\n",
    "    for i, (img, bbox, color) in enumerate(zip(imgs, bboxes, colors)):\n",
    "        imgs[i] = draw_bbox(img, bbox, color,thickness)\n",
    "    return imgs\n",
    "\n",
    "def draw_classes(imgs, classes, colors, origin, prefix: str ='',fontScale : int = 2):\n",
    "    \"\"\"Dibuja las clases en las imágenes.\"\"\"\n",
    "    for i, (img, class_id, color) in enumerate(zip(imgs, classes, colors)):\n",
    "        if type(c)==list:\n",
    "            name_class_=id2obj[classes[i]]\n",
    "        else:\n",
    "            name_class_=id2obj[classes[i][0]]\n",
    "        imgs[i] = cv2.putText(\n",
    "            img, f'{prefix}{name_class_}', #class_id.squeeze()\n",
    "            origin, cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale , color, 2, cv2.LINE_AA\n",
    "        )\n",
    "    return imgs\n",
    "\n",
    "def draw_predictions(imgs, classes, bboxes, colors, origin,thickness,fontScale):\n",
    "    \"\"\"\n",
    "    Combina las funciones anteriores para dibujar cuadros delimitadores\n",
    "    y clases en las imágenes.\n",
    "    \"\"\"\n",
    "    assert all(len(x) > 0 for x in [imgs, classes, bboxes, colors])\n",
    "    if len(colors) == 1:\n",
    "        colors = [colors[0] for _ in imgs]\n",
    "    imgs = draw_bboxes(imgs, bboxes, colors,thickness)\n",
    "    imgs = draw_classes(imgs, classes, colors, origin,\"\",fontScale)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eda1bf",
   "metadata": {
    "papermill": {
     "duration": 0.01182,
     "end_time": "2025-04-07T22:59:55.621890",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.610070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Graficamos una muestra de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c328fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:55.646882Z",
     "iopub.status.busy": "2025-04-07T22:59:55.646599Z",
     "iopub.status.idle": "2025-04-07T22:59:56.535128Z",
     "shell.execute_reply": "2025-04-07T22:59:56.534205Z"
    },
    "papermill": {
     "duration": 0.909842,
     "end_time": "2025-04-07T22:59:56.543817",
     "exception": false,
     "start_time": "2025-04-07T22:59:55.633975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_root_dir = osp.join(DATA_DIR, \"images/images\")#, \"train\"\n",
    "train_ds = militarDataset(train_df, root_dir=train_root_dir,output_size=(w,h))\n",
    "\n",
    "num_imgs = 6\n",
    "start_idx = 0\n",
    "\n",
    "samples = [train_ds[i] for i in range(start_idx, num_imgs)]\n",
    "\n",
    "imgs = [s['image'] for s in samples]\n",
    "bboxes = [normalize_bbox(s['bbox'].squeeze(),h,w) for s in samples]\n",
    "classes = [s['class_id'] for s in samples]\n",
    "\n",
    "imgs = draw_predictions(imgs, classes, bboxes, [(0, 150, 0)], (int(w*0.1), int(h*0.1)),thickness = 1,fontScale=1)#(150, 10)\n",
    "\n",
    "fig = plt.figure(figsize=(30, num_imgs))\n",
    "\n",
    "for i, img in enumerate(imgs):\n",
    "    fig.add_subplot(1, num_imgs, i+1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7f2b4",
   "metadata": {
    "papermill": {
     "duration": 0.022342,
     "end_time": "2025-04-07T22:59:56.589719",
     "exception": false,
     "start_time": "2025-04-07T22:59:56.567377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalización (Ahora de los píxeles, es diferente a la normalización anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b7a46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:56.634826Z",
     "iopub.status.busy": "2025-04-07T22:59:56.634527Z",
     "iopub.status.idle": "2025-04-07T22:59:59.484315Z",
     "shell.execute_reply": "2025-04-07T22:59:59.483389Z"
    },
    "papermill": {
     "duration": 2.874331,
     "end_time": "2025-04-07T22:59:59.486018",
     "exception": false,
     "start_time": "2025-04-07T22:59:56.611687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = militarDataset(train_df, root_dir=train_root_dir,output_size=(w,h))#,output_size=(255,255)\n",
    "\n",
    "means = np.zeros(3)\n",
    "stds = np.zeros(3)\n",
    "n_images = 0\n",
    "\n",
    "for x in train_ds:\n",
    "    img = x['image']#.astype(np.float32)  # Asegúrate de que la imagen está en float para cálculos precisos\n",
    "    n_images += 1\n",
    "\n",
    "    for channel in range(3):\n",
    "        channel_pixels = img[..., channel]\n",
    "        # Acumular la suma y suma de cuadrados para calcular la media y desviación estándar\n",
    "        means[channel] += np.mean(channel_pixels)\n",
    "        stds[channel] += np.std(channel_pixels)\n",
    "\n",
    "# Calcular la media y desviación estándar final\n",
    "means /= n_images\n",
    "stds /= n_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcbab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:59.577857Z",
     "iopub.status.busy": "2025-04-07T22:59:59.577530Z",
     "iopub.status.idle": "2025-04-07T22:59:59.585072Z",
     "shell.execute_reply": "2025-04-07T22:59:59.584203Z"
    },
    "papermill": {
     "duration": 0.032191,
     "end_time": "2025-04-07T22:59:59.586477",
     "exception": false,
     "start_time": "2025-04-07T22:59:59.554286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C (0,1,2)\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = torch.from_numpy(image).float()\n",
    "        sample.update({'image': image})\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Normalizer(object):\n",
    "    \n",
    "    def __init__(self, stds, means):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        \n",
    "            stds: array of length 3 containing the standard deviation of each channel in RGB order.\n",
    "            means: array of length 3 containing the means of each channel in RGB order.\n",
    "        \"\"\"\n",
    "        self.stds = stds\n",
    "        self.means = means\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Sample: a dicitonary containing:\n",
    "            image: sample image in format (C, H, W)\n",
    "        Returns:\n",
    "            the image in (C, H, W) format with the channels normalized.\n",
    "        \"\"\"\n",
    "        image = sample['image']\n",
    "        \n",
    "        for channel in range(3):\n",
    "            image[channel] = (image[channel] - means[channel]) / stds[channel]\n",
    "\n",
    "        sample['image'] = image\n",
    "        return sample\n",
    "\n",
    "class TVTransformWrapper(object):\n",
    "    \"\"\"Torch Vision Transform Wrapper\n",
    "    \"\"\"\n",
    "    def __init__(self, transform: torch.nn.Module):\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = self.transform(sample['image'])\n",
    "        return sample\n",
    "\n",
    "class AlbumentationsWrapper(object):\n",
    "    \n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        transformed = self.transform(\n",
    "            image=sample['image'], \n",
    "            bboxes=sample['bbox'],\n",
    "            #category_ids=sample['class_id']\n",
    "        )\n",
    "        sample['image'] = transformed['image']\n",
    "        sample['bbox'] = np.array(transformed['bboxes'])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27d62a",
   "metadata": {
    "papermill": {
     "duration": 0.021929,
     "end_time": "2025-04-07T22:59:59.630713",
     "exception": false,
     "start_time": "2025-04-07T22:59:59.608784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39f961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:59.675778Z",
     "iopub.status.busy": "2025-04-07T22:59:59.675494Z",
     "iopub.status.idle": "2025-04-07T22:59:59.681405Z",
     "shell.execute_reply": "2025-04-07T22:59:59.680734Z"
    },
    "papermill": {
     "duration": 0.029984,
     "end_time": "2025-04-07T22:59:59.682658",
     "exception": false,
     "start_time": "2025-04-07T22:59:59.652674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_transforms = [\n",
    "    ToTensor(),\n",
    "    Normalizer(\n",
    "        means=means,\n",
    "        stds=stds,\n",
    "    )\n",
    "]\n",
    "\n",
    "train_data_augmentations = A.Compose([\n",
    "    A.HorizontalFlip(p=1),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(\n",
    "        format='albumentations', \n",
    "        label_fields=[],\n",
    "    )\n",
    ")\n",
    "\n",
    "train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        AlbumentationsWrapper(train_data_augmentations),\n",
    "    ] + common_transforms\n",
    ")\n",
    "\n",
    "eval_transforms = torchvision.transforms.Compose(common_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008ed80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:59:59.728865Z",
     "iopub.status.busy": "2025-04-07T22:59:59.728593Z",
     "iopub.status.idle": "2025-04-07T23:00:00.092758Z",
     "shell.execute_reply": "2025-04-07T23:00:00.091785Z"
    },
    "papermill": {
     "duration": 0.389244,
     "end_time": "2025-04-07T23:00:00.094313",
     "exception": false,
     "start_time": "2025-04-07T22:59:59.705069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = militarDataset(df, root_dir=train_root_dir, transform=train_transforms,output_size=(w,h))#\n",
    "train_data = torch.utils.data.DataLoader(train_ds, batch_size=16)#,collate_fn=custom_collate_fn\n",
    "\n",
    "for x in train_data:\n",
    "    print(x['image'].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4191b",
   "metadata": {
    "papermill": {
     "duration": 0.021938,
     "end_time": "2025-04-07T23:00:00.139010",
     "exception": false,
     "start_time": "2025-04-07T23:00:00.117072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db307ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.features = model.features\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "efficientnet_model = efficientnet_b2(weights=EfficientNet_B2_Weights.DEFAULT)\n",
    "pretrained_model = FeatureExtractor(efficientnet_model).to(device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet201, DenseNet201_Weights\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.features = model.features\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "densenet_model = densenet201(weights=DenseNet201_Weights.DEFAULT)\n",
    "pretrained_model = FeatureExtractor(densenet_model).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab1410",
   "metadata": {
    "papermill": {
     "duration": 0.025569,
     "end_time": "2025-04-07T23:00:04.817109",
     "exception": false,
     "start_time": "2025-04-07T23:00:04.791540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360b68e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:04.865511Z",
     "iopub.status.busy": "2025-04-07T23:00:04.865160Z",
     "iopub.status.idle": "2025-04-07T23:00:04.872058Z",
     "shell.execute_reply": "2025-04-07T23:00:04.871362Z"
    },
    "papermill": {
     "duration": 0.032728,
     "end_time": "2025-04-07T23:00:04.873382",
     "exception": false,
     "start_time": "2025-04-07T23:00:04.840654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_output_shape(model: nn.Sequential, image_dim: ty.Tuple[int, int, int]):\n",
    "    return model(torch.rand(*(image_dim)).to(device)).data.shape\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_shape: ty.Tuple[int, int, int] = (3, 255, 400), n_classes: int = 6):\n",
    "        \"\"\"\n",
    "        Model with one input (image) and two outputs: \n",
    "            1. Digit classification (classification).\n",
    "            2. Bounding box prediction (regression). \n",
    "        \n",
    "        Arguments:\n",
    "            input_shape: input shape of the image in format (C, H, W)\n",
    "            n_classes: number of classes to perfrom classification with\n",
    "            \n",
    "        Attributes:\n",
    "            backbone: ConvNet that process the image and \n",
    "            returns a flattened vector with the information of the \n",
    "            activations.\n",
    "            \n",
    "            cls_head: MLP that receives the flattened input from the backbone \n",
    "            and predicts the classification logits for the classes (classficiation task).\n",
    "            \n",
    "            reg_head: MLP that receives the flattened input from the backbone \n",
    "            and predicts the coordinates of the predicted bounding box (regression task). \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # When doing transfer learning, use pretrained model instead of custom backbone\n",
    "        self.backbone = pretrained_model\n",
    "        \n",
    "        backbone_output_shape = get_output_shape(self.backbone, [1, *input_shape])\n",
    "        backbone_output_features = reduce(lambda x, y: x*y, backbone_output_shape)\n",
    "        \n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(in_features=backbone_output_features, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "        \n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(in_features=backbone_output_features, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> ty.Dict[str, Tensor]:\n",
    "        features = self.backbone(x)\n",
    "        cls_logits = self.cls_head(features)\n",
    "        pred_bbox = self.reg_head(features)\n",
    "        predictions = {'bbox': pred_bbox, 'class_id': cls_logits}\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734b8f7",
   "metadata": {
    "papermill": {
     "duration": 0.033065,
     "end_time": "2025-04-07T23:00:04.930437",
     "exception": false,
     "start_time": "2025-04-07T23:00:04.897372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bfe01f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:04.983159Z",
     "iopub.status.busy": "2025-04-07T23:00:04.982862Z",
     "iopub.status.idle": "2025-04-07T23:00:04.986592Z",
     "shell.execute_reply": "2025-04-07T23:00:04.985943Z"
    },
    "papermill": {
     "duration": 0.029757,
     "end_time": "2025-04-07T23:00:04.987912",
     "exception": false,
     "start_time": "2025-04-07T23:00:04.958155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iou(y_true: Tensor, y_pred: Tensor):\n",
    "    # Ensure y_true and y_pred are 2D tensors of shape [N, 4]\n",
    "    y_true = y_true.squeeze()\n",
    "    y_pred = y_pred.squeeze()\n",
    "    if y_true.ndim == 1:\n",
    "        y_true = y_true.unsqueeze(0)\n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred = y_pred.unsqueeze(0)\n",
    "    pairwise_iou = torchvision.ops.box_iou(y_true, y_pred)\n",
    "    result = torch.trace(pairwise_iou) / pairwise_iou.size(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e438c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:05.035971Z",
     "iopub.status.busy": "2025-04-07T23:00:05.035682Z",
     "iopub.status.idle": "2025-04-07T23:00:05.039957Z",
     "shell.execute_reply": "2025-04-07T23:00:05.039093Z"
    },
    "papermill": {
     "duration": 0.029585,
     "end_time": "2025-04-07T23:00:05.041319",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.011734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true: Tensor, y_pred: Tensor):\n",
    "    pred = torch.argmax(y_pred, axis=-1)\n",
    "    y_true = y_true.squeeze()\n",
    "    correct = torch.eq(pred, y_true).float()\n",
    "    total = torch.ones_like(correct)\n",
    "    result = torch.divide(torch.sum(correct), torch.sum(total))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2384060b",
   "metadata": {
    "papermill": {
     "duration": 0.023501,
     "end_time": "2025-04-07T23:00:05.088388",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.064887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9610d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:05.136026Z",
     "iopub.status.busy": "2025-04-07T23:00:05.135732Z",
     "iopub.status.idle": "2025-04-07T23:00:05.140464Z",
     "shell.execute_reply": "2025-04-07T23:00:05.139643Z"
    },
    "papermill": {
     "duration": 0.030006,
     "end_time": "2025-04-07T23:00:05.141652",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.111646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_preds, alpha: float = 0.5):\n",
    "    cls_y_true, cls_y_pred = y_true['class_id'].long(), y_preds['class_id'].float().unsqueeze(-1)\n",
    "    reg_y_true, reg_y_pred = y_true['bbox'].float().squeeze(), y_preds['bbox'].float().squeeze()\n",
    "    \n",
    "    cls_loss = F.cross_entropy(cls_y_pred, cls_y_true)\n",
    "    \n",
    "    reg_loss = F.mse_loss(reg_y_pred, reg_y_true)\n",
    "    # Adds weights to both tasks\n",
    "    total_loss = (1 - alpha) * cls_loss + alpha * reg_loss\n",
    "    return dict(loss=total_loss, reg_loss=reg_loss,cls_loss=cls_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31423eb",
   "metadata": {
    "papermill": {
     "duration": 0.023293,
     "end_time": "2025-04-07T23:00:05.188467",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.165174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5a0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:05.236504Z",
     "iopub.status.busy": "2025-04-07T23:00:05.236170Z",
     "iopub.status.idle": "2025-04-07T23:00:05.241135Z",
     "shell.execute_reply": "2025-04-07T23:00:05.240248Z"
    },
    "papermill": {
     "duration": 0.030676,
     "end_time": "2025-04-07T23:00:05.242576",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.211900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def printer(logs: ty.Dict[str, ty.Any]):\n",
    "    # print every 10 steps\n",
    "    if logs['iters'] % 10 != 0:\n",
    "        return\n",
    "    print('Iteration #: ',logs['iters'])\n",
    "    for name, value in logs.items():\n",
    "        if name == 'iters':\n",
    "            continue\n",
    "        \n",
    "        if type(value) in [float, int]:\n",
    "            value = round(value, 4)\n",
    "        elif type(value) is torch.Tensor:\n",
    "            value = torch.round(value, decimals=4)\n",
    "        \n",
    "        print(f'\\t{name} = {value}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd653d",
   "metadata": {
    "papermill": {
     "duration": 0.02323,
     "end_time": "2025-04-07T23:00:05.289353",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.266123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48277c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:05.337382Z",
     "iopub.status.busy": "2025-04-07T23:00:05.337059Z",
     "iopub.status.idle": "2025-04-07T23:00:05.348016Z",
     "shell.execute_reply": "2025-04-07T23:00:05.347387Z"
    },
    "papermill": {
     "duration": 0.036421,
     "end_time": "2025-04-07T23:00:05.349180",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.312759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    logs: ty.Dict[str, ty.Any], \n",
    "    labels: ty.Dict[str, Tensor],\n",
    "    preds: ty.Dict[str, Tensor],\n",
    "    eval_set: str,\n",
    "    metrics: ty.Dict[str, ty.Callable[[Tensor, Tensor], Tensor]],\n",
    "    losses: ty.Optional[ty.Dict[str, Tensor]] = None,\n",
    ") -> ty.Dict[str, ty.Any]:\n",
    "    \n",
    "    if losses is not None:\n",
    "        for loss_name, loss_value in losses.items():\n",
    "            logs[f'{eval_set}_{loss_name}'] = loss_value\n",
    "    \n",
    "    for task_name, label in labels.items():\n",
    "        for metric_name, metric in metrics[task_name]:\n",
    "            value = metric(label, preds[task_name])\n",
    "            logs[f'{eval_set}_{metric_name}'] = value\n",
    "            \n",
    "    return logs\n",
    "\n",
    "def step(\n",
    "    model: Model, \n",
    "    optimizer: Optimizer, \n",
    "    batch: militarDataset,\n",
    "    loss_fn: ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor],\n",
    "    device: str,\n",
    "    train: bool = False,\n",
    ") -> ty.Tuple[ty.Dict[str, Tensor], ty.Dict[str, Tensor]]:\n",
    "    \n",
    "    if train:\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    #img = batch['image'].to(device)\n",
    "    img = batch.pop('image').to(device)\n",
    "    \n",
    "    for k in list(batch.keys()):\n",
    "        batch[k] = batch[k].to(device)\n",
    "    \n",
    "    preds = model(img.float())\n",
    "    losses = loss_fn(batch, preds)\n",
    "    final_loss = losses['loss']\n",
    "    \n",
    "    if train:\n",
    "        final_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses, preds\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: Model, \n",
    "    optimizer: Optimizer, \n",
    "    dataset: DataLoader,\n",
    "    eval_datasets: ty.List[ty.Tuple[str, DataLoader]],\n",
    "    loss_fn: ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor],\n",
    "    metrics: ty.Dict[str, ty.Callable[[Tensor, Tensor], Tensor]],\n",
    "    callbacks: ty.List[ty.Callable[[ty.Dict[ty.Any, ty.Any]], None]],\n",
    "    device: str,\n",
    "    train_steps: 100,\n",
    "    eval_steps: 10,\n",
    ") -> Model:\n",
    "    # Send model to device (GPU or CPU)\n",
    "    model = model.to(device)\n",
    "    iters = 0\n",
    "    iterator = iter(dataset)\n",
    "    assert train_steps > eval_steps, 'Train steps should be greater than the eval steps'\n",
    "    \n",
    "    while iters <= train_steps:\n",
    "        logs = dict()\n",
    "        logs['iters'] = iters\n",
    "        try:\n",
    "            batch = next(iterator)\n",
    "        except StopIteration:\n",
    "            iterator = iter(dataset)\n",
    "            batch = next(iterator)\n",
    "        # Send batch to device \n",
    "        losses, preds = step(model, optimizer, batch, loss_fn, device, train=True)\n",
    "        logs = evaluate(logs, batch, preds, 'train', metrics, losses)\n",
    "        \n",
    "        # Eval every eval_steps iterations\n",
    "        if iters % eval_steps == 0:        \n",
    "            # Evaluate\n",
    "            # Deactives layers that only needed to train\n",
    "            # https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615\n",
    "            model.eval()\n",
    "            \n",
    "            # Avoids calculating gradients in evaluation dataset. \n",
    "            with torch.no_grad():\n",
    "\n",
    "                for name, dataset in eval_datasets:\n",
    "                    \n",
    "                    for batch in dataset:\n",
    "                        losses, preds = step(model, optimizer, batch, loss_fn, device, train=False)            \n",
    "                        logs = evaluate(logs, batch, preds, name, metrics, losses)\n",
    "        \n",
    "        for callback in callbacks:\n",
    "            callback(logs)\n",
    "        \n",
    "        iters += 1\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f17c1a",
   "metadata": {
    "papermill": {
     "duration": 0.024267,
     "end_time": "2025-04-07T23:00:05.397282",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.373015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a802429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:00:05.445640Z",
     "iopub.status.busy": "2025-04-07T23:00:05.445340Z",
     "iopub.status.idle": "2025-04-07T23:00:06.037901Z",
     "shell.execute_reply": "2025-04-07T23:00:06.037172Z"
    },
    "papermill": {
     "duration": 0.61853,
     "end_time": "2025-04-07T23:00:06.039626",
     "exception": false,
     "start_time": "2025-04-07T23:00:05.421096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hparams\n",
    "batch_size = 16\n",
    "lr = 0.001\n",
    "\n",
    "# Data\n",
    "train_ds = militarDataset(train_df, root_dir=train_root_dir, transform=train_transforms,output_size=(w,h))#,output_size=(255,255)\n",
    "val_ds = militarDataset(val_df, root_dir=train_root_dir, transform=eval_transforms,output_size=(w,h)) #,output_size=(255,255)\n",
    "\n",
    "#train_data = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=cpu_count())\n",
    "#val_data = DataLoader(val_ds, batch_size=batch_size, num_workers=cpu_count())\n",
    "\n",
    "train_data = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0,generator=generator)\n",
    "val_data = DataLoader(val_ds, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "# Model\n",
    "model = Model().to(device)\n",
    "#summary(model, model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98325f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(lr=lr, params=model.parameters())\n",
    "\n",
    "model = train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_data,\n",
    "    eval_datasets=[('val', val_data)],\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\n",
    "        'bbox': [('iou', iou)],\n",
    "        'class_id': [('accuracy', accuracy)]\n",
    "    },\n",
    "    callbacks=[printer],\n",
    "    device=device,\n",
    "    train_steps=400,\n",
    "    eval_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a418f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Obtener la fecha y hora actual\n",
    "ahora = datetime.now()\n",
    "# Formatear como AAAAMMDD_HH_SS\n",
    "fecha = ahora.strftime(\"%Y%m%d_%H_%S\")\n",
    "print(fecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43915d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nom_modelo_entrenado = osp.join(DIR_Results,'pretrained_model_'+fecha+'.pth')\n",
    "nom_submision = osp.join(DIR_Results,'submission_'+fecha+'.csv') \n",
    "\n",
    "# Save the model to disk\n",
    "torch.save(model, nom_modelo_entrenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on cpu in order to avoid memory problems \n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "test_root_dir = osp.join(DATA_DIR, \"images/images\")\n",
    "test_df = pd.read_csv(osp.join(DATA_DIR, \"test.csv\"))\n",
    "\n",
    "test_ds = militarDataset(test_df, root_dir=test_root_dir, labeled=False, transform=eval_transforms,output_size=(w,h))#\n",
    "test_data = DataLoader(test_ds, batch_size=1, num_workers=0, shuffle=False)\n",
    "\n",
    "class_preds = []\n",
    "bbox_preds = []\n",
    "\n",
    "for batch in test_data:\n",
    "    batch_preds = model(batch['image'].float().to(device))\n",
    "    \n",
    "    class_pred = batch_preds['class_id'].argmax(-1).detach().cpu().numpy()\n",
    "    bbox_pred = batch_preds['bbox'].detach().cpu().numpy()\n",
    "    \n",
    "    class_preds.append(class_pred.squeeze())\n",
    "    bbox_preds.append(bbox_pred.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = np.array(class_preds)\n",
    "bbox_preds = np.array(bbox_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    index=test_df.filename,\n",
    "    data={\n",
    "        'class': class_preds,\n",
    "        }\n",
    ")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90cfac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"xmin\"] = bbox_preds[:, 0]*w_real\n",
    "submission[\"ymin\"] = bbox_preds[:, 1]*h_real\n",
    "submission[\"xmax\"] = bbox_preds[:, 2]*w_real\n",
    "submission[\"ymax\"] = bbox_preds[:, 3]*h_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b295e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['class']=submission['class'].replace(id2obj)\n",
    "submission.to_csv(nom_submision)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11672293,
     "sourceId": 97986,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.783225,
   "end_time": "2025-04-07T23:00:47.759016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T22:59:35.975791",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16394c8b0b3548a6bb7e6e85ba5b8edd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ceedf1613b3f443b873ba8471e890791",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aac01175d6064acab51e786670626698",
       "tabbable": null,
       "tooltip": null,
       "value": 0
      }
     },
     "3f3bbfbb2a5a4cc49ea2f20768f807c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "443b9d0093a240bf896a39621d7bee5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "65eb9bb216c84d4d8b3c16df62a3eca9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_702de51199b84f548dc10f0ff02dcef4",
       "placeholder": "​",
       "style": "IPY_MODEL_3f3bbfbb2a5a4cc49ea2f20768f807c6",
       "tabbable": null,
       "tooltip": null,
       "value": " 0/? [00:00&lt;?, ?it/s]"
      }
     },
     "702de51199b84f548dc10f0ff02dcef4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a99616741eb4ab7a541d30173dd8551": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aac01175d6064acab51e786670626698": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b2a7dd969aa748e793936bdc159cdc0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd70270271fa49678e0a595be7e997f5",
       "placeholder": "​",
       "style": "IPY_MODEL_443b9d0093a240bf896a39621d7bee5e",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "ceedf1613b3f443b873ba8471e890791": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "da7fa9424ee84549bafebc2adda3d104": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b2a7dd969aa748e793936bdc159cdc0d",
        "IPY_MODEL_16394c8b0b3548a6bb7e6e85ba5b8edd",
        "IPY_MODEL_65eb9bb216c84d4d8b3c16df62a3eca9"
       ],
       "layout": "IPY_MODEL_7a99616741eb4ab7a541d30173dd8551",
       "tabbable": null,
       "tooltip": null
      }
     },
     "dd70270271fa49678e0a595be7e997f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
